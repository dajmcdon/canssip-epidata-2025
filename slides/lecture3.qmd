---
talk-title: "Quick Tour of Time Series Forecasting"
talk-short-title: "Time Series"
talk-subtitle: "InsightNet Forecasting Workshop 2024"
talk-date: "12 December -- Morning"
format: revealjs
---

{{< include _titleslide.qmd >}}

```{r ggplot-theme}
#| cache: false
ggplot2::theme_set(ggplot2::theme_bw())
```


## Outline

1. Some Words About Forecasting

1. Linear Regression for Time Series 

1. Evaluation Methods

1. ARX Models

1. Overfitting and Regularization

1. Prediction Intervals

1. Forecasting with Versioned Data

1. Traditional Approaches to Time Series 

# Some Words About Forecasting

## Forecasting is not magic

- Forecasts are generally comprised of two parts: trend and seasonality
- Methods for detecting and projecting trends are not magic; in general they're
  not qualitatively that different from what you can do with your eyeballs
- That said, assimilating information from exogenous features (ideally, leading
  indicators) can lead highly nontrivial gains, beyond the eyeballs
- Remember ... good data is just as (more?) important as a good model! 
- Seasonality can help short-term forecasts. Long-term forecasts, absent of 
  strong seasonality, are generally not very tractable

# Linear Regression for Time Series 

## Basics of linear regression 

* Assume we observe a predictor $x_i$ and an outcome $y_i$ for $i = 1, \dots, n$.

* Linear regression seeks coefficients $\beta_0$ and $\beta_1$ such that

$$y_i \approx \beta_0 + \beta_1 x_i$$

is a good approximation for every $i = 1, \dots, n$.

* In R, the coefficients are found by running `lm(y ~ x)`, where `y` is the vector 
of responses and `x` the vector of predictors.


## Multiple linear regression 

* Given $p$ different predictors, we seek $(p+1)$ coefficients such that

$$y_i \approx \beta_0 + \beta_1 x_{i1} + \dots + \beta_p x_{ip}$$
is a good approximation for every $i = 1, \dots, n$.


## Linear regression with lagged predictor


* In time series, outcomes and predictors are usually indexed by time $t$. 

::: {.fragment .fade-in}
* [Goal]{.primary}: predicting future $y$, given present $x$. 

:::

::: {.fragment .fade-in}
* [Model]{.primary}: linear regression with lagged predictor

$$\hat y_t = \hat \beta + \hat \beta_0 x_{t-k}$$

i.e. regress the outcome $y$ at time $t$ on the predictor $x$ at time $t-k$.

:::

::: {.fragment .fade-in}
* [Equivalent]{.primary} way to write the model: 

$$\hat y_{t+k} = \hat \beta + \hat \beta_0 x_t$$

:::

## Example: predicting COVID deaths  

* During the pandemic, interest in predicting COVID deaths 7, 14, 21, 28 days ahead.

* Can we reasonably [predict COVID deaths 28 days ahead]{.primary} by just using cases today?


::: {.fragment .fade-in}
* If we let

$$y_{t+28} = \text{deaths at time } t+28 \quad\quad x_{t} = \text{cases at time } t$$
  is the following a good model?

  $$\hat y_{t+28} = \hat\beta_0 + \hat\beta_1 x_{t}$$

:::

## Example: COVID cases and deaths in California 

::: flex

::: w-65

```{r plot-ca-cases-deaths}
#| out-width: "100%"
source(here::here("_code/ca_cases_deaths.R"))
ggplot(ca |> 
         mutate(deaths = trans21(deaths)) |>
         pivot_longer(cols = c(cases, deaths), names_to = 'name'),
       aes(x = time_value, y = value)) + 
  geom_line(aes(color = name), key_glyph = "timeseries") +
  scale_color_delphi() +
  scale_y_continuous(
    expand = expansion(c(0, 0.05)),
    name = "Incident cases per 100k people",
    limits = range1,
    sec.axis = sec_axis(
      trans = trans12, 
      name = "Incident deaths per 100k people")) +
  labs(x = "Date") +
  theme(legend.position = "bottom", legend.title = element_blank(),
        axis.title = element_text(size = 10)) 
```

:::

::: w-35

```{r ca data}
#| echo: true
head(ca)
```

:::

:::

::: {.callout-important icon="false"}
## Note

[Cases]{.primary} seem [highly correlated]{.primary} with [deaths]{.primary}
several weeks later (but [relation]{.primary} cases-deaths [changes]{.primary} over time).
:::

## Checking correlation


* Let’s split the data into a training and a test set (before/after 2021-04-01).

* On training set: [large correlation]{.primary}
between cases and deaths 28 days ahead (> 0.95).

```{r correlation-cases-deaths}
t0_date <- as.Date('2021-04-01') #split date

train <- ca |> filter(time_value <= t0_date)
test <- ca |> filter(time_value > t0_date)

t0 <- nrow(train)  #split index

# look at cases and deaths (where we move deaths forward by 1, 2, ..., 35 days)
lags = 1:35
cor_deaths_cases <- lapply(
  lags, 
  function(x) epi_cor(train, deaths, cases, cor_by = geo_value, dt1 = x)
)

cor_deaths_cases <- list_rbind(cor_deaths_cases, names_to = 'Lag') 

#k <- which.max(cor_deaths_cases$cor)
k <- 28 # selected lag

cor_deaths_cases |>
  ggplot(aes(Lag, cor)) +
  geom_vline(xintercept = k, color = base) +
  geom_point(color = primary) +
  geom_line(color = primary) +
  labs(x = "Lag", y = "Correlation") +
  ggtitle('Correlation between cases and deaths by lag')
```

::: {.fragment .fade-in}
* Let's use (base) R to prepare the data and fit 

$$\hat y_{t+28} = \hat\beta + \hat\beta_0 x_{t}$$

:::

## Preparing the data

```{r lag-cases}
#| echo: true
ca$lagged_cases <- dplyr::lag(ca$cases, n = k)     # Add column with cases lagged by k
t0_date <- as.Date('2021-04-01')                   # Split into train and test (before/after t0_date)
train <- ca |> filter(time_value <= t0_date)
test <- ca |> filter(time_value > t0_date)
```

Check if `deaths` is approximately linear in `lagged_cases`:

```{r plot-lag-cases}
ggplot(train, aes(lagged_cases, deaths)) + 
  geom_point(alpha = .5, color = primary, shape = 16) +
  labs(x = "Cases", y = "Deaths 28 days later")
```

## Fitting lagged linear regression in R

```{r lagged-lm}
#| echo: true
reg_lagged = lm(deaths ~ lagged_cases, data = train)
coef(reg_lagged)
```

```{r plot-linear-fit}
ggplot(train, aes(lagged_cases, deaths)) + 
  geom_point(alpha = .5, color = primary, shape = 16) +
  geom_smooth(method = "lm", se = FALSE, color = base) +
  labs(x = "Cases", y = "Deaths 28 days later")
```

# Evaluation

## Error metrics

* Assume we have predictions $\hat y_{new, t}$ for the unseen observations 
$y_{new,t}$ over times $t = 1, \dots, N$.

* Four commonly used error metrics are:

  * mean squared error (MSE)

  * mean absolute error (MAE)

  * mean absolute percentage error (MAPE)

  * mean absolute scaled error (MASE)

## Error metrics: MSE and MAE

$$MSE = \frac{1}{N} \sum_{t=1}^N (y_{new, t}- \hat y_{new, t})^2$$
$$MAE = \frac{1}{N} \sum_{t=1}^N |y_{new, t}- \hat y_{new, t}|$$

* MAE gives less importance to extreme errors than MSE.

* [Drawback]{.primary}: both metrics are scale-dependent, so they are not universally 
interpretable.
(For example, if $y$ captures height, MSE and MAE will vary depending on whether we measure in feet or meters.)

## Error metrics: MAPE

* Fixing scale-dependence:

$$MAPE = 100 \times \frac{1}{N} \sum_{t=1}^N 
\left|\frac{y_{new, t}- \hat y_{new, t}}{y_{new, t}}\right|$$

* [Drawbacks]{.primary}:

  * Erratic behavior when $y_{new, t}$ is close to zero

  * It assumes the unit of measurement has a meaningful zero (e.g. using 
Fahrenheit or Celsius to measure temperature will lead to different MAPE)

## Comparing MAE and MAPE

::: {.callout-important}
There are situations when MAPE is problematic!
:::

::: flex
::: w-70

```{r mae-mape-example}
#| out-width: "100%"
set.seed(0)
fake_upswing <- tibble(
  x = 1:50,
  y = rpois(n = 50, lambda = c(rep(5, 25), 5 + exp(0:24 * 0.2))),
  yhat1 = c(rep(6.5, 25), 6.5 + exp(0:24 * 0.2)),
  yhat2 = c(rep(5, 25), 5 + exp(0:24 * 0.18))
) 

fake_upswing |>
  pivot_longer(starts_with("yhat")) |>
  ggplot(aes(x)) +
  geom_point(aes(y = y), color = tertiary, shape = 16) +
  geom_line(aes(y = value, color = name)) +
  scale_color_delphi(name = "") +
  theme(legend.position = "inside", legend.position.inside = c(.1, .9),
        legend.background = element_blank())
```

:::

::: {.w-30}

```{r mae-mape-error}
with(fake_upswing,
     data.frame("MAE"= c(mean(abs(y - yhat1)), mean(abs(y - yhat2))), 
                "MAPE" = c(mean(abs(y - yhat1) / y), mean(abs(y - yhat2) / y)) * 100, 
                row.names = c('yhat1', 'yhat2')) 
) |>
  knitr::kable(digits = 3)
```

:::
:::


## Error metrics: MASE

$$MASE = 100 \times \frac{\frac{1}{N} \sum_{t=1}^N 
|y_{new, t}- \hat y_{new, t}|}
{\frac{1}{N-1} \sum_{t=2}^N 
|y_{new, t}- y_{new, t-1}|}$$

* [Advantages]{.primary}:

  * is universally interpretable (not scale dependent)

  * avoids the zero-pitfall

* MASE in words: we normalize the error of our forecasts by that of a naive method 
which always predicts the last observation.


## Comparing MAE, MAPE and MASE

::: flex
::: w-70

```{r mae-mape-mase-example}
#| out-width: "100%"
fake_upswing |>
  pivot_longer(starts_with("yhat")) |>
  ggplot(aes(x)) +
  geom_point(aes(y = y), color = tertiary, shape = 16) +
  geom_line(aes(y = value, color = name)) +
  scale_color_delphi(name = "") +
  theme(legend.position = "inside", legend.position.inside = c(.1, .9),
        legend.background = element_blank())
```
:::

::: w-35

```{r mae-mape-mase-error}
with(fake_upswing, data.frame(
  "MAE" = c(mean(abs(y - yhat1)), mean(abs(y - yhat2))), 
  "MAPE" = c(mean(abs(y - yhat1) / y), mean(abs(y - yhat2) / y)) * 100, 
  "MASE" = c(mean(abs(y - yhat1)), 
             mean(abs(y - yhat2))) / mean(abs(diff(y))) * 100,
  row.names = c('yhat1', 'yhat2'))
) |>
  knitr::kable(digits = 3)
```

:::
:::

## Defining the error metrics in R

```{r error functions}
#| echo: true
MSE <- function(truth, prediction) {
  mean((truth - prediction)^2)}

MAE <- function(truth, prediction) {
  mean(abs(truth - prediction))}

MAPE <- function(truth, prediction) {
  100 * mean(abs(truth - prediction) / truth)}

MASE <- function(truth, prediction) {
  100 * MAE(truth, prediction) / mean(abs(diff(truth)))}
```

## Estimating the prediction error

* Given an error metric, we want to estimate the prediction error under that metric. 

* This can be accomplished in different ways, using the

  * Training error

  * Split-sample error

  * Time series cross-validation error (using all past data or a trailing window)


## Training error

* The easiest but [worst]{.primary} approach to estimate the prediction error is 
to use the training error, i.e. the average error on the training set that was 
used to fit the model.

* The training error is

  * generally too optimistic as an estimate of prediction error

  * [more optimistic the more complex the model!]{.primary}^[More on this when we talk about overfitting.]


## Training error 
#### Linear regression of COVID deaths on lagged cases

```{r pred-train}
#| echo: true
# Getting the predictions for the training set
pred_train <- predict(reg_lagged)
```

```{r plot-train-predictions}
#| fig-width: 7
ca |>
  mutate(observed = deaths, 
         predicted = c(rep(NA, k), pred_train, rep(NA, nrow(test)))) |>
  pivot_longer(cols = c(predicted, observed), names_to = 'Deaths') |>
  ggplot(aes(time_value, value, col = Deaths)) + 
  geom_line(aes(alpha = ifelse(time_value < t0_date, 1, .5)), key_glyph = "timeseries") + 
  geom_vline(xintercept = t0_date) +    
  labs(x = "", y = "Deaths per 100k people") + 
  theme(legend.title = element_blank()) +
  scale_y_continuous(expand = expansion(c(0, .05))) +
  scale_color_delphi() +
  scale_alpha_identity()
```

```{r function errors}
getErrors <- function(truth, prediction, type) {
  data.frame(
    #"MSE" = MSE(truth, prediction), 
    "MAE"= MAE(truth, prediction), 
    #"MAPE" = MAPE(truth, prediction), 
    "MASE" = MASE(truth, prediction), 
    row.names = type
  )
}
```


```{r training-error}
errors <- getErrors(train$deaths[-(1:k)], pred_train, "training")
errors
```



## Split-sample error 

To compute the split-sample error  

  1. [Split]{.primary} data into training (up to time $t_0$), and test set (after $t_0$)

  1. [Fit]{.primary} the model to the [training]{.primary} data only

  1. Make [predictions]{.primary} for the [test]{.primary} set

  1. Compute the selected [error]{.primary} metric on the [test]{.primary} set only


::: {.callout-important icon="false"}
## Note

Split-sample estimates of prediction error don't mimic a situation where we 
would refit the model in the future. 
They are [pessimistic]{.primary} if the relation between outcome and predictors 
changes over time.
:::

## Split-sample MSE 

Assume we want to make $h$-step ahead predictions, i.e. at time $t$ we want to 
make a forecast for $t+h$. Then, the split-sample MSE is

$$\text{SplitMSE} = \frac{1}{n-h-t_0} \sum_{t = t_0}^{n-h} (\hat y_{t+h|t_0} - y_{t+h})^2$$

where	$\hat y_{t+h|t_0}$ indicates a prediction for $y$ at time $t+h$ that was made 
with a model that was fit on data up to time $t_0$.



## Split-sample error
#### Linear regression of COVID deaths on lagged cases

```{r test-pred}
#| echo: true
# Getting h-step ahead predictions for the test set
h <- k
test_h <- test[-(1:h-1), ] # drop first h-1 rows to avoid data leakage
pred_test <- predict(reg_lagged, newdata = test_h)
```

```{r plot-test-predictions}
#| fig-width: 7
ca |> 
  mutate(observed = deaths, predicted = c(rep(NA, h), pred_train, 
                                          rep(NA, h-1), pred_test)) |>
  pivot_longer(cols = c(predicted, observed), names_to = 'Deaths') |>
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line(aes(alpha = ifelse(time_value > t0_date, 1, .5)), key_glyph = "timeseries") + 
  geom_vline(xintercept = t0_date) +    
  geom_vline(xintercept = t0_date + h, lty = 2) +
  scale_y_continuous(expand = expansion(c(0, .05))) +
  labs(x = "", y = "Deaths per 100k people") +
  theme(legend.title = element_blank()) +
  scale_alpha_identity() +
  scale_color_delphi()
```


```{r test-error}
errors <- rbind(errors, getErrors(test$deaths, pred_test, "split-sample"))
errors
```

::: {.notes}
Note that we are overestimating the peak due to the changed relationship 
between cases - deaths over time.

Talk about data leakage.
:::

## Warning!

* [Predictions]{.primary} are [overshooting]{.primary} the target, 
especially in early 2022 ([Omicron]{.primary} phase).

* This is because we are predicting [deaths]{.primary} using [lagged cases]{.primary}, 
but the [relation]{.primary} between 
the two [changes]{.primary} over time.


```{r plot-ca-cases-deaths-again}
#| fig-width: 7
ggplot(ca |> 
         mutate(deaths = trans21(deaths)) |>
         pivot_longer(cols = c(cases, deaths), names_to = 'name'),
       aes(x = time_value, y = value)) + 
  geom_line(aes(color = name), key_glyph = "timeseries") +
  scale_color_delphi() +
  scale_y_continuous(
    expand = expansion(c(0, 0.05)),
    name = "Incident cases per 100k people",
    limits = range1,
    sec.axis = sec_axis(
      trans = trans12, 
      name = "Incident deaths per 100k people")) +
  labs(x = "Date") +
  theme(legend.title = element_blank(),
        axis.title = element_text(size = 10)) 
```



## Time series cross-validation (CV)
#### $h$-step ahead predictions

* If we [refit]{.primary} in the future once new data are available, a more 
appropriate way to estimate the prediction error is time series cross-validation.

* To get $h$-step ahead predictions, for each time $t = t_0, t_0+1, \dots$,

  * [Fit]{.primary} the model using data [up to time $t$]{.primary}

  * Make a [prediction for $t+h$]{.primary} 

  * Record the [prediction error]{.primary}

* The cross-validation MSE is then

$$CVMSE = \frac{1}{n-h-t_0} \sum_{t = t_0}^{n-h} (\hat y_{t+h|t} - y_{t+h})^2$$

where	$\hat y_{t+h|t}$ indicates a prediction for $y$ at time $t+h$ that was made 
with data available up to time $t$.

## Time series cross-validation (CV) 
#### Linear regression of COVID deaths on lagged cases

```{r time-series-cv}
#| echo: true
n <- nrow(ca)                               #length of time series
h <- k                                      #number of days ahead for which prediction is wanted
pred_all_past <- rep(NA, length = n)        #initialize vector of predictions

for (t in t0:(n-h)) {
  # fit to all past data and make h-step ahead prediction
  reg_all_past = lm(deaths ~ lagged_cases, data = ca, subset = (1:n) <= t) 
  pred_all_past[t+h] = predict(reg_all_past, newdata = data.frame(ca[t+h, ]))
}

```

::: {.callout-important icon="false"}
## Note

With the current model, we can only predict $k$ days ahead (where $k$ = number of days by which predictor is lagged)!
:::


## Time series cross-validation (CV)
#### Linear regression of COVID deaths on lagged cases

```{r plot-cv-predictions}
#| fig-width: 7
ca |> 
  mutate(observed = deaths, 
         `predicted (CV)` = pred_all_past) |>
  pivot_longer(cols = c(observed, `predicted (CV)`), names_to = 'Deaths') |>
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line(aes(alpha = ifelse(time_value > t0_date, 1, .5)), key_glyph = "timeseries") +
  geom_vline(xintercept = t0_date) +   
  geom_vline(xintercept = t0_date + h, lty = 2) +
  scale_y_continuous(expand = expansion(c(0, .05))) +
  labs(x = "", y = "Deaths per 100k people") +
  theme(legend.title = element_blank()) +
  scale_alpha_identity() +
  scale_color_delphi()
```

```{r cv-error}
errors <- rbind(errors, getErrors(test_h$deaths, 
                                  pred_all_past[!is.na(pred_all_past)], 
                                  "time series CV"))
errors
```

::: {.notes}
Some improvement wrt split-sample, but still overestimating peak. 
:::

## Warning!

* [Predictions]{.primary} are still [overshooting]{.primary} the target, 
but [error]{.primary} is [smaller]{.primary} than split-sample.

* Why?

  * <span class="inner-list"> 👍 Forecaster is partially learning the change in cases-deaths relation 
(especially in late 2022)</span>

  * <span class="inner-list">👎 We refit on all past data, so predictions are still influenced by 
    old cases-deaths relation</span>


::: {.callout-important icon="false"}
## Idea 💡

**Ignore old data when refitting?**
:::

## Regression on a trailing window

* [Fit the model on a window of data of length $w$]{.primary}, 
starting at $t-w$ and ending at $t$.

* [Advantage]{.primary}: if the predictors-outcome relation changes over time,
training the forecaster on a window of recent data can better capture the recent 
relation which might be more relevant to predict the outcome in the near future.

* Window length [$w$]{.primary} considerations: 

  * <span class="inner-list">if $w$ is too [big]{.primary}, 
  the model [can't adapt]{.primary} to the 
  recent predictors-outcome relation </span>
  

  * <span class="inner-list">if $w$ is too [small]{.primary}, 
  the fitted model may be [too volatile]{.primary} 
  (trained on too little data)</span>
  

## Trailing window
#### Linear regression of COVID deaths on lagged cases

```{r time-series-cv-trailing}
#| echo: true
# Getting the predictions through CV with trailing window
w <- 120                                    #trailing window size
h <- k                                      #number of days ahead for which prediction is wanted
pred_trailing <- rep(NA, length = n)        #initialize vector of predictions

for (t in t0:(n-h)) {
  # fit to a trailing window of size w and make h-step ahead prediction
  reg_trailing = lm(deaths ~ lagged_cases, data = ca, 
                    subset = (1:n) <= t & (1:n) > (t-w)) 
  pred_trailing[t+h] = predict(reg_trailing, newdata = data.frame(ca[t+h, ]))
}
```


## Time series CV: all past vs trailing window
#### Linear regression of COVID deaths on lagged cases

```{r plot-cv-predictions-trailing}
#| fig-width: 7
ca |> 
  mutate(observed = deaths, 
         `predicted (CV)` = pred_all_past, 
         `predicted (trailing + CV)` = pred_trailing) |>
  pivot_longer(cols = c(observed, `predicted (CV)`, `predicted (trailing + CV)`), 
               names_to = 'Deaths') |>
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line(aes(alpha = ifelse(time_value > t0_date, 1, .5)), key_glyph = "timeseries") + 
  geom_vline(xintercept = t0_date) +    
  geom_vline(xintercept = t0_date + h, lty = 2) +
  labs(x = "", y = "Deaths per 100k people") +
  scale_y_continuous(expand = expansion(c(0, .05))) +
  theme(legend.title = element_blank()) +
  scale_alpha_identity() +
  scale_color_delphi()
```


```{r cv-trailing-error}
errors <- rbind(errors, getErrors(test_h$deaths, 
                                  pred_trailing[!is.na(pred_trailing)],
                                  "time series CV + trailing"))
errors
```

::: {.notes}
A lot of improvement: trailing window allows to adapt to the change in relationship 
between cases and deaths over time.
:::


# ARX models

## Autoregressive exogenous input (ARX) model

* [Idea]{.primary}: predicting the outcome via a linear combination of its lags 
and a set of exogenous (i.e. external) input variables

* Example:

$$\hat y_{t+h} = \hat\phi + \sum_{i=0}^p \hat\phi_i y_{t-i} + \sum_{j=0}^q \hat\beta_j x_{t-j}$$

* [Notice]{.primary}: we don't need to include all contiguous lags, and we could fit e.g.

$$\hat y_{t+h} = \hat \phi + \hat\phi_0 y_{t} + \hat\phi_1 y_{t-7} + \hat\phi_2 y_{t-14} +
\hat\beta_0 x_{t} + \hat\beta_1 x_{t-7} + \hat\beta_2 x_{t-14}$$


## ARX model for COVID deaths

* Let's add lagged deaths as a predictor to our previous forecaster: 

$$\hat y_{t+28} = \hat\phi + \hat\phi_0 y_{t} + \hat\beta_0 x_{t}$$

* We will refer to this model as [ARX(1)]{.primary}, as it only includes one lag for each predictor.

```{r arx-lm}
#| echo: true
# Prepare data: add column with deaths lagged by 28
ca$lagged_deaths <- dplyr::lag(ca$deaths, n = k)
```

* How does it compare to the previous model in terms of time series CV?

::: {.callout-important icon="false"}
## Note

From now on, we will only consider regression on a [trailing window]{.primary},
since regression on all past data leads to overshooting during Omicron.
:::


```{r arx-training-error}
# Split into train and test (before/after t0_date)
train <- ca |> filter(time_value <= t0_date)
test <- ca |> filter(time_value > t0_date)

# Fit to training set
arx_fit = lm(deaths ~ lagged_deaths + lagged_cases, data = train)
# coef(arx_fit)

pred_train <- predict(arx_fit)                  #get training predictions
pred_test <- predict(arx_fit, newdata = test)   #get test predictions
```

```{r arx-plot-train-test-predictions, eval=FALSE}
ca |> 
  mutate(observed = deaths, 
         predicted = c(rep(NA, k), pred_train, pred_test)) |>
  pivot_longer(cols = c(predicted, observed), names_to = 'Deaths') |>
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line(key_glyph = "timeseries") + 
  geom_vline(xintercept = t0_date) +    
  geom_vline(xintercept = t0_date + h, lty = 2) +
  labs(x = "", y = "Deaths per 100k people") +
  theme(legend.position = "bottom", legend.title = element_blank())
```

```{r arx-train-test-errors, eval=FALSE}
errors_arx <- rbind(getErrors(train$deaths[-(1:k)], pred_train, "training"),
                    getErrors(test$deaths, pred_test, "split-sample"))
errors_arx
```



## Time series CV (trailing): ARX(1) vs `lm` on lagged cases

```{r arx-time-series-cv}
# Getting 28-step ahead predictions through CV 
h <- k                                                      #number of days ahead 
pred_arx1_all_past = pred_arx1 <- rep(NA, length = n)       #initialize vector of predictions
w <- 120                                                    #trailing window size

for (t in t0:(n-h)) {
  # fit to all past data
  arx_all_past = lm(deaths ~ lagged_deaths + lagged_cases, data = ca, subset = (1:n) <= t) 
  # fit to trailing window of data
  arx_trailing = lm(deaths ~ lagged_deaths + lagged_cases, data = ca, 
                    subset = (1:n) <= t & (1:n) > (t-w)) 
  # make h-step ahead prediction
  pred_arx1_all_past[t+h] = max(0, predict(arx_all_past, newdata = data.frame(ca[t+h, ])))
  pred_arx1[t+h] = max(0, predict(arx_trailing, newdata = data.frame(ca[t+h, ])))
}
```

```{r arx-lm-plot-cv-predictions}
#| fig-width: 7
ca |> 
  mutate(observed = deaths, 
         `lm on lagged cases` = pred_trailing, 
         `ARX(1)` = pred_arx1) |>
  pivot_longer(cols = c(observed, `lm on lagged cases`, `ARX(1)`), names_to = 'Deaths') |>
  mutate(Deaths = factor(Deaths, 
                         levels = c("observed", "lm on lagged cases", "ARX(1)"))) |>
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line(aes(alpha = ifelse(time_value > t0_date, 1, .5)), key_glyph = "timeseries") + 
  geom_vline(xintercept = t0_date) +    
  geom_vline(xintercept = t0_date + h, lty = 2) +
  scale_y_continuous(expand = expansion(c(0, .05))) +
  labs(x = "", y = "Deaths per 100k people") +
  theme(legend.title = element_blank()) +
  scale_alpha_identity() +
  scale_color_delphi()
```


```{r arx-cv-error}
rbind(
  getErrors(test_h$deaths, pred_arx1[!is.na(pred_arx1)], "ARX(1)"),
  getErrors(test_h$deaths, pred_trailing[!is.na(pred_trailing)], "lm on lagged cases")
)
```

::: {.notes}
Errors under both metrics are smaller than with previous model.
:::

## Warning!

Regression on a trailing window can be quite sensitive to data issues.

```{r warning-cv-predictions}
#| fig-width: 7
ca |> 
  mutate(`observed deaths` = deaths, 
         `observed cases` = cases / 200,
         `ARX(1)` = pred_arx1) |>
  pivot_longer(cols = c(`observed deaths`, `observed cases`, `ARX(1)`)) |>
  mutate(name = factor(name, 
                       levels = c("observed deaths", "observed cases", "ARX(1)"))) |>  
  ggplot(aes(time_value, value)) +
  geom_line(aes(
    alpha = ifelse(time_value > as.Date("2021-09-13")-2*h-w &
                     time_value < as.Date("2021-09-13") &
                     name != "ARX(1)", 1, .5), col = name), 
    key_glyph = "timeseries") + 
  geom_point(aes(x = as.Date("2021-09-13"), y = 0), size = 1, col = 'darkblue') + 
  geom_vline(xintercept = as.Date("2021-09-13")-2*h-w, lty = 3) +  
  geom_vline(xintercept = as.Date("2021-09-13")-h, lty = 3) +  
  labs(x = "", y = "") +
  theme(legend.title = element_blank()) +
  scale_y_continuous(expand = expansion(c(0, .05))) +
  scale_color_delphi() +
  scale_alpha_identity()
```

## Warning!

* At the [forecast date]{.primary} when the downward dip in deaths is predicted, 
the coefficients estimated by [ARX(1)]{.primary} are

```{r check-issue-trailing}
#which(pred_trailing == 0)
t_issue = 503 #502, 503
all_past = lm(deaths ~ lagged_deaths + lagged_cases, data = ca, subset = (1:n) <= t_issue) 
trailing = lm(deaths ~ lagged_deaths + lagged_cases, data = ca, 
                    subset = (1:n) <= t_issue & (1:n) > (t_issue-w)) 

coef(trailing)
```


* The downward dip is explained by the [negative coefficient on `lagged_cases`]{.primary}, 
and by the fact that at the forecast date

  * observed deaths are exactly equal to 0 (data issue)

  * observed cases are increasing



## Predictions for different $h$

* So far we only focused on COVID death predictions 28 days ahead.

* We will now compare the model with lagged cases as predictor

$$\hat y_{t+h} = \hat\beta + \hat\beta_0 x_t$$

to the ARX(1) model

$$\hat y_{t+h} = \hat\phi + \hat\phi_0 y_t + \hat\beta_0 x_t$$

for [horizons $h = 7, 14, 21, 28$]{.primary}.

* We will only make forecasts on the $1^{st}$ day of each month, and use a trailing window with $w = 120$.


## Predictions for different $h$

```{r different-h-pred}
#| echo: true
h_vals <- c(7, 14, 21, 28)  #horizons 
pred_m1 = pred_m2 <- data.frame(matrix(NA, nrow = 0, ncol = 3))  #initialize df for predictions
colnames(pred_m1) = colnames(pred_m2) = c("forecast_date", "target_date", "prediction")
w <- 120    #trailing window size

ca_lags <- ca |> select(!c(lagged_cases, lagged_deaths))

# Create lagged predictors 
for (i in seq_along(h_vals)) {
  ca_lags[[paste0("lagged_deaths_", h_vals[i])]] <- dplyr::lag(ca_lags$deaths, n = h_vals[i])
  ca_lags[[paste0("lagged_cases_", h_vals[i])]] <- dplyr::lag(ca_lags$cases, n = h_vals[i])
}

# Only forecast on 1st day of the months
forecast_time <- which(ca_lags$time_value >= t0_date & 
                         ca_lags$time_value < ca_lags$time_value[n-max(h_vals)] &
                         day(ca_lags$time_value) == 1)

for (t in forecast_time) {
  for (i in seq_along(h_vals)) {
    h = h_vals[i]
    # formulas including h-lagged variables
    m1_formula = as.formula(paste0("deaths ~ lagged_cases_", h))
    m2_formula = as.formula(paste0("deaths ~ lagged_cases_", h, " + lagged_deaths_", h))
    # fit to trailing window of data
    m1_fit = lm(m1_formula, data = ca_lags, subset = (1:n) <= t & (1:n) > (t-w)) 
    m2_fit = lm(m2_formula, data = ca_lags, subset = (1:n) <= t & (1:n) > (t-w)) 
    # make h-step ahead predictions
    pred_m1 = rbind(pred_m1, 
                    data.frame(forecast_date = ca_lags$time_value[t],
                               target_date = ca_lags$time_value[t+h],
                               prediction = predict(m1_fit, newdata = data.frame(ca_lags[t+h, ]))))
    pred_m2 = rbind(pred_m2, 
                    data.frame(forecast_date = ca_lags$time_value[t],
                               target_date = ca_lags$time_value[t+h],
                               prediction = predict(m2_fit, newdata = data.frame(ca_lags[t+h, ]))))
    }
}
```

## Predictions for different $h$, `lm` on lagged cases

```{r plot-m1}
#| fig-width: 8
#| fig-height: 4.5
pred_m1 |>
  ggplot(aes(target_date, prediction, group = forecast_date)) +
  geom_line(data = ca_lags, aes(x = time_value, y = deaths), 
            inherit.aes = FALSE, col = base) + 
  geom_line(col = primary) +
  geom_point(col = primary) +
  geom_vline(xintercept = ca_lags$time_value[forecast_time], 
             lty = 2, col = 'gray50') +
  labs(x = "", y = "Deaths per 100k people") +
  scale_y_continuous(expand = expansion(c(0, .05))) +
  theme(legend.title = element_blank())
```

```{r m1-error}
getErrors((ca |> filter(time_value %in% pred_m1$target_date))$deaths, 
          pred_m1$prediction, "lm on lagged cases")
```

## Predictions for different $h$, ARX(1)

```{r plot-m2}
#| fig-width: 8
#| fig-height: 4.5
pred_m2 |>
  ggplot(aes(target_date, prediction, group = forecast_date)) +
  geom_line(data = ca_lags, aes(x = time_value, y = deaths), 
            inherit.aes = FALSE, col = base) + 
  geom_line(col = secondary) +
  geom_point(col = secondary) +
  geom_vline(xintercept = ca_lags$time_value[forecast_time], 
             lty = 2, col = 'gray50') +
  labs(x = "", y = "Deaths per 100k people") +
  scale_y_continuous(expand = expansion(c(0, .05))) +
  theme(legend.title = element_blank())
```

```{r m2-error}
getErrors((ca |> filter(time_value %in% pred_m2$target_date))$deaths, 
          pred_m2$prediction, "ARX(1)")
```


## Visualizing predictions for multiple horizons

Different ways to visualize predictions for multiple $h$

* Last slides: [group by forecast date]{.primary}, and show prediction "trajectories"

* Other approach: [one line and color per horizon]{.primary} $h$

## Predictions by horizon, ARX(1)

```{r weekly-predictions}
pred_m2_week <- data.frame(matrix(NA, nrow = 0, ncol = 3))  #initialize df for predictions
colnames(pred_m2_week) = c("forecast_date", "target_date", "prediction")

# Only forecast on sundays
sundays <- which(ca_lags$time_value >= t0_date & 
                   ca_lags$time_value < ca_lags$time_value[n-max(h_vals)] &
                   wday(ca_lags$time_value) == 1)

for (t in sundays) {
  for (i in seq_along(h_vals)) {
    h = h_vals[i]
    # formulas including h-lagged variables
    m2_formula = as.formula(paste0("deaths ~ lagged_cases_", h, " + lagged_deaths_", h))
    # fit to trailing window of data
    m2_fit = lm(m2_formula, data = ca_lags, subset = (1:n) <= t & (1:n) > (t-w)) 
    # make h-step ahead predictions
    pred_m2_week = rbind(pred_m2_week, 
                         data.frame(forecast_date = ca_lags$time_value[t],
                                    target_date = ca_lags$time_value[t+h],
                                    prediction = predict(m2_fit, 
                                                         newdata = data.frame(ca_lags[t+h, ]))))
    }
}
```

```{r plot-by-h}
#| fig-width: 8
#| fig-height: 4.5
ca_lags |> 
  ggplot() +
  geom_line(aes(x = time_value, y = deaths), col = 'gray50', alpha = .6) +
  geom_line(data = pred_m2_week |> 
              mutate(horizon = as.factor(target_date - forecast_date)),
            aes(target_date, prediction, group = horizon, col = horizon), 
            inherit.aes = FALSE) +
  geom_vline(xintercept = ca_lags$time_value[sundays[1]]) +
  labs(x = "", y = "Deaths per 100k people") +
  scale_colour_viridis_d(option = "inferno", end = .8) +
  scale_y_continuous(expand = expansion(c(0, .05)))
```

# Overfitting and Regularization

## ARX models with 2 and 3 lags

* The [ARX(1)]{.primary} model 
$\hat y_{t+h} = \hat \phi + \hat\phi_0 y_{t} + \hat\beta_0 x_{t}$ 
has good predictive performance

* We will now try to improve the ARX(1) model by including [more lags]{.primary} in the set of predictors

* Let's consider two extensions: the [ARX(2)]{.primary} model

$$\hat y_{t+h} = \hat \phi + \hat\phi_0 y_{t} + \hat\phi_1 y_{t-7} + 
\hat\beta_0 x_{t} + \hat\beta_1 x_{t-7}$$

and the [ARX(3)]{.primary} model

$$\hat y_{t+h} = \hat \phi + \hat\phi_0 y_{t} + \hat\phi_1 y_{t-7} + \hat\phi_2 y_{t-14} +
\hat\beta_0 x_{t} + \hat\beta_1 x_{t-7} + \hat\beta_2 x_{t-14}$$

and fit them using a trailing window with $w = 120$.

## Fit ARX(2) and ARX(3) on trailing window

```{r arx-2-and-3}
#| echo: true
pred_arx2 = pred_arx3 <- rep(NA, length = n)  
w <- 120     #trailing window size
h <- 28      #number of days ahead

# create lagged predictors
ca_lags$lagged_deaths_35 <- dplyr::lag(ca_lags$deaths, n = 35)
ca_lags$lagged_deaths_42 <- dplyr::lag(ca_lags$deaths, n = 42)
ca_lags$lagged_cases_35 <- dplyr::lag(ca_lags$cases, n = 35)
ca_lags$lagged_cases_42 <- dplyr::lag(ca_lags$cases, n = 42)

for (t in t0:(n-h)) {
  arx2_formula = as.formula(paste0("deaths ~ lagged_cases_", h, " + lagged_deaths_", h,
                                  " + lagged_cases_", h+7, " + lagged_deaths_", h+7))
  arx3_formula = as.formula(paste0("deaths ~ lagged_cases_", h, " + lagged_deaths_", h,
                                  " + lagged_cases_", h+7, " + lagged_deaths_", h+7,
                                  " + lagged_cases_", h+14, " + lagged_deaths_", h+14))
  # fit to trailing window of data
  arx2_fit = lm(arx2_formula, data = ca_lags, subset = (1:n) <= t & (1:n) > (t-w-7)) 
  arx3_fit = lm(arx3_formula, data = ca_lags, subset = (1:n) <= t & (1:n) > (t-w-14)) 
  # make h-step ahead predictions
  pred_arx2[t+h] <- max(0, predict(arx2_fit, newdata = data.frame(ca_lags[t+h, ])))
  pred_arx3[t+h] <- max(0, predict(arx3_fit, newdata = data.frame(ca_lags[t+h, ])))
}

```

## Time series CV (trailing): ARX(1), ARX(2), and ARX(3) 

```{r arx-2-and-3-plot-cv-predictions}
#| fig-width: 7
ca |> 
  mutate(observed = deaths, 
         `ARX(1)` = pred_arx1,
         `ARX(2)` = pred_arx2, 
         `ARX(3)` = pred_arx3) |>
  pivot_longer(cols = c(observed, `ARX(1)`, `ARX(2)`, `ARX(3)`), 
               names_to = 'Deaths') |>
  mutate(Deaths = factor(Deaths, 
                         levels = c("observed", "ARX(1)", "ARX(2)", "ARX(3)"))) |>
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line(aes(alpha = ifelse(time_value > t0_date, 1, .5)), key_glyph = "timeseries") + 
  geom_vline(xintercept = t0_date) +    
  geom_vline(xintercept = t0_date + h, lty = 2) +
  geom_vline(xintercept = as.Date("2022-03-31")) +    
  labs(x = "", y = "Deaths per 100k people") +
  theme(legend.title = element_blank()) +
  scale_color_delphi() +
  scale_alpha_identity() +
  scale_y_continuous(expand = expansion(c(0, .05)))
```


```{r arx-1-arx-2-and-3-cv-error}
rbind(getErrors(test_h$deaths, pred_arx1[!is.na(pred_arx1)], "ARX(1)"),
      getErrors(test_h$deaths, pred_arx2[!is.na(pred_arx2)], "ARX(2)"),
      getErrors(test_h$deaths, pred_arx3[!is.na(pred_arx3)], "ARX(3)"))
```

```{r arx-1-arx-2-and-3-no-omicron, eval=FALSE}
omicron_start = which(ca$time_value == as.Date("2022-01-15"))
omicron_end = which(ca$time_value == as.Date("2022-03-31"))
no_omicron = (1:n < omicron_start | 1:n > omicron_end)
rbind(getErrors(ca$deaths[!is.na(pred_arx1) & no_omicron], 
                pred_arx1[!is.na(pred_arx1) & no_omicron], "ARX(1)"),
      getErrors(ca$deaths[!is.na(pred_arx1) & no_omicron], 
                pred_arx2[!is.na(pred_arx2) & no_omicron], "ARX(2)"),
      getErrors(ca$deaths[!is.na(pred_arx1) & no_omicron], 
                pred_arx3[!is.na(pred_arx3) & no_omicron], "ARX(3)"))
```


## Warning!

As we add more predictors, [forecasts]{.primary} seem more [volatile]{.primary} and errors increase.

::: {.callout-important icon="false"}
## **Overfitting**
:::

## Overfitting

When we introduce [too many predictors]{.primary} in the model

* The estimated coefficients will be chosen to mimic the observed data very 
  closely on the training set, leading to [small training error]{.primary}

* The predictive performance on the test set might be very poor, 
  producing [large split-sample and CV error]{.primary}



## Extreme case: ARX model with 120 predictors

* What happens if we increase the number of predictors to 120? 

* Let's fit

$$\hat y_{t+28} = \hat\phi + \hat\phi_0 y_{t} + \hat\phi_1 y_{t-1} + \dots + 
\hat\phi_{59} y_{t-59} + 
\hat\beta_0 x_{t} + \dots + \hat\beta_{t-59} x_{t-59}$$

and compare [training vs split-sample errors]{.primary}


```{r overfit-data}
## Preparing the data
y <- ca$deaths  #outcome
lags <- 28:87   #lags used for predictors (deaths and cases)
h <- 28

# Build predictor matrix with 60 columns
X <- data.frame(matrix(NA, nrow = length(y), ncol = 2*length(lags)))
colnames(X) <- paste('X', 1:ncol(X), sep = '')

for (j in 1:length(lags)) {
  # first 60 columns contain deaths lagged by 28, 29, ..., 87
  X[, j] = dplyr::lag(ca$deaths, lags[j])
  # last 60 columns contain cases lagged by 28, 29, ..., 87
  X[, length(lags) + j] = dplyr::lag(ca$cases, lags[j])
}
```

```{r overfit-lm}
## Fitting the ARX model
# Train/test split
y_train <- y[1:t0]
X_train <- X[1:t0, ]
y_test <- y[(t0+h):length(y)]
X_test <- X[(t0+h):length(y), ]

# Fitting the ARX model
reg = lm(y_train ~ ., data = X_train)
```

## Extreme case: predictions on training and test set 

```{r overfit-pred}
pred_train <- predict(reg)                    #get training predictions
pred_test <- predict(reg, newdata = X_test)   #get test predictions
```

```{r overfit-plot-train-test, eval=FALSE}
#| fig-width: 6
ca |> 
  mutate(observed = deaths, 
         predicted = c(rep(NA, max(lags)), pred_train, rep(NA, h-1), pred_test)) |>
  pivot_longer(cols = c(predicted, observed), names_to = 'Deaths') |>
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line(key_glyph = "timeseries") + 
  geom_vline(xintercept = t0_date) +
  geom_vline(xintercept = t0_date + h, lty = 2) +
  labs(x = "", y = "Deaths per 100k people") +
  theme(legend.title = element_blank()) +
  scale_color_delphi()

```

```{r overfit-train-test-error, eval=FALSE}
errors <- rbind(getErrors(y_train[-(1:max(lags))], pred_train, "training"),
                getErrors(y_test, pred_test, "split-sample"))
errors
```


```{r overfit-plot-train-test-trunc}
#| fig-width: 7
ca |> 
  mutate(observed = deaths, 
         predicted = c(rep(NA, max(lags)), pred_train, rep(NA, h-1), pmax(0, pred_test))) |>
  pivot_longer(cols = c(predicted, observed), names_to = 'Deaths') |>
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line(key_glyph = "timeseries") + 
  geom_vline(xintercept = t0_date) +
  geom_vline(xintercept = t0_date + h, lty = 2) +
  labs(x = "", y = "Deaths per 100k people") +
  theme(legend.title = element_blank()) +
  scale_color_delphi() +
  scale_y_continuous(expand = expansion(c(0, .05)))
```

```{r overfit-train-test-error-trunc}
getErrors(y_test, pmax(0, pred_test), "split-sample")
```


::: {.callout-important icon="false"}
## Note

Some predictions were negative, which doesn't make sense for count data, so we truncated them at 0.
:::


## Back to ARX(1), ARX(2), and ARX(3)

How can we 

* select the "right" number of lags to include? 

* avoid overfitting, while considering a large number of predictors? 


## Regularization

* [Idea]{.primary}: introduce a regularization parameter $\lambda$ that [shrinks or sets]{.primary} some 
of the estimated coefficients to zero, i.e. some predictors are estimated to 
have limited or no predictive power

* Most common regularization methods

  * [Ridge]{.primary}: shrinks coefficients to zero
  
  * [Lasso]{.primary}: sets some coefficients to zero


* Let's predict $h=28$ days ahead by regularizing

  * ARX(1)
  * ARX(2)
  * ARX(3)


## Fit ARX(3) + ridge/lasso for COVID deaths

```{r ridge-lasso-fit}
#| echo: true
library(glmnet) # Implements ridge and lasso

h <- 28
X <- as_tibble(ca_lags) |> select(ends_with("_28"), ends_with("_35"), ends_with("_42"))
y <- ca_lags$deaths

# We'll need to omit NA values explicitly, as otherwise glmnet will complain
X_train <- X[43:t0, ]
y_train <- y[43:t0]

# Ridge regression: set alpha = 0, lambda sequence will be chosen automatically
ridge <- glmnet(X_train, y_train, alpha = 0)
beta_ridge <- coef(ridge)       # matrix of estimated coefficients 
lambda_ridge <- ridge$lambda    # sequence of lambdas used to fit ridge 

# Lasso regression: set alpha = 1, lambda sequence will be chosen automatically
lasso <- glmnet(X_train, y_train, alpha = 1)
beta_lasso <- coef(lasso)       # matrix of estimated coefficients 
lambda_lasso <- lasso$lambda    # sequence of lambdas used to fit lasso 

dim(beta_lasso)                 # One row per coefficient, one column per lambda value
```

```{r lasso-ridge-predictions, eval=FALSE}
## Predictions on test set and best $\lambda$
#| echo: true
X_test <- X[(t0+h):n, ]
y_test <- y[(t0+h):n]

# Predict values for second half of the time series
yhat_ridge <- predict(ridge, newx = as.matrix(X_test))
yhat_lasso <- predict(lasso, newx = as.matrix(X_test))

# Compute MAE 
mae_ridge <- colMeans(abs(yhat_ridge - y_test))
mae_lasso <- colMeans(abs(yhat_lasso - y_test))

# Select index of lambda vector which gives lowest MAE
min_ridge <- which.min(mae_ridge)
min_lasso <- which.min(mae_lasso)

# Get corresponding predictions for train and test sets
pred_train_ridge <- predict(ridge, newx = as.matrix(X_train))[, min_ridge] 
pred_test_ridge <- yhat_ridge[, min_ridge]
pred_train_lasso <- predict(lasso, newx = as.matrix(X_train))[, min_lasso] 
pred_test_lasso <- yhat_lasso[, min_lasso]
```

```{r lasso-ridge-coeff, eval=FALSE}
## Estimated coefficients: shrinkage vs sparsity
# Estimated coefficients
cbind('ridge' = beta_ridge[, min_ridge], 
      'lasso' = beta_lasso[, min_lasso])
```

```{r plot-ridge-lasso-coeff, eval=FALSE}
#| out-height: "600px"
data.frame('x'= 1:nrow(beta_lasso),
           'ridge' = beta_ridge[, min_ridge], 
           'lasso' = beta_lasso[, min_lasso]) |>
  pivot_longer(cols = c('ridge', 'lasso'), names_to = 'Method') |>
  ggplot(aes(x, value, col = Method)) +
  geom_point(alpha = .8) +
  geom_line() +
  xlab('Regressor') + 
  ylab('Estimated coefficient')
```

```{r shrinkage-sparsity, eval=FALSE}
## Predictions: ARX + ridge/lasso (train and test set)
#| fig-width: 7
ca |> 
  mutate(observed = deaths, 
         `predicted (ridge)` = c(rep(NA, 42), pred_train_ridge, 
                                 rep(NA, h-1), pred_test_ridge),
         `predicted (lasso)` = c(rep(NA, 42), pred_train_lasso, 
                                 rep(NA, h-1), pred_test_lasso)) |>
  pivot_longer(cols = c(observed, `predicted (ridge)`, 
                        `predicted (lasso)`), names_to = 'Deaths') |>
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line(key_glyph = "timeseries") + 
  geom_vline(xintercept = t0_date) +
  geom_vline(xintercept = t0_date + h, lty = 2) +
  labs(x = "", y = "Deaths per 100k people") +
  theme(legend.title = element_blank()) +
  scale_color_delphi() +
  scale_y_continuous(expand = expansion(c(0, .05)))
```



## Time series CV (trailing) for ARX(3) + ridge/lasso 

```{r regularization-cv}
#| echo: true
h <- 28  # number of days ahead 
w <- 120 # window length

# Initialize matrices for predictions (one column per lambda value)
yhat_ridge_mat <- matrix(NA, nrow = n, ncol = length(lambda_ridge))
yhat_lasso_mat <- matrix(NA, nrow = n, ncol = length(lambda_lasso)) 
yhat_ridge = yhat_lasso <- rep(NA, length = n)

# Select index of best lambda value on training set
ridge_index = cv.glmnet(as.matrix(X_train), y_train, alpha = 0, lambda = lambda_ridge)$index[1]
lasso_index = cv.glmnet(as.matrix(X_train), y_train, alpha = 1, lambda = lambda_lasso)$index[1]

for (t in t0:(n-h)) {
  # Indices of data within window
  inds = t-w < 1:n & 1:n <= t
  # Fit ARX + ridge/lasso for each lambda value
  ridge_trail = glmnet(X[inds, ], y[inds], alpha = 0, lambda = lambda_ridge)
  lasso_trail = glmnet(X[inds, ], y[inds], alpha = 1, lambda = lambda_lasso)
  # Predict for each lambda value
  yhat_ridge_mat[t+h, ] = predict(ridge_trail, newx = as.matrix(X[(t+h), ]))
  yhat_lasso_mat[t+h, ] = predict(lasso_trail, newx = as.matrix(X[(t+h), ]))
  # Save prediction corresponding to best lambda so far
  yhat_ridge[t+h] = max(0, yhat_ridge_mat[t+h, ridge_index])
  yhat_lasso[t+h] = max(0, yhat_lasso_mat[t+h, lasso_index])
  if (t >= t0+h) {
    # Prediction error
    mae_ridge = colMeans(abs(yhat_ridge_mat[1:(t+1), ] - y[1:(t+1)]), na.rm = T)
    mae_lasso = colMeans(abs(yhat_lasso_mat[1:(t+1), ] - y[1:(t+1)]), na.rm = T)
    # Select index of lambda vector which gives lowest MAE so far
    ridge_index <- which.min(mae_ridge)
    lasso_index <- which.min(mae_lasso)
  }
}
```


## Predictions: time series CV (trailing) for ARX(1) + ridge/lasso 

```{r regularize-arx-1}
#| fig-width: 7
X_arx1 <- as_tibble(ca_lags) |> select(ends_with("_28"))
X_arx1_train <- X_arx1[29:t0, ]
y_arx1_train <- y[29:t0]

ridge_arx1 <- glmnet(X_arx1_train, y_arx1_train, alpha = 0)
lambda_ridge_arx1 <- ridge_arx1$lambda 

lasso_arx1 <- glmnet(X_arx1_train, y_arx1_train, alpha = 1)
lambda_lasso_arx1 <- lasso_arx1$lambda   

yhat_ridge_mat <- matrix(NA, nrow = n, ncol = length(lambda_ridge_arx1))
yhat_lasso_mat <- matrix(NA, nrow = n, ncol = length(lambda_lasso_arx1)) 
yhat_ridge_arx1 = yhat_lasso_arx1 <- rep(NA, length = n)

# Select index of best lambda value on training set
ridge_index = cv.glmnet(as.matrix(X_arx1_train), y_arx1_train, alpha = 0, 
                        lambda = lambda_ridge_arx1)$index[1]
lasso_index = cv.glmnet(as.matrix(X_arx1_train), y_arx1_train, alpha = 1, 
                        lambda = lambda_lasso_arx1)$index[1]

for (t in t0:(n-h)) {
  # Indices of data within window
  inds = t-w < 1:n & 1:n <= t
  # Fit ARX + ridge/lasso for each lambda value
  ridge_trail = glmnet(X_arx1[inds, ], y[inds], alpha = 0, lambda = lambda_ridge_arx1)
  lasso_trail = glmnet(X_arx1[inds, ], y[inds], alpha = 1, lambda = lambda_lasso_arx1)
  # Predict for each lambda value
  yhat_ridge_mat[t+h, ] = predict(ridge_trail, newx = as.matrix(X_arx1[(t+h), ]))
  yhat_lasso_mat[t+h, ] = predict(lasso_trail, newx = as.matrix(X_arx1[(t+h), ]))
  # Save prediction corresponding to best lambda so far
  yhat_ridge_arx1[t+h] = max(0, yhat_ridge_mat[t+h, ridge_index])
  yhat_lasso_arx1[t+h] = max(0, yhat_lasso_mat[t+h, lasso_index])
  if (t >= t0+h) {
    # Prediction error
    mae_ridge = colMeans(abs(yhat_ridge_mat[1:(t+1), ] - y[1:(t+1)]), na.rm = T)
    mae_lasso = colMeans(abs(yhat_lasso_mat[1:(t+1), ] - y[1:(t+1)]), na.rm = T)
    # Select index of lambda vector which gives lowest MAE so far
    ridge_index <- which.min(mae_ridge)
    lasso_index <- which.min(mae_lasso)
  }
}

ca |> 
  mutate(observed = deaths, 
         `ARX(1)` = pred_arx1,
         `ARX(1) + ridge` = yhat_ridge_arx1,
         `ARX(1) + lasso` = yhat_lasso_arx1) |>
  pivot_longer(cols = c(observed, `ARX(1)`, `ARX(1) + ridge`, `ARX(1) + lasso`), 
               names_to = 'Deaths') |>
  mutate(Deaths = factor(Deaths, levels = c("observed", "ARX(1)",
                                            "ARX(1) + ridge", "ARX(1) + lasso"))) |>
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line(aes(alpha = ifelse(time_value > t0_date, 1, .5)), key_glyph = "timeseries") + 
  geom_vline(xintercept = t0_date) +    
  geom_vline(xintercept = t0_date + h, lty = 2) +
  ylim(0, max(pred_arx3, na.rm = T)) +
  labs(x = "", y = "Deaths per 100k people") +
  theme(legend.title = element_blank()) +
  scale_alpha_identity() +
  scale_color_delphi() +
  scale_y_continuous(expand = expansion(c(0, .05)))

```

```{r errors-arx1-regularized}
rbind(getErrors(y_test, pred_arx1[!is.na(pred_arx1)], "ARX(1)"),
      getErrors(y_test, yhat_ridge_arx1[!is.na(yhat_ridge_arx1)], "ARX(1) + ridge"),
      getErrors(y_test, yhat_lasso_arx1[!is.na(yhat_lasso_arx1)], "ARX(1) + lasso"))
```


## Predictions: time series CV (trailing) for ARX(2) + ridge/lasso 

```{r regularize-arx-2}
#| fig-width: 7
X_arx2 <- as_tibble(ca_lags) |> select(ends_with("_28"), ends_with("_35"))
X_arx2_train <- X_arx2[36:t0, ]
y_arx2_train <- y[36:t0]

ridge_arx2 <- glmnet(X_arx2_train, y_arx2_train, alpha = 0)
lambda_ridge_arx2 <- ridge_arx2$lambda 

lasso_arx2 <- glmnet(X_arx2_train, y_arx2_train, alpha = 1)
lambda_lasso_arx2 <- lasso_arx2$lambda   

yhat_ridge_mat <- matrix(NA, nrow = n, ncol = length(lambda_ridge_arx2))
yhat_lasso_mat <- matrix(NA, nrow = n, ncol = length(lambda_lasso_arx2)) 
yhat_ridge_arx2 = yhat_lasso_arx2 <- rep(NA, length = n)

# Select index of best lambda value on training set
ridge_index = cv.glmnet(as.matrix(X_arx2_train), y_arx2_train, alpha = 0, 
                        lambda = lambda_ridge_arx2)$index[1]
lasso_index = cv.glmnet(as.matrix(X_arx2_train), y_arx2_train, alpha = 1, 
                        lambda = lambda_lasso_arx2)$index[1]

for (t in t0:(n-h)) {
  # Indices of data within window
  inds = t-w < 1:n & 1:n <= t
  # Fit ARX + ridge/lasso for each lambda value
  ridge_trail = glmnet(X_arx2[inds, ], y[inds], alpha = 0, lambda = lambda_ridge_arx2)
  lasso_trail = glmnet(X_arx2[inds, ], y[inds], alpha = 1, lambda = lambda_lasso_arx2)
  # Predict for each lambda value
  yhat_ridge_mat[t+h, ] = predict(ridge_trail, newx = as.matrix(X_arx2[(t+h), ]))
  yhat_lasso_mat[t+h, ] = predict(lasso_trail, newx = as.matrix(X_arx2[(t+h), ]))
  # Save prediction corresponding to best lambda so far
  yhat_ridge_arx2[t+h] = max(0, yhat_ridge_mat[t+h, ridge_index])
  yhat_lasso_arx2[t+h] = max(0, yhat_lasso_mat[t+h, lasso_index])
  if (t >= t0+h) {
    # Prediction error
    mae_ridge = colMeans(abs(yhat_ridge_mat[1:(t+1), ] - y[1:(t+1)]), na.rm = T)
    mae_lasso = colMeans(abs(yhat_lasso_mat[1:(t+1), ] - y[1:(t+1)]), na.rm = T)
    # Select index of lambda vector which gives lowest MAE so far
    ridge_index <- which.min(mae_ridge)
    lasso_index <- which.min(mae_lasso)
  }
}

ca |> 
  mutate(observed = deaths, 
         `ARX(2)` = pred_arx2,
         `ARX(2) + ridge` = yhat_ridge_arx2,
         `ARX(2) + lasso` = yhat_lasso_arx2) |>
  pivot_longer(cols = c(observed, `ARX(2)`, `ARX(2) + ridge`, `ARX(2) + lasso`), 
               names_to = 'Deaths') |>
  mutate(Deaths = factor(Deaths, levels = c("observed", "ARX(2)",
                                            "ARX(2) + ridge", "ARX(2) + lasso"))) |>
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line(aes(alpha = ifelse(time_value > t0_date, 1, .5)), key_glyph = "timeseries") + 
  geom_vline(xintercept = t0_date) +    
  geom_vline(xintercept = t0_date + h, lty = 2) +
  labs(x = "", y = "Deaths per 100k people") +
  ylim(0, max(pred_arx3, na.rm = T)) +
  theme(legend.title = element_blank()) +
  scale_color_delphi() +
  scale_alpha_identity() +
  scale_y_continuous(expand = expansion(c(0, .05)))
```

```{r errors-arx2-regularized}
rbind(getErrors(y_test, pred_arx2[!is.na(pred_arx2)], "ARX(2)"),
      getErrors(y_test, yhat_ridge_arx2[!is.na(yhat_ridge_arx2)], "ARX(2) + ridge"),
      getErrors(y_test, yhat_lasso_arx2[!is.na(yhat_lasso_arx2)], "ARX(2) + lasso"))
```



## Predictions: time series CV (trailing) for ARX(3) + ridge/lasso 

```{r plot-arx3-regularization-cv}
#| fig-width: 7
ca |> 
  mutate(observed = deaths, 
         `ARX(3)` = pred_arx3,
         `ARX(3) + ridge` = yhat_ridge,
         `ARX(3) + lasso` = yhat_lasso) |>
  pivot_longer(cols = c(observed, #`ARX(1)`, 
                        `ARX(3)`, `ARX(3) + ridge`, `ARX(3) + lasso`), 
               names_to = 'Deaths') |>
  mutate(Deaths = factor(Deaths, levels = c("observed", "ARX(1)", "ARX(3)",
                                            "ARX(3) + ridge", "ARX(3) + lasso"))) |>
  ggplot(aes(time_value, value, col = Deaths)) +
  geom_line(aes(alpha = ifelse(time_value > t0_date, 1, .5)), key_glyph = "timeseries") + 
  geom_vline(xintercept = t0_date) +    
  geom_vline(xintercept = t0_date + h, lty = 2) +
  labs(x = "", y = "Deaths per 100k people") +
  ylim(0, max(pred_arx3, na.rm = T)) +
  theme(legend.title = element_blank()) +
  scale_color_delphi() +
  scale_alpha_identity() +
  scale_y_continuous(expand = expansion(c(0, .05)))
```


```{r arx3-regularization-cv-errors}
rbind(getErrors(y_test, pred_arx3[!is.na(pred_arx3)], "ARX(3)"),
      getErrors(y_test, yhat_ridge[!is.na(yhat_ridge)], "ARX(3) + ridge"),
      getErrors(y_test, yhat_lasso[!is.na(yhat_lasso)], "ARX(3) + lasso"))
```

## Comparison of regularized ARX(1), ARX(2), and ARX(3)

* Best model: ARX(1) + ridge

* Second best: ARX(3) + lasso

* Ridge worsens as more predictors are included

* Lasso improves as more predictors are included


# Prediction Intervals

## Point predictions vs intervals 

* So far, we have only considered [point predictions]{.primary}, i.e. 
we have fitted models 
to provide our [best guess on the outcome]{.primary} at time $t+h$. 

::: {.callout-important icon="false"}
## 
What if we want to provide a [measure of uncertainty]{.primary} around the point 
prediction or a [likely range of values]{.primary} for the outcome at time $t+h$?

:::

* For each target time $t+h$, we can construct [prediction intervals]{.primary}, i.e. provide 
ranges of values that are expected to cover the true outcome value a fixed 
fraction of times.

## Prediction intervals for `lm` fits

* To get prediction intervals for the models we previously fitted, 
we only need to tweak our call to `predict` by adding as an input: 

  `interval = "prediction", level = p`

  where $p \in (0, 1)$ is the desired coverage.

* The output from `predict` will then be a matrix with 

  * first column a [point estimate]{.primary}
  
  * second column the [lower limit]{.primary} of the interval
  
  * third column the [upper limit]{.primary} of the interval


## Prediction intervals for ARX (CV, trailing window)

```{r arx-intervals-time-series-cv}
#| echo: true
# Initialize matrices to store predictions 
# 3 columns: point estimate, lower limit, and upper limit
pred_interval_lm <- matrix(NA, nrow = n, ncol = 3)
colnames(pred_interval_lm) <- c('prediction', 'lower', 'upper')

for (t in t0:(n-h)) {
  # Fit ARX and predict
  arx_trailing = lm(deaths ~ lagged_deaths + lagged_cases, data = ca, 
                    subset = (1:n) <= t & (1:n) > (t-w)) 
  pred_interval_lm[t+h, ] = pmax(0, 
                              predict(arx_trailing, newdata = data.frame(ca[t+h, ]),
                                      interval = "prediction", level = 0.8))
}
```

## Prediction intervals for ARX (CV, trailing window)

```{r plot arx-intervals-cv-trailing}
#| fig-width: 7
lm_pred_trailing <- cbind(ca, pred_interval_lm)

lm_pred_trailing |>
  mutate(observed = deaths, 
         `predicted (CV + trailing)` = prediction) |>
  pivot_longer(cols = c(observed, `predicted (CV + trailing)`), 
               names_to = 'Deaths') |>
  ggplot(aes(time_value, value)) +
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = .3, fill = primary) +
  geom_line(aes(col = Deaths, alpha = ifelse(time_value > t0_date, 1, .5)), key_glyph = "timeseries") + 
  geom_vline(xintercept = t0_date) +
  geom_vline(xintercept = t0_date + h, lty = 2) +
  labs(x = "", y = "Deaths per 100k people") +
  theme(legend.title = element_blank()) +
  scale_color_delphi() +
  scale_alpha_identity() +
  scale_y_continuous(expand = expansion(c(0, .05)))
```

```{r lm-errors-arx}
getErrors(y_test, pred_interval_lm[!is.na(pred_interval_lm)], "lm.trailing")
```

## Expected vs actual coverage

* We would [expect]{.primary} the ARX model to [cover]{.primary} the truth
about [80\%]{.primary} of the times. Is this actually true in practice?

* The actual coverage of the predictive intervals is [lower]{.primary}:

```{r lm-coverage-all-past}
data.frame("Actual" = round(mean(ca$deaths >= lm_pred_trailing$lower & 
                                   ca$deaths <= lm_pred_trailing$upper, na.rm = T), 2),
           "Expected" = 0.80,
           row.names = "Coverage")
```

* We can use [calibration]{.primary} to handle under-covering (more on this in the afternoon)



# Forecasting with Versioned Data

## Versioned data

So far: data never revised 
(or simply ignored revisions, `as_of` today)

::: {.callout-important icon="false"}
## 
How can we [train forecasters]{.primary} when dealing with [versioned data]{.primary}?
:::

```{r get-versioned-data}
source(here::here("_code/ca_versioned.R"))
```

```{r versioned-data}
#| echo: true
ca_archive
```

## Version-aware forecasting

[Important]{.primary}: when fitting and predicting, only use data in the latest 
version available at the forecast date!

## Version-aware forecasting

```{r versioned-weekly-avg}
fc_time_values <- seq(
  from = t0_date,
  to = as.Date("2023-02-09"),
  by = "1 week"
)

ca_archive <- ca_archive |>
  epix_slide(
    .before = Inf, 
    .versions = fc_time_values,
    function(x, gk, rtv) {
      x |>
        group_by(geo_value) |>
        epi_slide_mean(case_rate, .window_size = 7L, .suffix = "_7d_av") |>
        epi_slide_mean(death_rate, .window_size = 7L, .suffix = "_7d_av") |>
        ungroup()
    }
  ) |>
  rename(
    cases = case_rate_7d_av,
    deaths = death_rate_7d_av
  ) |>
  select(version, time_value, geo_value, cases, deaths) |>
  as_epi_archive(compactify = TRUE)

ca_archive <- ca_archive$DT |> 
  as_epi_archive()
```


```{r versioned-reg}
#| echo: true
# initialize dataframe for predictions
# 5 columns: forecast date, target date, 10%, 50%, and 90% quantiles
pred_aware <- data.frame(matrix(NA, ncol = 5, nrow = 0))

w <- 120         #trailing window size
h <- 28          #number of days ahead

# forecast once a week
fc_time_values <- seq(from = t0_date, to = as.Date("2023-02-09"), by = "1 week")

for (fc_date in fc_time_values) {
  # get data version as_of forecast date
  data <- epix_as_of(ca_archive, version = as.Date(fc_date))
  # create lagged predictors
  data$lagged_deaths <- dplyr::lag(data$deaths, h) 
  data$lagged_cases <- dplyr::lag(data$cases, h)
  # perform regression
  lm_weekly <- lm(deaths ~ lagged_deaths + lagged_cases, 
                  # only consider window of data
                  data = data |> filter(time_value > (max(time_value) - w))) 
  # construct data.frame with the right predictors for the target date
  predictors <- data.frame(lagged_deaths = tail(data$deaths, 1), 
                           lagged_cases = tail(data$cases, 1))
  # make predictions for target date and add them to dataframe of predictions
  pred_aware <- rbind(pred_aware, 
                      data.frame('forecast_date' = max(data$time_value),
                                 'target_date' = max(data$time_value) + h, 
                                 t(pmax(0, predict(lm_weekly, newdata = predictors,
                                                   interval = "prediction", level = 0.8)))))
}
```


## Version-aware predictions (CV, trailing)

```{r clean-data-output}
# clean output and join it with finalized values (`ca` dataset)
pred_aware <- pred_aware |>
  rename(median = X1, lower = X2, upper = X3) |>
  full_join(ca |> select(time_value, deaths), join_by(target_date == time_value)) |>
  arrange(target_date)
```

```{r plot-versioned-cv-trailing}
#| fig-width: 7
pred_aware |>
  drop_na(median) |>
  ggplot(aes(x = target_date, median)) +
  geom_line(data = ca, aes(x = time_value, y = deaths), inherit.aes = FALSE, col = base) + 
  geom_ribbon(aes(ymin = lower, ymax = upper), alpha = .3, fill = primary) +
  geom_line(col = primary) +
  geom_vline(xintercept = t0_date) +    
  geom_vline(xintercept = t0_date + h, lty = 2) +
  labs(x = "", y = "Deaths per 100k people") +
  theme(legend.title = element_blank()) +
  scale_y_continuous(expand = expansion(c(0, .05)))
```


```{r versioned-cv-errors}
getErrors(pred_aware$deaths[!is.na(pred_aware$median)], 
          pred_aware$median[!is.na(pred_aware$median)], "version-aware")
```

## Version-unaware predictions (CV, trailing)

```{r version-unaware-reg}
pred_unaware <- data.frame(matrix(NA, ncol = 5, nrow = 0))

for (fc_date in fc_time_values) {
  t = which(ca$time_value == fc_date)
  lm_unaware <- lm(deaths ~ lagged_deaths + lagged_cases, data = ca, 
                   subset = (1:n) <= t & (1:n) > (t-w)) 
  pred_unaware <- rbind(pred_unaware, 
                        data.frame('forecast_date' = as.Date(fc_date),
                                   'target_date' = as.Date(fc_date) + h, 
                                   t(pmax(0, predict(lm_unaware, newdata = data.frame(ca[t+h, ]),
                                                     interval = "prediction", level = 0.8)))))
}
```

```{r plot-version-unaware-cv-trailing}
#| fig-width: 7
pred_unaware |>
  drop_na(X1) |>
  ggplot(aes(x = target_date, X1)) +
  geom_line(data = ca, aes(x = time_value, y = deaths), inherit.aes = FALSE, col = base) + 
  geom_ribbon(aes(ymin = X2, ymax = X3), alpha = .3, fill = primary) +
  geom_line(col = primary) +
  geom_vline(xintercept = t0_date) +    
  geom_vline(xintercept = t0_date + h, lty = 2) +
  labs(x = "", y = "Deaths per 100k people") +
  theme(legend.title = element_blank()) +
  scale_y_continuous(expand = expansion(c(0, .05)))
```

```{r qr-errors-unaware}
getErrors((ca |> filter(time_value %in% (fc_time_values+h)))$deaths, 
          pred_unaware$X1, "version-unaware")
```

# Traditional Approaches to Time Series 

## Popular forecasting frameworks

- Autoregressive integrated model average (ARIMA) models
- Exponential smoothing with trend and seasonality (ETS) 
- Prophet forecaster
- DeepAR (neural network)

First two here are classic and standard, second two are more recent. None are 
particularly well-suited for epi forecasting out-of-the-box, ask us about them
if you're curious. We'll discuss ARIMA as it's closest to what we've seen.

## Dissecting ARIMA 

- AR = autoregressive, include lags of response itself as features
- MA = moving average, include lags of noise terms (correlated noise model)
- I = integrated, we model and forecast differences between observations

## Discussion

Worth comparing and discussing ARIMA versus the kind of autoregressive models 
you've just seen:

- The way lags are handled:
    * In what you've seen, we can include arbitrary lags (and regularize)
    * Traditional AR models require lags to be contiguous (e.g., all of 0-17, 
    instead of 0, 7, 14)
- The way multi-step forecasts are made: 
    * In what you've seen, we model h-step ahead directly 
    * Traditional AR models only do 1-step ahead prediction, and iterate this 
    to get forecasts at longer horizons

## Discussion

- The way nonstationarity is handled: 
    * In what you've seen, we address nonstationarity via trailing training 
    windows (or observation weights more generally)
    * Traditional ARIMA models use the I component for this: remove linear or
    quadratic trends by differences, add them back in at prediction time
- The way exogenous features are included: 
    * In what you've seen, they appear directly as an exogenous predictor
    * Traditional ARIMA models (software, such as `fable()`) includes them in 
    a different manner; they are effectively subject to the same lags as the AR
    and MA terms

## Supplementary resources

- Hyndman and Athanasopoulos, [Forecasting: Principles and Practice](https://otexts.com/fpp3/)
- Ryan's course notes, [Introduction to Time Series](https://stat153.berkeley.edu/fall-2024/)

<!--
## ETS

### Simple Exponential Smoothing (SES)

* The $h$-step ahead prediction is a weighted average of the current 
observation $y_t$ and the forecast $\hat y_{t|t-1}$:

$$\hat y_{t+h|t} = \alpha y_t + (1- \alpha) \hat y_{t|t-1}$$

where $\alpha \in [0,1]$

* [Forecasts are flat]{.primary}, i.e. do not depend on $h$

* If $\alpha = 1$, we retrieve the [naive flatline]{.primary} forecaster

$$ y_{t+h|t} = y_t$$


## ETS

### Simple Exponential Smoothing (SES)

* The SES forecast can be re-expressed as

$$\hat y_{t+h|t} = \alpha y_t + \alpha (1- \alpha) y_{t-1}  + \alpha (1- \alpha)^2 y_{t-2} + \dots$$

i.e. observations [$y_{t-k}$]{.primary}  that are $k$ steps into the past are [exponentially 
down-weighted]{.primary}, with weight $(1- \alpha)^2$. Hence the name exponential smoothing.

* [Component form]{.primary} of the SES forecast

\begin{align*}
\hat y_{t+h | t} & = l_t \\
l_t & = \alpha y_t + (1- \alpha) l_{t-1}
\end{align*}

## ETS

### Holt's linear trend method

* Expands SES component form by introducing a [trend]{.primary} $b_t$

\begin{align*}
\hat y_{t+h | t} &= l_t + b_t h\\
l_t &= \alpha y_t + (1- \alpha) (l_{t-1} + b_{t-1}) \\
b_t & = \beta (l_{t} - l_{t-1}) + (1-\beta) b_{t-1}
\end{align*}

where $\alpha, \beta \in [0,1]$.

* [Forecasts are linear]{.primary} in $h$, with slope $b_t$.

::: {.callout-important icon="false"}
## Note

Linear trend forecasts can be erratic for large $h$!
:::


## ETS

### Damped Holt's method

* Introduces a parameter $\phi$ to [dampen the forecast trajectory]{.primary} 

\begin{align*}
\hat y_{t+h | t} &= l_t + b_t (\phi +\phi^2 + \dots + \phi^h)\\
l_t &= \alpha y_t + (1- \alpha) (l_{t-1} + b_{t-1}\phi) \\
b_t & = \beta (l_{t} - l_{t-1}) + (1-\beta) b_{t-1}\phi
\end{align*}

where $\alpha, \beta, \phi \in [0,1]$

* Contribution of slope $b_t$ to a forecast diminishes at each step into the 
future, by a multiplicative factor $\phi$

* As $h\to \infty$, forecasts approach a constant level

$$ y_{t+h | t} \to l_t + b_t \sum_{j=1}^\infty \phi^j = l_t + b_t \frac{\phi}{1-\phi}$$

## ARIMA

### AR(p)

Auto-regressive model of order $p$

$$y_t = \sum_{j=1}^p \phi_j y_{t-j} + w_t$$

### MA(q)

Moving average model of order $q$

$$y_t = w_t + \sum_{j=1}^q \theta_j w_{t-j} $$

where $w_t$ is a white noise sequence, i.e. 
$\mathbb{E}(w_t)=0$ and $\text{Var}(w_t)=\sigma^2$ for all $t$, and 
$\text{Cov}(w_s, w_t)=0$ for all $s \neq t$


## ARIMA

### ARMA(p, q)

$$y_t = \sum_{j=1}^p \phi_j y_{t-j} + \sum_{j=0}^q \theta_j w_{t-j} $$

with $\theta_0 = 1$

### ARIMA(p, d, q)

Assumes an $ARMA(p, q)$ model on the 
$d^{th}$-order differences of $y_t$
-->
