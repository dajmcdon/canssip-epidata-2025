---
org: "CANSSI Prairies &mdash; Epi Forecasting Workshop 2025"
title: "Data Cleaning, Versioning, Nowcasting with [{epiprocess}]{.monotype}"
subtitle: "Lecture 2"
short-title: "Nowcasting"
format: revealjs
---

```{r setup}
#| cache: false
source(here::here("slides", "_code", "setup.R"))
library(epidatr)
library(epipredict)
library(epidatasets)
asciicast::init_knitr_engine(
  startup = quote({
    suppressPackageStartupMessages(library(epiprocess))
  }),
  echo = TRUE,
  echo_input = FALSE
)
```


## Outline


1. Signal processing with `{epiprocess}`

1. Exploring signals

1. Basic Nowcasting using `{epiprocess}`

1. Nowcasting with One Variable

1. Nowcasting with Two Variables

1. Case Study - Nowcasting Cases Using %CLI




## Now that you have data, what do you do with it? {.nostretch}


![R4DS by Wickham, Ã‡etinkaya-Rundel, and Grolemund](https://r4ds.hadley.nz/diagrams/data-science/base.png){width=600}

::: {.fragment}
### Complications

* Usually panel data (multiple locations at once)

* Usually accessing in real time

* Data have revisions

* Data are reported irregularly, `NA`'s are frequent

* Individual streams have high signal-to-noise ratio
:::

::: {.fragment .box-text .absolute top=50%}
[Result:]{.secondary} spend lots of time doing processing and dealing with corner behaviour
:::

```{r download-api-data}
#| eval: false
#| include: false
cases_df_api <- pub_covidcast(
  source = "jhu-csse",
  signals = "confirmed_incidence_num",
  geo_type = "state",
  time_type = "day",
  geo_values = "ca,nc,ny",
  time_values = epirange(20220301, 20220331),
  as_of = as.Date("2024-01-01")
)
write_rds(cases_df_api, here::here("_data", "cases_df_api.rds"))

bc_linelist <- CanCovidData::get_british_columbia_case_data()
write_rds(bc_linelist, here::here("_data", "bc_linelist.rds"))
can_deaths <- read_csv("https://raw.githubusercontent.com/ccodwg/CovidTimelineCanada/refs/heads/main/data/hr/deaths_hr.csv")
can_cases <- read_csv("https://raw.githubusercontent.com/ccodwg/CovidTimelineCanada/refs/heads/main/data/hr/cases_hr.csv")
hr_crosswalk <- read_csv("https://raw.githubusercontent.com/ccodwg/CovidTimelineCanada/refs/heads/main/geo/hr.csv") |>
  select(region, hruid, name_short, pop)
can_cases_deaths <- full_join(
  can_cases |> select(region, sub_region_1, time_value = date, cases = value_daily),
  can_deaths |> select(region, sub_region_1, time_value = date, deaths = value_daily)
) |> left_join(hr_crosswalk |> select(hruid, name_short), by = join_by(sub_region_1 == hruid)) |>
  select(region, hr = name_short, time_value, cases, deaths) |>
  replace_na(list(hr = "Other", deaths = 0))
write_rds(can_cases_deaths, here::here("_data", "can_cases_deaths.rds"))
write_rds(hr_crosswalk, here::here("_data", "can_hr_crosswalk.rds"))
```

```{r load-data}
#| echo: false
# bc_linelist <- read_rds(here::here("_data", "bc_linelist.rds"))
cases_df_api <- read_rds(here::here("_data", "cases_df_api.rds"))
can_cases_deaths <- read_rds(here::here("_data", "can_cases_deaths.rds"))
hr_crosswalk <- read_rds(here::here("_data", "can_hr_crosswalk.rds"))
prov_pop <- summarise(hr_crosswalk, pop = sum(pop), .by = region)
cases_df <- cases_df_api |> 
  select(time_value, geo_value, raw_cases = value)

case_rates_df <- cases_df |>
  left_join(state_census |> select(abbr, pop), join_by(geo_value == abbr)) |>
  mutate(scaled_cases = raw_cases / pop * 1e5, pop = NULL)
```

## R packages we maintain to facilitate typical analyses


![](gfx/epiverse_packages_flow.jpg)

# Signal processing with [{epiprocess}]{.monotype} {.inverse}
  
## `{epiprocess}` Data Structures

### `epi_df`: snapshot of a data set

* a tibble with a couple of required columns, `geo_value` and `time_value`.
* arbitrary additional columns containing measured values, called [signals]{.secondary}
* additional [keys]{.secondary} that index subsets (health region, `age_group`, `ethnicity`, etc.)

::: {.callout-note}
## `epi_df`

Represents a [snapshot]{.secondary} that
contains the most [up-to-date values]{.secondary} of the signal variables, 
[as of]{.secondary} a given time.
:::

<!--

## Example, linelist to `epi_df`

```{r bc-linelist}
#| eval: false
bc_linelist |> head(3)
```

```{r bc-linelist-edf}
#| echo: true
#| eval: false
bc_linelist |>
  rename(time_value = `Reported Date`, geo_value = `Health Authority`) |>
  count(time_value, geo_value, name = "cases") |>
  as_epi_df()
```

-->
  

## `epi_df`: Snapshot of a dataset

```{r extra-junk}
#| include: false
#| eval: false
base_url <- "https://raw.githubusercontent.com/dajmcdon/rvdss-canada/main/data/"
one_season <- "season_2024_2025/positive_tests.csv"
positive_tests <- read_csv(paste0(base_url, one_season), col_types = cols_only(
  geo_value = col_character(), time_value = col_date(), issue = col_date(), flu_pct_positive = col_double()
)) |> filter(
  geo_value %in% c("atlantic", "bc", "on", "qc", "prairies", "territories")
)
earch1 <- as_epi_archive(positive_tests)
edf1 <- earch1 |> epix_as_of(version = max(positive_tests$issue))
```

```{r can-edf}
#| echo: true
#| code-line-numbers: 1-3|4
can_edf <- can_cases_deaths |>
  rename(geo_value = region) |>
  as_epi_df(as_of = "2024-04-13", other_keys = "hr")
can_edf
```


## Examples of signal processing

<br><br>

1. Making locations commensurate (per capita scaling)
1. Correlating signals across location or time 
1. Computing growth rates
1. Detecting and removing outliers
1. Calculating summaries with rolling windows
1. Dealing with revisions 

## Warm up: plotting

```{r plot-edf}
#| echo: true
#| fig-width: 7
#| code-line-numbers: 1-3
can_edf |>
  filter(geo_value == "MB") |>
  autoplot(cases, deaths) +
  scale_y_continuous(name = "", expand = expansion(c(0, .05))) + xlab("") + scale_color_delphi(name = "")
```

::: {.fragment .box-text .absolute top=20% left=20%}
Weird reporting behaviour.

* MB stopped reporting deaths by HR.
* Put them all in "Other"
* Lots of missing values
:::

## Warm up: handling missingness

Two types of missing data

1. Explicit missingness means that there's an `NA`
2. Implicit missingness means that a combination of `time_value` and `geo_value` is not in the data.

```{r fix-missingness}
#| code-line-numbers: 2
#| echo: true
can_edf <- can_edf |>
  complete(time_value = full_seq(time_value, period = 1), fill = list(cases = 0, deaths = 0)) 
can_edf
```

## Warm up: aggregating

```{r can-agg}
#| echo: true
#| code-line-numbers: 2
can_prov <- can_edf |>
  sum_groups_epi_df(c("cases", "deaths"), group_cols = "geo_value")
can_prov
```



## Warm up: per capita scaling

```{r edf-rates}
#| echo: true
#| code-line-numbers: 1-2|3
can_prov <- can_prov |>
  inner_join(prov_pop, by = join_by(geo_value == region)) |>
  mutate(case_rate = cases / pop * 1e5, death_rate = deaths / pop * 1e6) |>
  select(-pop)
```

```{r plot-can-prov}
#| fig-width: 7
can_prov |>
  autoplot(case_rate, death_rate) +
  scale_y_continuous(name = "", expand = expansion(c(0, .05))) +
  xlab("") +
  guides(colour = guide_legend(ncol = 2))
```

::: {.fragment .absolute .box-text top=5% left=5%}
* Negative incidence is often due to cummulatives being differenced
* But sometimes due to correcting an error. 
* With luck, the source would make an adjustment.

```{r negative-deaths}
can_prov |> select(geo_value:deaths) |> filter(deaths < 0)
```

:::

# Exploring signals {.inverse}

## Correlations at different lags (province-level)

```{r corr-lags-ex}
#| echo: true
cor0 <- epi_cor(can_prov, case_rate, death_rate, cor_by = geo_value)
cor14 <- epi_cor(can_prov, case_rate, death_rate, cor_by = geo_value, dt1 = -14)
```

```{r plot-corr-lags-ex}
#| fig-width: 7
bind_rows(`0` = cor0, `14` = cor14, .id = "lag") |>
  mutate(lag = fct_relabel(factor(lag), ~ paste(.x, "days"))) |>
  ggplot(aes(lag, cor, fill = geo_value)) +
  coord_flip() +
  geom_dotplot(binaxis = "y", stackdir = "center", binwidth = 1/20, stackgroups = TRUE, method = "histodot") +
  labs(y = "Correlation", x = "Lag") +
  scale_fill_viridis_d(option = "B", guide = guide_legend(ncol = 2)) +
  theme(legend.position = "right")
```

::: {.fragment .box-text .absolute top=20% left=5%}
* Are case and death rates linearly associated across all days for each geography?

* Deaths and cases likely not contemporaneous, expect cases to precede deaths.
:::

## Lag analysis more systematically


```{r can-cors}
#| echo: true
#| code-line-numbers: 1|2|5
lags <- 0:35
can_lag_cors <- map(lags, \(l) epi_cor(can_prov, case_rate, death_rate, cor_by = geo_value, dt1 = -l)) |>
  set_names(lags) |> 
  list_rbind(names_to = "lag") |>
  summarize(mean_cor = mean(cor, na.rm = TRUE), .by = lag) |>
  mutate(lag = as.numeric(lag))
```

```{r plot-can-cors}
#| fig-width: 7
can_lag_cors |> 
  ggplot(aes(x = lag, y = mean_cor)) +
  geom_vline(xintercept = can_lag_cors$lag[which.max(can_lag_cors$mean_cor)], color = primary) + 
  geom_line(color = secondary) +
  geom_point(color = secondary) +
  scale_x_continuous(expand = expansion()) +
  labs(x = "Lag", y = "Correlation over time\naveraged over space")
```

::: {.fragment .absolute .box-text left=10% top=20%}
* Really strong weekly pattern. But we can fix that. More in a moment
:::

## Quickly compute rolling functions by group

```{r can-7dav}
#| echo: true
#| code-line-numbers: 1-2|5
# trailing by default, new names are automatically created
can_prov <- epi_slide_mean(can_prov, c(case_rate, death_rate), .window_size = 7L)
can_lag_cors <- map(
  lags, 
  \(l) epi_cor(can_prov, case_rate_7dav, death_rate_7dav, cor_by = geo_value, dt1 = -l)
)
```

```{r can-cors-again}
#| fig-width: 7
can_lag_cors |> 
  set_names(lags) |> 
  list_rbind(names_to = "lag") |>
  summarize(mean_cor = mean(cor, na.rm = TRUE), .by = lag) |>
  mutate(lag = as.numeric(lag)) |>
  ggplot(aes(x = lag, y = mean_cor)) +
  geom_vline(aes(xintercept = lag[which.max(mean_cor)]), color = primary) + 
  geom_line(color = secondary) +
  geom_point(color = secondary) +
  scale_x_continuous(expand = expansion()) +
  labs(x = "Lag", y = "Correlation over time\naveraged over space")
```


## Notes on lagged correlations

<br>
Trailing average pushes the correlation [backward]{.secondary}

<br>
But weekly reporting aggregates incidence [forward]{.primary}

<br>
These may roughly offset, but better if you know the probability of reports and
deconvolve  
[more on this later]{.small .grey}

<br>
We were only averaging over 13 provinces + territories

<br>
Implicitly assuming that reporting / testing / disease behaviour is stable over
4 years

## Compare to the US


```{r us-cor}
#| echo: true
#| code-line-numbers: 1-2
# Only consider the 50 US states (no territories)
us_edf <- covid_case_death_rates |> filter(geo_value %in% tolower(state.abb)) 
cor0 <- epi_cor(us_edf, case_rate, death_rate, cor_by = geo_value)
cor14 <- epi_cor(us_edf, case_rate, death_rate, cor_by = geo_value, dt1 = -14)
```

```{r us-cor-plot}
#| fig-width: 7
bind_rows(`0` = cor0, `14` = cor14, .id = "lag") |>
  mutate(lag = fct_relabel(factor(lag), ~ paste(.x, "days"))) |>
  ggplot(aes(cor)) +
  geom_density(aes(fill = lag, col = lag), alpha = 0.5) +
  scale_fill_delphi() +
  scale_color_delphi() +
  scale_y_continuous(expand = expansion(c(0, .05))) +
  scale_x_continuous(expand = expansion(0), limits = c(0, 1)) +
  labs(x = "Correlation", y = "Density", fill = "Lag", col = "Lag") +
  theme(legend.position = "right")
```


## Compare to the US

<br><br>

```{r sys-lag-ex}
#| fig-width: 7
map(lags, \(lag) epi_cor(us_edf, case_rate, death_rate, cor_by = geo_value, dt1 = -lag)) |>
  set_names(lags) |> 
  list_rbind(names_to = "lag") |>
  summarize(mean_cor = mean(cor, na.rm = TRUE), .by = lag) |>
  mutate(lag = as.numeric(lag)) |>
  ggplot(aes(x = lag, y = mean_cor)) +
  geom_vline(xintercept = can_lag_cors$lag[which.max(can_lag_cors$mean_cor)], color = primary) + 
  geom_line(color = secondary) +
  geom_point(color = secondary) +
  labs(x = "Lag", y = "Correlation over time\naveraged over space")
```

::: {.fragment .box-text .absolute top=30% left=10%}
Aggregate cases tend to lead deaths by &#8776;23 days (arg max $\rho$)

<br>
Same was true for Canada after smoothing, but lower correlation
:::

## Compute growth rates


```{r growth-rates-ex}
#| echo: true
#| code-line-numbers: 2
edfg <- filter(can_prov, geo_value %in% c("MB", "BC"), !is.na(case_rate_7dav)) |>
  mutate(gr_cases = growth_rate(case_rate_7dav, time_value, method = "linear_reg", h = 21L), .by = geo_value)
```

```{r plot-growth-rates-ex}
#| fig-width: 7
edf <- us_edf
gr1 <- edfg |>
  filter(between(time_value, ymd("2020-06-01"), ymd("2023-06-01"))) |>
  ggplot(aes(time_value)) +
  geom_ribbon(aes(ymin = 0, ymax = pmax(case_rate_7dav, 0), fill = geo_value)) +
  scale_fill_delphi() +
  ylab("Case rate\n(7 day avg.)") + xlab("") +
  facet_wrap(~geo_value) +
  scale_y_continuous(expand = expansion(c(0, 0.05))) +
  theme(legend.position = "none", axis.text.x = element_blank(), axis.ticks.x = element_blank())
  
gr2 <- edfg |>
  filter(between(time_value, ymd("2020-06-01"), ymd("2023-06-01"))) |>
  ggplot(aes(x = time_value)) +
  facet_grid(~ geo_value) +
  ylab("Growth rate") + xlab("") +
  geom_hline(yintercept = 0, alpha = .8) +
  geom_line(aes(y = gr_cases, color = geo_value)) +
  scale_color_delphi() +
  theme(legend.position = "none", strip.background = element_blank(),
  strip.text.x = element_blank())
cowplot::plot_grid(gr1, gr2, align = "v", ncol = 1, axis = "lr")
```

## Outlier detection


```{r outlier-query}
outliers <- pub_covidcast("jhu-csse", "confirmed_incidence_num", "state", "day",
                          geo_values = "fl,nj", as_of = "20210601") |>
  select(time_value, geo_value, cases = value) |>
  as_epi_df(as_of = "2021-06-01")
```

```{r outlier-ex}
#| echo: true
outliers <- outliers |>
  mutate(detect_outlr_rm(time_value, cases), .by = geo_value)
```


```{r plot-outlier-ex}
#| fig-width: 7
outp1 <- outliers |> 
  ggplot(aes(x = time_value)) +
  geom_line(aes(y = cases, color = geo_value)) +
  geom_line(aes(y = lower), color = primary, alpha = .6) +
  geom_line(aes(y = upper), color = primary, alpha = .6) +
  scale_color_manual(name = "", values = c(secondary, tertiary), guide = "none") +
  geom_hline(yintercept = 0) + xlab("") + ylab("Confirmed cases") +
  facet_wrap(~ geo_value, scales = "free_y", nrow = 1) +
  scale_x_date(date_breaks = "6 months", date_labels = "%b %Y", expand = expansion(0)) +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
outp2 <- outliers |> 
  ggplot(aes(x = time_value)) +
  geom_line(aes(y = cases, color = geo_value)) +
  geom_line(aes(y = replacement), color = primary) +
  scale_color_manual(name = "", values = c(secondary, tertiary), guide = "none") +
  xlab("") + ylab("Confirmed cases") +
  coord_cartesian(ylim = c(0, NA)) +
  facet_wrap(~ geo_value, scales = "free_y", nrow = 1) +
  scale_x_date(date_breaks = "6 months", date_labels = "%b %Y", expand = expansion(0)) +
  scale_y_continuous(expand = expansion(c(0, 0.05))) +
  theme(strip.background = element_blank(), strip.text.x = element_blank())
cowplot::plot_grid(outp1, outp2, align = "v", ncol = 1, axis = "lr")
```


## Advanced sliding on an `epi_df`

* It is often useful to compute rolling summaries of signals. 

* These depend on the reference time, and are computed separately over geographies (and other groups). 

* In `epiprocess`, this is achieved by `epi_slide()`.

```{r epi-slide-example-call}
#| echo: true
#| eval: false
epi_slide(
  .x,
  .f,
  ..., # for tidy-evaluation
  .window_size = NULL,
  .align = c("right", "center", "left"),
  .ref_time_values = NULL, # at which time values do I calculate the function
  .new_col_name = NULL, # add a new column with this name rather than the default
  .all_rows = FALSE # do return all available time_values, or only the ones with a result
)
```

::: {.fragment .box-text .absolute top=10%}
* `epi_slide()` is [very]{.secondary} general, often too much so.
* We already saw the [most]{.secondary} common special case `epi_slide_mean()`
* For other common cases, there is `epi_slide_opt()`
:::

## Really ugly, but actually deployed slide functions

Function to flag outliers for corrections during late-2020

```{r covid-corrections}
#| echo: true
#| eval: false
flag_covid_outliers <- function(signal, sig_cut = 3, size_cut = 20, sig_consec = 2.25, excess_cut = 0) {
  signal <- rlang::enquo(signal)
  function(x, g, t) {
    .fns <- list(m = mean, med = median, sd = sd, mad = ~ median(abs(.x - median(.x))))
    fs <- filter(x, time_value <= t) |> summarise(across(!!signal, .fns, .names = "{.fn}"))
    ss <- summarise(x, across(!!signal, .fns, .names = "{.fn}"))
    mutate(
      x, 
      ftstat = abs(!!signal - fs$med) / fs$sd, # mad in denominator is wrong scale, 
      ststat = abs(!!signal - ss$med) / ss$sd, # basically results in all the data flagged
      flag = 
        (abs(!!signal) > size_cut & !is.na(ststat) & ststat > sig_cut) | # best case
        (is.na(ststat) & abs(!!signal) > size_cut & !is.na(ftstat) & ftstat > sig_cut) | 
        # use filter if smoother is missing
        (!!signal < -size_cut & (!is.na(ststat) | !is.na(ftstat))), # big negative
      flag = flag | # these allow smaller values to also be outliers if they are consecutive
        (lead(flag) & !is.na(ststat) & ststat > sig_consec) | 
        (lag(flag) & !is.na(ststat) & ststat > sig_consec) |
        (lead(flag) & is.na(ststat) & ftstat > sig_consec) |
        (lag(flag) & is.na(ststat) & ftstat > sig_consec)
    ) |>
      filter(time_value == t) |> pull(flag)
  }
}
```

## Really ugly, but actually deployed slide functions

Function to back distribute data [randomly]{.secondary}

```{r covid-multinomial}
#| echo: true
#| eval: false
exp_w <- function(x, std_decay = 30, b0 = 8, a = exp(1) / 2){
  w = (1:std_decay) / std_decay
  w = tail(w, length(x))
  1 / (1 + exp(-w * b0 + a))
}

corrections_multinom_roll <- function(x, excess, flag, time_value, max_lag = Inf, reweight = exp_w) {
  locs <- which(flag)
  if (length(locs) == 0) return(x)
  
  for (ii in locs) {
    if (ii <= max_lag) ii_lag <- seq_len(ii)
    else ii_lag <- seq(ii - max_lag + 1, ii)
    w <- rep(1 / length(ii_lag), times = length(ii_lag))
    zz <- reweight(w)
    w <- zz * w
    
    x[ii] <- x[ii] - excess[ii]
    prop <- x[ii_lag] + sign(excess[ii]) * rmultinom(1, abs(excess[ii]), w)
    x[ii_lag] <- prop
  }
  x
}
```


## `epi_archive`: Collection of `epi_df`s

* full version history of a data set
* acts like a bunch of `epi_df`s --- but stored [compactly]{.secondary}
* allows similar functionality as `epi_df` but using only [data that would have been available at the time]{.secondary}

::: {.callout-note}
## Revisions

Epidemiology data gets revised frequently.

* We may want to use the data [as it looked in the past]{.secondary}.
* or we may want to examine [the history of revisions]{.secondary}.
:::

## `epi_archive`: Collection of `epi_df`s

Subset of daily COVID-19 doctor visits (Optum) and cases (JHU CSSE) from all U.S. states in `archive` format:

```{r archive-ex}
#| echo: true
#| message: true
archive_cases_dv_subset_all_states
```

## Features -- sliding computation over `epi_df`s

* We can apply a computation over different snapshots in an `epi_archive`.

```{r}
#| echo: true
#| eval: false

epix_slide(
  .x,
  .f,
  ...,
  .before = Inf,
  .versions = NULL,
  .new_col_name = NULL,
  .all_versions = FALSE
)

```

This functionality is very helpful in version aware forecasting. We will return with a concrete example. 
  

## Summarize revision behaviour


```{r epiprocess-revision-summary-demo}
#| echo: true
revision_data <- revision_summary(
  archive_cases_dv_subset,
  case_rate_7d_av,
  drop_nas = TRUE,
  min_waiting_period = as.difftime(60, units = "days"),
  within_latest = 0.2,
  compactify = TRUE,
  compactify_abs_tol = sqrt(.Machine$double.eps)
)
```

## Features -- summarize revision behavior


```{asciicast epiprocess-revision-summary-results}
revision_summary(archive_cases_dv_subset, case_rate_7d_av)

```



## Visualize revision patterns

```{r plot-revision-patterns}
#| fig-width: 7
autoplot(
  archive_cases_dv_subset, percent_cli, 
  .versions = seq(ymd("2020-07-01"), ymd("2021-11-30"), by = "1 month"), 
  .mark_versions = TRUE
) +
  scale_x_date(minor_breaks = "month", date_labels = "%b %Y") +
  labs(x = "", y = "% of doctor's visits with\n Covid-like illness") + 
  scale_color_viridis_c(option = "B", end = .8) +
  theme(legend.position = "none")
```

## Finalized data

* Counts are revised as time proceeds
* Want to know the [final]{.primary} value 
* Often not available until weeks/months later

  Forecasting
: At time $t$, predict the final value for time $t+h$, $h > 0$
  
  <br>
  
  Backcasting
: At time $t$, predict the final value for time $t-h$, $h < 0$

  <br>
  
  Nowcasting
: At time $t$, predict the final value for time $t$



# Basic Nowcasting using [{epiprocess}]{.monotype} {.inverse}

<!-- predicting a finalized value from a provisional value and making predictions. -->
## Backfill Canadian edition
  
* Every week [BC CDC released COVID-19 hospitalization data](http://www.bccdc.ca/health-info/diseases-conditions/covid-19/archived-b-c-covid-19-data).

* The following week, they revised the number upward (by ~25%) due to lagged reports.

![](gfx/bc_hosp_admissions_ex.jpg){fig-align="center"}

::: {.fragment .box-text .absolute top=30% left=10%}
Comparing preliminary to revised data [always]{.secondary} shows a decline.
:::

## Backfill American edition

* Again, we can see a similar systematic underestimation problem for COVID-19 mortality rates in CA. <!-- 2023-2024 -->

* This plot also illustrates the [**revision process**]{.primary} - how the reported mortality changes & increases across multiple updates until it stabilizes at the final value (black line).

![](gfx/am_mortality_revisions_ex.jpg){style="width: 45%; display: block; margin-left: auto; margin-right: auto;"}

* These two examples show the problem and now we need a solution...

## Nowcasting and its mathematical setup

* **Nowcasting**: Predict a finalized value from a provisional value.

* Suppose today is time $t$

* Let $y_i$ denote a series of interest observed at times $i=1,\ldots, t$.

::: {.callout-important icon="false"}
## Our goal

* Produce a [**point nowcast**]{.primary} for the finalized values of $y_t$.
* Accompany with time-varying prediction intervals

:::

* We may also have access to $p$ other time series 
$x_{ij},\; i=1,\ldots,t, \; j = 1,\ldots, p$ which may be subject to revisions.



## Case study: NCHS mortality

* In this example, we'll demonstrate the concept of nowcasting using [**NHCS mortality data**]{.primary}.
(the number of weekly new deaths with confirmed or presumed COVID-19, per 100,000 population).
* We will work with [**provisional**]{.primary} data (real-time reports) and compare them to **finalized** data (final reports).
* The goal is to estimate or [**nowcast the mortality rate**]{.primary} for weeks when only provisional data is available.
  
## Fetch versioned data

Let's fetch versioned mortality data from the API (`pub_covidcast`) for CA (`geo_values = "ca"`) and the signal of interest (`deaths_covid_incidence_num`) over early 2024.

```{r mortality-archive-construct}
#| echo: true

# Fetch the versioned NCHS mortality data (weekly)
nchs_archive <- pub_covidcast(
  source = "nchs-mortality",
  signals = "deaths_covid_incidence_num",
  geo_type = "state",
  time_type = "week",
  geo_values = c("ca", "ut"),  
  time_values = epirange(202001, 202440),  
  issues = "*"
) |> 
  select(geo_value, time_value, version = issue, mortality = value) |> 
  as_epi_archive(compactify = TRUE)
```


## Analysis of versioning behavior 

Recall, we need to watch out for:

* [**Latency**]{.primary} the time difference between date of reference and date of the initial report
* [**Backfill**]{.primary} how data for a given date is updated after initial report. 

`revision_summary()` provides a summary of both aspects.  

```{r inspect-revision_summary}
#| echo: true
revision_data <- revision_summary(nchs_archive, mortality)
```


## Versioning analysis -- latency

* [**Question:**]{.primary} What is the latency of NCHS data? 

```{r nchs-latency-via-revision-summary}
#| echo: true
revision_data |> pluck("revision_behavior") |> select(geo_value, time_value, min_lag) |> slice_sample(n = 10)
```

* We randomly sampled some dates to check if there is a consistent latency pattern. 
* Understanding latency prevents us from using data that we shouldn't have access to. 

## Versioning analysis -- backfill

* [**Question:**]{.primary} How long does it take for the reported value to be close to the finalized value? 

```{r revision-summary-time-near-latest-demo}
#| echo: true
revision_data |> pluck("revision_behavior") |> select(geo_value, time_value, lag_near_latest) |> slice_sample(n = 10)
```
* It generally takes at least 4 weeks for reported value to be within 20\% (default in `revision_summary()`) of the finalized value. 
* We can change the threshold of percentage difference by specifying the `within_latest` argument of `revision_summary()`. 

## Versioning analysis - backfill 

* [**Question:**]{.primary} When is the [**finalized value**]{.primary} first attained for each date? Would we have access to any in real-time?
* How fast are the final values attained & what's the pattern for these times, if any?


```{r finalized-value-first-attained-fun}
#| echo: false
check_when_finalized <- function(epi_archive, start_date = NULL, end_date = NULL) {
  # Extract the mortality archive data
  dt <- epi_archive$DT
  
  # Extract the latest (finalized) version
  mortality_latest <- epix_as_of(epi_archive, max(dt$version))
  
  # Merge the finalized mortality data with all versions
  merged_data <- dt |>
    filter(geo_value %in% mortality_latest$geo_value &
             time_value %in% mortality_latest$time_value) |>
    inner_join(mortality_latest, by = join_by(geo_value, time_value), suffix = c("", "_finalized"))
  
  # Find the minimal version where the finalized mortality first occurred
  finalized_version_data <- merged_data |>
    filter(mortality == mortality_finalized) |>
    group_by(geo_value, time_value) |>
    summarize(min_version = min(version), .groups = 'drop') |>
    mutate(time_to_final = min_version - time_value)
  
  return(finalized_version_data)
}
```

```{r check-when-finalized-run}
#| echo: false
res <- check_when_finalized(nchs_archive, 
  start_date = min(nchs_archive$DT$time_value), 
  end_date = max(nchs_archive$DT$time_value))

head(res)
```


* [**Conclusion**]{.primary}: The revision behavior is pretty long-tailed. Value reported 4 weeks later is reasonably close to the finalized value. 


## Revision pattern visualization  
This shows the finalized rates in comparison to [**multiple revisions**]{.primary} to see how the data changes over time:

```{r mortality-by-accessed-weeks-later}
#| echo: false

ref_dates <- unique(nchs_archive$DT$time_value)
offsets = seq(1, 7) * 7
max_version <- nchs_archive$versions_end

get_val_asof <- function(time_val, archive, offsets) {
  
  as_of_dates <- pmin(time_val + offsets, max_version)
  
  result <- map(as_of_dates, function(x) {
    
    qd <- archive |>
      epix_as_of(x) |>
      filter(time_value == time_val) |>
      select(geo_value, time_value, mortality) |>
      mutate(lag = x - time_val)
  }) |>
    list_rbind()
  
  return(result)

  
}

value_at_lags <- map(ref_dates, get_val_asof, 
  archive <- nchs_archive, offsets <- offsets) |>
  list_rbind()
  
values_final <- epix_as_of(nchs_archive, max(nchs_archive$versions_end))

```

```{r final-vs-revisions-plot}
#| echo: false
#| fig-width: 7
ggplot(value_at_lags, aes(x = time_value, y = mortality)) +  
  geom_line(aes(color = factor(lag))) + 
  facet_wrap(~ geo_value, scales = "free_y", ncol = 1) +
  scale_x_date(minor_breaks = "month", date_labels = "%b %Y") +
  labs(x = "", y = "Weekly new COVID deaths") + 
  # scale_color_viridis_d(option="D", end=0.8) +
  theme(legend.position = "none") +
  geom_line(data = values_final, aes(x = time_value, y = mortality), 
            inherit.aes = FALSE, color = "black")


```

## Revision pattern visualization 

```{r nchs-plot-different-ver}
#| echo: false
#| eval: true
  
versions <- seq.Date(as.Date("2021-01-01"), nchs_archive$versions_end, by = "1 month")
nchs_snapshots <- map(versions, function(v) {
  epix_as_of(nchs_archive, v) |>
    mutate(version = v)}) |>
  bind_rows() |>
  mutate(latest = version == nchs_archive$versions_end)
```

```{r nchs-plot-val-different-ver}
#| echo: false
#| fig-width: 7

ggplot(nchs_snapshots |> filter(!latest),
       aes(x = time_value, y = mortality)) +
  geom_line(aes(color = factor(version))) +
  geom_vline(aes(color = factor(version), xintercept = version), lty = 3) +
  facet_wrap(~ geo_value, scales = "free_y", ncol = 1) +
  scale_x_date(minor_breaks = "month", date_labels = "%b %Y") +
  labs(x = "", y = "Weekly covid deaths") +
  scale_color_viridis_d(option = "B", end = .8) +
  theme(legend.position = "none") +
  geom_line(data = nchs_snapshots |> filter(latest),
            aes(x = time_value, y = mortality),
            inherit.aes = FALSE, color = "black")
```

<!--
## Aside: Do we need a burn-in/training set? 

* Typical stat-ML practise suggests a train, validation, test split.
* But our exploratory analysis covered all available data, is that fine?


* Generally, for exploratory analysis, it is fine to not do train/test split. 
  + These analyses do not involve model fitting, we have little risk of an overly optimistic performance evaluation (no overfitting on test data).
* However, for a [**psuedo-prospective analysis**]{.primary}, the best practise is to do a train/test split.
  + In such analysis, one would be fitting and validating many models, a train/test split provides a more rigorous control on overfitting to test set. 
-->

## Ratio nowcaster: jumping from provisional to finalized value

* Recall, the goal of nowcast at date $t$ is to use project the [*finalized value*]{.primary} of $y_t,$ given the information available on date $t$. 
* A very simple nowcaster is the ratio between finalized and provisional value. 

How can we sensibly estimate this quantity? 

```{r nchs-ca-only}
#| echo: false
#| eval: true
nchs_archive <- pub_covidcast(
  source = "nchs-mortality",
  signals = "deaths_covid_incidence_num",
  geo_type = "state",
  time_type = "week",
  geo_values = "ca",  
  time_values = epirange(202001, 202440),  
  issues = "*"
) |> 
  select(geo_value, time_value, version = issue, mortality = value) |> 
  as_epi_archive(compactify = TRUE)
```

## Ratio nowcaster: building training samples

* At nowcast date $t,$ would have received reports with versions up to and including $t.$
* We need to build training samples, which
  + correctly aligns finalized value against provisional value 
  + uses features that would have been available at test time 
  + have enough samples to ensure sensible estimation results

::: {.fragment .fade-in}
* Build training samples by treating dates prior to date $t$ as actual nowcast dates.
  + What is the provisional data on that date?
  + Have we received finalized value for that date? 
:::

## Ratio nowcaster: building training samples

* At an earlier nowcast date $t_0,$ we define 
  + [**Provisional value**]{.primary} as the reported value of $Y_{s_0}$ with version $t_0.$ Here $s_0$ is the largest occurence date among all values reported up until $t_0.$
  + [**Finalized value**]{.primary} as the (potentially unobserved) finalized value of $Y_{s_0}.$
    - We only know in *hindsight* when reported value of $Y_{s_0}$ is finalized -- need an approximation. 

## Revisiting `revision_summary()`

Recall, `revision_summary()` reports the number of days to be within 20\% (default value) of finalized value

```{r revision-summary-time-near-latest-show-again}
#| echo: false
revision_data |> pluck("revision_behavior") |> select(geo_value, time_value, lag_near_latest) |> slice_sample(n = 5)
(lag_quantiles = quantile(revision_data$lag_near_latest))
approx_final_lag = lag_quantiles["75%"]
```

::: {.fragment .fade-in}
Let's say data reported `r approx_final_lag` days after reference date is good enough to be considered finalized. 
:::

## Ratio nowcaster: test time feature

* Due to latency, provisional values may not be available at lag 0
* We use last-observation-carried-forward (LOCF) to impute missing values at test time
* Precisely, at test time $t,$ we use last observed data point (among all those reported up through time $t$)

## Nowcasting at a single date: building training samples 

::: {.fragment .fade-in}
* Searching for provisional values, at previous hypothetical nowcast dates.

```{r one-date-look-for-provisional}
#| echo: true

nowcast_date <- as.Date("2022-01-02"); window_length = 180

initial_data <- nchs_archive$DT |>
  group_by(geo_value, time_value) |>
  filter(version == min(version)) |>
  rename(initial_val = mortality) |>
  select(geo_value, time_value, initial_val)

```
:::


::: {.fragment .fade-in}
* Searching for finalized values, at previous hypothetical nowcast dates.

```{r one-date-look-for-final}
#| echo: true
#| 
finalized_data <- epix_as_of(nchs_archive, nowcast_date) |>
  filter(time_value >= nowcast_date - approx_final_lag - window_length & time_value <= nowcast_date - approx_final_lag) |>
  rename(finalized_val = mortality) |>
  select(geo_value, time_value, finalized_val)
```
:::

## Nowcasting at a single date: estimating ratio model

* After searching for both provisional and finalized values, we merge them together and estimate the ratio. 
```{r one-date-combine-provsional-and-final}
#| echo: true
  
ratio <- finalized_data |>
  inner_join(initial_data, by = c("geo_value", "time_value")) |>
  mutate(ratio = finalized_val / initial_val) |>
  pull(ratio) |>
  median(na.rm = TRUE)
```

## Nowcasting at a single date: test feature construction

```{r one-date-test-feat}
#| echo: true

last_avail <- epix_as_of(nchs_archive, nowcast_date) |>
  slice_max(time_value) |>
  pull(mortality) 
```

## Nowcasting at a single date: producing the nowcast

```{r one-date-nowcast}
#| echo: true

nowcast <- last_avail * ratio
finalized_val <- epix_as_of(nchs_archive, nchs_archive$versions_end) |>
  filter(time_value == nowcast_date) |>
pull(mortality)

nowcast_final = data.frame(Nowcast = nowcast, `Finalized value` = finalized_val, check.names=FALSE)
knitr::kable(nowcast_final)

```


## Nowcasting for multiple dates

* All previous manipulations should really be seen as a template for all nowcast dates. 
* The template computation sould be applied over all nowcast dates, [**but we must respect data versioning**]{.primary}! 
* `epix_slide()` is designed just for this! It behaves similarly to `epi_slide`.
* Key exception: `epix_slide()` is version aware: the sliding computation at any reference time $t$ is performed on [**data that would have been available as of t**]{.primary}.


## Nowcasting for multiple dates via `epix_slide()`

We begin by templatizing our previous operations. 

```{r nowcaster-to-slide}
#| echo: true
nowcaster <- function(x, g, t, wl=180, appx=approx_final_lag) {
  initial_data <- x$DT |>
    group_by(geo_value, time_value) |>
    filter(version ==  min(version)) |>
    filter(time_value >= t - wl - appx & time_value <= t - appx) |>
    rename(initial_val = mortality) |>
    select(geo_value, time_value, initial_val)
  finalized_data <- x$DT |>
    group_by(geo_value, time_value) |>
    filter(version ==  max(version)) |>
    filter(time_value >= t - wl - appx & time_value <= t - appx) |>
    rename(finalized_val = mortality) |>
    select(geo_value, time_value, finalized_val)
  ratio <- finalized_data |>
    inner_join(initial_data, by = c("geo_value", "time_value")) |>
    mutate(ratio = finalized_val / initial_val) |>
    pull(ratio) |>
    median(na.rm = TRUE)
  last_avail <-  epix_as_of(x, t) |>
    slice_max(time_value) |>
    pull(mortality) 
  tibble(geo_value = x$geo_value, target_date = t, nowcast = last_avail * ratio)
}
```

## Sanity check of `epix_slide()`

```{r nowcast-san-check}
#| echo: true
#| eval: true

slided_nowcast_1d = epix_slide(
  .x = nchs_archive,
  .f = nowcaster,
  .before = Inf,
  .versions = nowcast_date,
  .all_versions = TRUE
)

nowcast_check = data.frame(`Manual nowcast` = nowcast, `Slided nowcast` = slided_nowcast_1d$nowcast, check.names = FALSE)
knitr::kable(nowcast_check)


```


## Nowcasting for multiple dates via `epix_slide()`

```{r epix-slide-extract-nowcast-date}
#| echo: false
#| eval: true

all_nowcast_dates = nchs_archive$DT |>
  filter(time_value >= as.Date("2022-01-01")) |>
  distinct(time_value) |>
  pull(time_value)
```


```{r nowcasts-slided}
#| echo: true
#| eval: true

nowcasts = nchs_archive |>
  group_by(geo_value) |>
  epix_slide(
    nowcaster,
    .before=Inf,
    .versions = all_nowcast_dates,
    .all_versions = TRUE
)
```



## Details of `epix_slide()`


```{r epix-slide-demo-call-allversions-FALSE}
#| echo: true
#| eval: false

epix_slide(
  .x,
  .f,
  ...,
  .before = Inf,
  .versions = NULL,
  .new_col_name = NULL,
  .all_versions = FALSE
)
```


* `.f` in `epix_slide()` can be specified with the same form of custom function as `epi_slide()`. 

```{r epix-slide-form-of-custom-function}
#| echo: true
#| eval: false

function(x, g, t) {
  # function body
}
```

* Mandatory variables of `.f` would have different forms depending on the value of `.all_versions`. 


## Details of `epix_slide()`

```{r epix-slide-demo-call-allversions-FALSE-again}
#| echo: true
#| eval: false
#| code-line-numbers: "|8"

epix_slide(
  .x,                          
  .f,                         
  ...,                        
  .before = Inf,             
  .versions = NULL,           
  .new_col_name = NULL,      
  .all_versions = FALSE
)
```

::: {.fragment .fade-in}
* When `.all_versions = FALSE`, `epix_slide()` essentially iterates the templatized computation over snapshots. 
* Said differently, when `.all_versions = FALSE`, data accessed at any sliding iteration [**only involves a single version**]{.primary}. 
:::

::: {.fragment .fade-in}
* Hence: 
  + `x`: an `epi_df` with same column names as archive's `DT`, minus the `version` column.
  +  `g`: a one-row tibble containing the values of groupping variables of the associated group.
  + `t`: the `ref_time_value` of the current window.
  + `...`: additional arguments. 
:::

## Details of `epix_slide()`

```{r epix-slide-demo-call-allversions-TRUE}
#| echo: true
#| eval: false
#| code-line-numbers: "|8"

epix_slide(
  .x,                          
  .f,                         
  ...,                        
  .before = Inf,             
  .versions = NULL,           
  .new_col_name = NULL,      
  .all_versions = TRUE
)
```

::: {.fragment .fade-in}
* When `.all_versions = FALSE`, data accessed at any sliding iteration involves versions [**up to and including .version**]{.primary}. 
:::

::: {.fragment .fade-in}
* Hence: 
  + `x`: an `epi_archive`, with version up to and including `.version`. 
  +  `g`: a one-row tibble containing the values of groupping variables of the associated group.
  + `t`: the `.version` of the current window.
  + `...`: additional arguments. 
:::


## Details of `epix_slide()`

```{r nowcasts-slide-demo-only}
#| echo: true
#| eval: false
#| code-line-numbers: "|7"

nowcasts <- nchs_archive |>
  group_by(geo_value) |>
  epix_slide(
    nowcaster,
    .before=Inf,
    .versions = all_nowcast_dates,
    .all_versions = TRUE
)
```

## Details of `epix_slide()`

```{r nowcaster-to-slide-again}
#| echo: true
#| code-line-numbers: "|3,9"
nowcaster <- function(x, g, t, wl=180, appx=approx_final_lag) {
  initial_data <- x$DT |>
    group_by(geo_value, time_value) |>
    filter(version ==  min(version)) |>
    filter(time_value >= t - wl - appx & time_value <= t - appx) |>
    rename(initial_val = mortality) |>
    select(geo_value, time_value, initial_val)
  finalized_data <- x$DT |>
    group_by(geo_value, time_value) |>
    filter(version ==  max(version)) |>
    filter(time_value >= t - wl - appx & time_value <= t - appx) |>
    rename(finalized_val = mortality) |>
    select(geo_value, time_value, finalized_val)
  ratio <- finalized_data |>
    inner_join(initial_data, by = c("geo_value", "time_value")) |>
    mutate(ratio = finalized_val / initial_val) |>
    pull(ratio) |>
    median(na.rm=TRUE)
  last_avail <- epix_as_of(x, t) |>
    slice_max(time_value) |>
    pull(mortality) 
  tibble(geo_value = x$geo_value, target_date = t, nowcast = last_avail * ratio)
}
```



## Visualize nowcasts


We are now finally able to compare nowcasts against first available reports:

```{r nowcast-subsetting}
#| echo: false

intial_val_extracter <- function(x, g, t, wl=180, appx=approx_final_lag) {
  
  last_avail = epix_as_of(x, t) |>
    slice_max(time_value) |>
    pull(mortality)
  
  res = tibble(geo_value = x$geo_value, target_date = t, value = last_avail)
  
  return(res)
  
}


provisional_val = epix_slide(nchs_archive, intial_val_extracter,  .versions = all_nowcast_dates, .all_versions = TRUE)

finalized_val = nchs_archive$DT |>
  filter(time_value >= as.Date("2021-01-10")) |>
  group_by(geo_value, time_value) |>
  filter(version == max(version))

```


```{r nowcast-fun-plot-results}
#| echo: false
#| fig-width: 7
ggplot() + 
  geom_line(data = finalized_val, aes(x = time_value, y = mortality, color = "Finalized")) +
  geom_line(data = provisional_val, aes(x = target_date, y = value, color = "Provisional")) +
  geom_line(data = nowcasts, aes(x = target_date, y = nowcast, color = "Nowcast")) +
  ylab("Mortality") +
  xlab("Reference date") +
  scale_y_continuous(expand = expansion(c(0, .05))) +
  scale_color_delphi(name = "")
```

* The real-time counts tend to be biased below the finalized counts. Nowcasted values tend to provide a much better approximation of the truth (at least for these dates).


## Smoothing nowcasts

* Nowcasts are quite volatile, reflecting the provisional counts are far from complete. 
* We can use a trailing average to smooth them.

```{r smooth-nowcasts-epi-slide}
#| echo: true
#| fig-width: 7

smoothed_nowcasts <- epi_slide(
  nowcasts |> as_epi_df(),
  smoothed_nowcasts = mean(nowcast, na.rm = TRUE),
  .window_size = as.difftime(3, units = "weeks")
)

```

```{r nowcast-smoothed-vis}
#| echo: false
#| fig-width: 7.5
#| fig-height: 2.5
cbPalette = c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442",
              "#0072B2", "#D55E00", "#CC79A7")

ggplot() + 
  geom_line(data = finalized_val, aes(x = time_value, y = mortality, color = "Finalized")) +
  geom_line(data = provisional_val, aes(x = target_date, y = value, color = "Provisional")) +
  geom_line(data = nowcasts, aes(x = target_date, y = nowcast, color = "Nowcast")) +
  geom_line(data = smoothed_nowcasts, aes(x = time_value, y = smoothed_nowcasts, color = "Smoothed")) +
  scale_color_delphi(name = "") +
  ylab("Mortality") +
  scale_y_continuous(expand = expansion(c(0, .05))) +
  xlab("Reference date")
```



## Evaluation using MAE

* Assume we have prediction $\hat y_{t}$ for the provisional value at time $t$.

* Then for $y_{t}$ over times $t = 1, \dots, N$, then we may compute error metrics like mean absolute error (MAE).


* MAE measures the average absolute difference between the nowcast and finalized values. 

$$MAE = \frac{1}{N} \sum_{t=1}^N |y_{t}- \hat y_{t}|$$

* Note that it's scale-dependent, meaning it can vary depending on the units of the data (e.g., cases, deaths, etc.).

## Evaluation using MAE

Let's numerically evaluate our point nowcasts for the provisional values of a time series (e.g., COVID-19 mortality) using MAE.

<!-- Accuracy of nowcast is assessed by how close provisional estimates are to the finalized values to gauge the model's performance. -->


```{r mae-code}
#| echo: false
# Step 1: Join the mortality data with nowcast data
mae_data <- finalized_val |> 
  select(-version) |>
  inner_join(nowcasts |> select(-version), by = join_by("geo_value", "time_value" == "target_date")) |>
  inner_join(initial_data, by = c("geo_value", "time_value")) |>
  inner_join(smoothed_nowcasts |> select(-version, -nowcast), by = c("geo_value", "time_value"))

# Step 2: Calculate the absolute error between actual and nowcasted values
mae_data <- mae_data |> 
  mutate(raw_nc_res = abs(mortality - nowcast),
         prov_res = abs(mortality - initial_val),
         smoothed_res = abs(mortality - smoothed_nowcasts))  

# Step 3: Compute the MAE (mean of absolute errors)
mae_value <- mae_data |> 
  group_by(geo_value) |>
  summarise(`Smoothed MAE` = mean(smoothed_res, na.rm = TRUE),
            `Unsmoothed nowcast MAE` = mean(raw_nc_res, na.rm = TRUE),
            `Provisional value MAE` = mean(prov_res, na.rm = TRUE)) |>
  select(-geo_value) 
  
knitr::kable(mae_value)
```


# Nowcasting with Regression

## Nowcasting: Moving from one predictor to multiple

* The ratio model predicts the finalized value of $Y_t$ from $Y_{s}$, the last value included in the version $t$ report.
* $Y_s$ is the closest in time we can get to $Y_t$, but we also expect it to be the least reliable value in version $t$.
* Can we add $Y_{s - 1}$, $Y_{s - 2}$, and even other data sources to the model to try to find a good mix of relevant and reliable signals?
* Regressions models will let us do that.
* Let's start "simple": predicting $Y_t$ with whichever of $Y_{t - 1}$ and $Y_{t -
  2}$ are available in version $t$.

## Start with a single nowcast date

We're only looking at California in this example:
```{r nchs-ca-archive}
#| echo: true

nchs_ca_archive <- nchs_archive$DT[geo_value == "ca",] |>
  as_epi_archive()
```

We'll start experimenting with just a single nowcast date:

::: {.notes}
Earlier nowcast dates often encounter extra difficulties regarding data
availability, so let's make sure we work on the first one.
:::

```{r regression-trial-nowcast-data}
#| echo: true

trial_nowcast_date <- all_nowcast_dates[[1]]
```

What data would we have had available then?
```{r regression-trial-nowcast-date-as-of}
#| echo: true

# This is the version history we'd have seen at that point:
nchs_ca_past_archive <- nchs_ca_archive |>
  epix_as_of(trial_nowcast_date, all_versions = TRUE)

# And this is what the latest version was at that point:
nchs_ca_past_latest <- nchs_ca_past_archive |>
  epix_as_of(trial_nowcast_date)
```



## What predictors were available at test time?

```{r predictor-descriptions}
#| echo: true

# At version t, our target is finalized Y_t:
target_time_value <- trial_nowcast_date

# Check which of Y_{t-1} and Y_{t-2} are available, assign distinct names:
predictor_descriptions <- nchs_ca_past_latest |>
  filter(as.integer(target_time_value - time_value) <= 2 * 7) |>
  drop_na(mortality) |>
  transmute(
    varname = "mortality",
    lag_days = as.integer(trial_nowcast_date - time_value),
    predictor_name = paste0(varname, "_lag", lag_days, "_realtime")
  )
predictor_descriptions
```

## Line up with training data

We need to make sure to line up our predictors in `nchs_ca_past_latest` with
training data that is analogous (e.g., "equally unreliable").

```{r regression-trial-nowcast-analogues-fn-prototype}
#| echo: true
#| eval: false

library(data.table)
get_predictor_training_data <- function(archive, varname, lag_days, predictor_name) {
  ...
  ...
  ...
  return (training_data_edf_for_this_predictor)
}
```

Actual implementation:
```{r regression-trial-nowcast-analogues}
#| echo: true
#| code-fold: true

library(data.table)
get_predictor_training_data <- function(archive, varname, lag_days, predictor_name) {
  epikeytime_names <- setdiff(key(archive$DT), "version")
  requests <- unique(archive$DT, by = epikeytime_names, cols = character())[
  , version := time_value + ..lag_days
  ]
  setkeyv(requests, c(epikeytime_names, "version"))
  result <- archive$DT[
    requests, c(key(archive$DT), varname), roll = TRUE, nomatch = NULL, allow.cartesian = TRUE, with = FALSE
  ][
  , time_value := version
  ][
  , version := NULL
  ]
  nms <- names(result)
  nms[[match(varname, nms)]] <- predictor_name
  setnames(result, nms)
  setDF(result)
  as_tibble(result)
}
```

```{r regression-trial-nowcast-analogues-example}
#| echo: true
get_predictor_training_data(nchs_ca_past_archive, "mortality", 7, "mortality_lag7_realtime")
```
The first value here is a version of $Y_{\text{2020-11-30}}$ as it was reported in version 2020-12-06.  We expect it to have similar characteristics as $Y_{t - 7\text{ days}}$ as reported in version $t$ for other values of $t$.

## Get multiple predictors

```{r regression-trial-nowcast-predictors-data}
#| echo: true
predictors <- predictor_descriptions |>
  pmap(function(varname, lag_days, predictor_name) {
    get_predictor_training_data(nchs_ca_past_archive, varname, lag_days, predictor_name)
  }) |>
  reduce(full_join, by = c("geo_value", "time_value"))
predictors
```

- A full join is nice to show differences in missingness
- But before training we're going to `drop_na()` and end up with something more
  like an inner join

## Combine with target data

```{r regression-trial-nowcast-predictors-target-data}
#| echo: true

target <- nchs_ca_past_latest |>
  filter(time_value <= max(time_value) - 49) |>
  rename(mortality_semistable = mortality)
```

For each training time $t'$, approximate finalized $Y_{t'}$ with $Y_{t'}$ as
reported at our trial nowcast date $t$.
* Based on earlier analysis, we shouldn't really trust this for $t'$ within 49
  days of $t$, so filter those training times out.


## Fit the regression model

```{r regression-trial-nowcast-fit}
#| echo: true

training_test <- full_join(predictors, target, by = c("geo_value", "time_value"))

training <- training_test |> drop_na()
test <- training_test |> filter(time_value == trial_nowcast_date)

fit <- training |>
  select(all_of(predictor_descriptions$predictor_name), mortality_semistable) |>
  lm(formula = mortality_semistable ~ .)

pred <- tibble(
  nowcast_date = trial_nowcast_date,
  target_date = target_time_value,
  prediction = unname(predict(fit, test))
)

pred
```

## Our prediction

```{r regression-trial-nowcast-pred}
#| echo: true

pred
```

## Backtesting our nowcaster

We'll wrap our nowcasting code in a function and `epix_slide()` again.

* And get an error --- some versions $t$ don't include a value $Y_{t-1}$ or $Y_{t-2}$ (e.g., version 2022-06-26 doesn't).
    * So let's try looking farther into the past at $Y_{t-3}$, etc.
    * ... but don't look too far: $Y_{t-5}$ is the limit.
    * The same regression approach applies to models with 3 or more features.
    * Including more features tends to improve performance, up to a point.

## Some other modifications

* Add some basic checks throughout our nowcasting function.
* Make sure we have "enough" training data to fit a model.
* Add ability to look not just at provisional $Y_{t-k}$, but also provisional
  $Z_{t-k}$ for some other signal $Z$.
    * $Z$ here is HHS/NHSN COVID-19 hospitalization reporting.
      * This was daily-resolution and daily-reporting-cadence for some time;
        it's possible but a bit tricky to combine with our weekly-resolution
        weekly-cadence archive.
    * Exclude a potential predictor if it doesn't have much training data available.
* Allow for linear regression or quantile regression at the median level (tau = 0.5)

```{r regression-nowcaster-function}
#| echo: true
#| code-fold: true

regression_nowcaster <- function(archive, settings, return_info = FALSE) {
  if (!inherits(archive, "epi_archive")) {
    stop("`archive` isn't an `epi_archive`")
  }
  if (length(unique(archive$DT$geo_value)) != 1L) {
    stop("Expected exactly one unique `geo_value`")
  }
  if (archive$time_type == "day") {
    archive <- thin_daily_to_weekly_archive(archive)
  }

  nowcast_date <- archive$versions_end
  target_time_value <- nowcast_date
  latest_edf <- archive |> epix_as_of(nowcast_date)
  # print(nowcast_date)

  predictor_descriptions <-
    latest_edf |>
    mutate(lag_days = as.integer(nowcast_date - time_value)) |>
    select(-c(geo_value, time_value)) |>
    pivot_longer(-lag_days, names_to = "varname", values_to = "value") |>
    drop_na(value) |>
    inner_join(settings$predictors, by = "varname", unmatched = "error") |>
    filter(abs(lag_days) <= max_abs_shift_days) |>
    arrange(varname, abs(lag_days)) |>
    group_by(varname) |>
    filter(seq_len(n()) <= max_n_shifts[[1]]) |>
    ungroup() |>
    mutate(predictor_name = paste0(varname, "_lag", lag_days, "_realtime")) |>
    select(varname, lag_days, predictor_name)

  predictor_edfs <- predictor_descriptions |>
    pmap(function(varname, lag_days, predictor_name) {
      get_predictor_training_data(archive, varname, lag_days, predictor_name)
    }) |>
    lapply(na.omit) |>
    keep(~ nrow(.x) >= settings$min_n_training_per_predictor)

  if (length(predictor_edfs) == 0) {
    stop("Couldn't find acceptable predictors in the latest data.")
  }

  predictors <- predictor_edfs |>
    reduce(full_join, by = c("geo_value", "time_value"))

  target <- latest_edf |>
    filter(time_value <= max(time_value) - settings$days_until_target_semistable) |>
    select(geo_value, time_value, mortality_semistable = mortality)

  training_test <- full_join(predictors, target, by = c("geo_value", "time_value"))

  training <- training_test |>
    drop_na() |>
    slice_max(time_value, n = settings$max_n_training_intersection)

  test <- training_test |>
    filter(time_value == nowcast_date)

  if (isTRUE(settings$median)) {
    fit <- training |>
      select(any_of(predictor_descriptions$predictor_name), mortality_semistable) |>
      quantreg::rq(formula = mortality_semistable ~ ., tau = 0.5)
  } else {
    fit <- training |>
      select(any_of(predictor_descriptions$predictor_name), mortality_semistable) |>
      lm(formula = mortality_semistable ~ .)
  }  

  pred <- tibble(
    geo_value = "ca",
    nowcast_date = nowcast_date,
    target_date = target_time_value,
    prediction = unname(predict(fit, test))
  )

  if (return_info) {
    return(tibble(
      coefficients = list(coef(fit)),
      predictions = list(pred)
    ))
  } else {
    return(pred)
  }
}

# We can apply this separately for each nowcast_date to ensure that we consider
# the latest possible value for every signal, though whether that is advisable
# or not may depend on revision characteristics of the signals.
thin_daily_to_weekly_archive <- function(archive) {
  key_nms <- key(archive$DT)
  val_nms <- setdiff(names(archive$DT), key_nms)
  update_tbl <- as_tibble(archive$DT)
  val_nms |>
    lapply(function(val_nm) {
      update_tbl[c(key_nms, val_nm)] |>
        # thin out to weekly, making sure that we keep the max time_value with non-NA value:
        filter(as.POSIXlt(time_value)$wday == as.POSIXlt(max(time_value[!is.na(.data[[val_nm]])]))$wday) |>
        # re-align:
        mutate(
          time_value = time_value - as.POSIXlt(time_value)$wday, # Sunday of same epiweek
          old_version = version,
          version = version - as.POSIXlt(version)$wday # Sunday of same epiweek
        ) |>
        slice_max(old_version, by = all_of(key_nms)) |>
        select(-old_version) |>
        as_epi_archive(other_keys = setdiff(key_nms, c("geo_value", "time_value", "version")),
                       compactify = TRUE)
    }) |>
    reduce(epix_merge, sync = "locf")
}

# Baseline model:
locf_nowcaster <- function(archive) {
  nowcast_date <- archive$versions_end
  target_time_value <- nowcast_date
  latest_edf <- archive |> epix_as_of(nowcast_date)

  latest_edf |>
    complete(geo_value, time_value = target_time_value) |>
    arrange(geo_value, time_value) |>
    group_by(geo_value) |>
    fill(mortality) |>
    ungroup() |>
    filter(time_value == target_time_value) |>
    transmute(
      geo_value,
      nowcast_date = nowcast_date,
      target_date = time_value,
      prediction = mortality
    )
}
```

## Model settings

After fixing, enhancing, and parameterizing our regression nowcaster, we'll
compare two different configurations:

* one with just mortality-based predictions
* one that also uses hospitalizations as a predictor
* and two that use quantile reg instead of linear reg

## Model settings

```{r regression-model-settings}
#| echo: true

reg1_settings <- list(
  predictors = tribble(
    ~varname,    ~max_abs_shift_days, ~max_n_shifts,
    "mortality",                  35,             3,
    ),
  min_n_training_per_predictor = 30, # or else exclude predictor
  days_until_target_semistable = 7 * 7, # filter out unstable when training (and evaluating)
  min_n_training_intersection = 20, # or else raise error
  max_n_training_intersection = Inf # or else filter down rows
)

reg2_settings <- list(
  predictors = tribble(
    ~varname,     ~max_abs_shift_days, ~max_n_shifts,
    "admissions",                  35,             3,
    "mortality",                   35,             3,
    ),
  min_n_training_per_predictor = 30, # or else exclude predictor
  days_until_target_semistable = 7 * 7, # filter out unstable when training (and evaluating)
  min_n_training_intersection = 20, # or else raise error
  max_n_training_intersection = Inf # or else filter down rows
)

reg3_settings <- c(reg1_settings, median = TRUE)
reg4_settings <- c(reg2_settings, median = TRUE)
```

```{r regression-run-nowcasts-backtesting}

hhs_hosp_archive <- pub_covidcast(
  source = "hhs",
  signals = "confirmed_admissions_covid_1d_7dav",
  geo_type = "state",
  time_type = "day",
  geo_values = "ca",
  time_values = epirange(20210301, 20241001),
  issues = "*"
) |>
  transmute(geo_value, time_value, version = issue, admissions = 7 * value) |>
  as_epi_archive(compactify = TRUE)

nchs_ca_archive_daily <-
  nchs_ca_archive$DT |>
  as_tibble() |>
  mutate(
    time_value = time_value + 6L, # align with trailing averages
    version = version + 4L # assume NCHS data were released only on Thursdays
  ) |>
  group_by(geo_value, time_value, version) |>
  reframe(time_value = time_value - 6:0,
          mortality = c(rep(NA, 6), mortality)) |>
  as_epi_archive(compactify = TRUE)

hosp_mort_archive <- epix_merge(hhs_hosp_archive, nchs_ca_archive_daily, sync = "locf")

locf_nowcasts <- nchs_ca_archive |>
  epix_slide(~ locf_nowcaster(.x), .versions = all_nowcast_dates, .all_versions = TRUE)

reg1_nowcasts <- nchs_ca_archive |>
  epix_slide(~ regression_nowcaster(.x, reg1_settings), .versions = all_nowcast_dates, .all_versions = TRUE)

reg2_nowcasts <- hosp_mort_archive |>
  epix_slide(~ regression_nowcaster(.x, reg2_settings),
             .versions = all_nowcast_dates + 4, # assume we nowcast on Thursday, same day as assumed NCHS release
             .all_versions = TRUE)

reg3_nowcasts <- nchs_ca_archive |>
  epix_slide(~ regression_nowcaster(.x, reg3_settings), .versions = all_nowcast_dates, .all_versions = TRUE)

reg4_nowcasts <- hosp_mort_archive |>
  epix_slide(~ regression_nowcaster(.x, reg4_settings),
             .versions = all_nowcast_dates + 4, # assume we nowcast on Thursday, same day as assumed NCHS release
             .all_versions = TRUE)
```

```{r regression-nowcast-wrangling}
ratio_nowcasts_archive <- nowcasts |>
  filter(geo_value == "ca") |>
  rename(time_value = target_date,
         prediction_ratio = nowcast) |>
  as_epi_archive(compactify = TRUE)

nowcast_comparison <-
  list(
    locf_nowcasts |> rename(prediction_locf = prediction),
    ratio_nowcasts_archive$DT |> as_tibble() |> rename(nowcast_date = version, target_date = time_value),
    reg1_nowcasts |> rename(prediction_reg1 = prediction),
    reg2_nowcasts |> rename(prediction_reg2 = prediction),
    reg3_nowcasts |> rename(prediction_reg3 = prediction),
    reg4_nowcasts |> rename(prediction_reg4 = prediction)#,
    #   get_predictor_training_data(nchs_ca_archive, "mortality", 14L, "mortality_lag14_realtime") |>
    #     transmute(geo_value, nowcast_date = time_value, target_date = time_value, mortality_lag14_realtime)
    ) |>
  lapply(select, -any_of("version")) |>
  reduce(full_join, by = c("geo_value", "nowcast_date", "target_date")) |>
  full_join(nchs_ca_archive |> epix_as_of(nchs_ca_archive$versions_end),
            by = c("geo_value", "target_date" = "time_value")) |>
  pivot_longer(starts_with("prediction"), names_to = "Nowcaster", values_to = "prediction") |>
  mutate(Nowcaster = recode(Nowcaster,
                            prediction_locf = "LOCF",
                            prediction_ratio = "LOCF ratio model",
                            prediction_reg1 = "Regression model",
                            prediction_reg2 = "Regression + hosp",
                            prediction_reg3 = "QuantReg model",
                            prediction_reg4 = "QuantReg + hosp",
                            .default = Nowcaster))
```

## Comparison: linear regression

```{r regression-nowcast-plot-linreg}
#| fig-width: 7
nowcast_comparison |>
  filter(target_date >= min(all_nowcast_dates) - 35,
         !(Nowcaster %in% c("QuantReg model", "QuantReg + hosp"))) |>
  ggplot() +
  geom_line(aes(target_date, mortality)) +
  geom_line(aes(target_date, prediction, color = Nowcaster)) +
  scale_color_delphi() +
  xlab("Reference date") +
  ylab("Mortality")
```

## Comparison: quantile regression

```{r regression-nowcast-plot-quantreg}
#| fig-width: 7

nowcast_comparison |>
  filter(target_date >= min(all_nowcast_dates) - 35,
         !(Nowcaster %in% c("Regression model", "Regression + hosp"))) |>
  ggplot() +
  geom_line(aes(target_date, mortality)) +
  geom_line(aes(target_date, prediction, color = Nowcaster)) +
  scale_color_delphi(name = "") +
  xlab("Reference date") +
  ylab("Mortality")
```

## Evaluations

```{r regression-nowcast-eval-comparison}
#| echo: true

n_models <- length(unique(nowcast_comparison$Nowcaster))
nowcast_comparison |>
  # Filter evaluation based on target stability
  filter(target_date <= nchs_ca_archive$versions_end - 49) |>
  # Filter evaluated tasks to those with all models available
  group_by(target_date) |>
  filter(sum(!is.na(prediction)) == n_models) |>
  ungroup() |>
  summarize(.by = Nowcaster,
            MAE = mean(abs(mortality - prediction)),
            MAPE = 100*mean(abs(mortality - prediction)/abs(mortality)))
```

## Mea culpa

This quickly became complicated and we've glossed over some core concepts.
We'll explain concepts of regression, lagged features, and evaluation more
carefully tomorrow.

## Aside on nowcasting

* To some Epis, "nowcasting" can be equated with "estimate the time-varying instantaneous reproduction number, $R_t$"

* Ex. using the number of reported COVID-19 cases in British Columbia between Jan. 2020 and Apr. 15, 2023. 

<!-- This data is the number of reported COVID-19 cases in British Columbia between January 2020 and April 15, 2023. The values are.up-to-date as of August 2023. -->
```{r rtestim}
#| fig-width: 9
#| fig-height: 3
#| out-height: "400px"
library(rtestim)
source(here::here("_code/bccovid.R"))

p1 <- bccovid|>
  ggplot(aes(date, cases)) + 
  geom_line(colour = primary) +
  geom_vline(xintercept = ymd("2023-04-15"), colour = secondary,
             linewidth = 2) +
  labs(y = "BC Covid-19 cases", x = "Date") +
  scale_y_continuous(expand = expansion(c(0, NA)))
bc_rt <- estimate_rt(bccovid$cases, x = bccovid$date, 
                     lambda = c(1e6, 1e5))
p2 <- plot(confband(bc_rt, lambda = 1e5)) + 
  coord_cartesian(ylim = c(0.5, 2)) +
  scale_y_continuous(expand = expansion(0))
cowplot::plot_grid(p1, p2)
```

* Group built [`{rtestim}`](https://dajmcdon.github.io/rtestim) doing for this nonparametrically.

* We may come back to this later...
