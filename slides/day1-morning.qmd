---
talk-title: "Signal Discovery, Data Fetching, & Panel Data"
talk-short-title: "Understanding Data"
talk-subtitle: "InsightNet Forecasting Workshop 2024"
talk-date: "11 December -- Morning"
format: revealjs
---

{{< include _titleslide.qmd >}}

```{r theme-load-pkg}
#| cache: false
library(tidymodels)
library(epidatasets)
library(epipredict)
library(epidatr)
load(here::here("_data", "day1m_queries.rda"))
ggplot2::theme_set(ggplot2::theme_bw())
```


## Outline

1. The Delphi Research Group

1. Workshop Overview and System Setup

1. Panel Data

1. Versioned Data

1. Epidata Repository and API

1. Find Data Sources and Signals

1. `{epidatr}`

1. Versioning in `{epidatr}`


# The Delphi Research Group

## About Delphi

* Founded in 2012 at Carnegie Mellon University, now expanded to UC Berkeley, and University of British Columbia.

* Currently 5 faculty, ~10 PhD students, ~15 staff (mostly software engineers).

* Easy to join us from anywhere (lots of volunteers during Covid-19 pandemic).

* We are:
    + CDC Center of Excellence for Influenza and Covid-19 Forecasting (2019-24).
    + CDC Innovation Center for Outbreak Analytics and Disease Modeling (2024-29).

[**Our mission:**]{.primary} To develop the theory and practice of [epidemic detection, tracking and forecasting]{.primary}, and their use in decision making, both public and private.

## What does Delphi do?

* Procure [real-time, aggregated data streams]{.primary} informative of infectious diseases and syndromes, in collaboration with partners in industry and government.

* Extract signals and make them widely available via the [Epidata platform & API]{.primary}.

* Develop and deploy algorithms for [epidemic detection, tracking, forecasting]{.primary}.

* Develop and maintain statistical software packages for these tasks.

* Make it all production-grade, maximally-accessible, and open-source (to serve CDC, state and local public health agencies, epi-forecasting researchers, data journalists, the public)

## What we provide

![](gfx/web_of_parts.svg){fig-align=center}

# Workshop Overview and System Setup

## A few slides here

## A few slides here

## System setup -- Passive viewing

<br>

### All of the slides are at 

<br>

[<https://cmu-delphi.github.io/insightnet-workshop-2024>]{style="text-align: center;"}

<br>

### The source code is in the Repo 

<br>

<https://github.com/cmu-delphi/insightnet-workshop-2024>

<br>

This is enough, but we hope you'll want to work through the code as we go along.

<br>

[Detailed versions of the next few slides are shown at the Repo Link above.]{.secondary}

## System setup -- Required software 

<br>

### We assume you already have

<br>

1. `R`

<br>

2. An IDE. We'll use RStudio, but you can use VSCode or Emacs or Whatnot

## System setup -- Downloading the materials

### Easy way: 

1. Click the [Big Green Button]{.fourth-colour} that says <kbd>< > Code â–¾</kbd>
2. Choose [Download Zip]{.primary}
3. Open the Zip directory and then Open `insightnet-workshop-2024.Rproj`

### More expert (local `git` user):

1. Click the [Big Green Button]{.fourth-colour} that says <kbd>< > Code â–¾</kbd>
2. Copy the URL.
3. Open RStudio, select File > New Project > Version Control. Paste there and proceed.

### Even more expert (wants `github` remote):

1. Click the Grey Button that says <kbd>â‘‚ Fork â–¾</kbd>
2. Proceed along the same lines as above.

## System setup -- Installing required packages

We will use a [lot]{.tertiary} of packages.

### We've tried to make it so you can get them all at once (with the right versions)

ðŸ¤ž We hope this works... ðŸ¤ž
[Note that you can "Copy to Clipboard"]{.fourth-colour}

<br>

In RStudio:

``` r
install.packages("pak") # good for installing from non-CRAN sources
pak::pkg_install("cmu-delphi/InsightNetFcast24", dependencies = TRUE)
InsightNetFcast24::verify_setup()
```

<br>

Hopefully, you see:
```{r}
#| message: true
cli::cli_alert_success("You should be good to go!")
```

Ask for help if you see something like:
```{r}
#| error: TRUE
verify_setup <- function() {
  cli::cli_abort(c(
    "The following packages do not have the correct version:",
    "i" = "Installed: {.pkg epipredict 0.2.0}.",
    "i" = "Required: {.pkg epipredict == 0.1.0}."
  ))
}
verify_setup()
```

# Panel Data

## Panel data

* [**Panel data**](https://en.wikipedia.org/wiki/Panel_data) or longitudinal data, contain cross-sectional measurements of subjects over time.

* Since we're working with aggregated data, the subjects are geographic units (e.g. counties, states) 

<!-- and not individuals.--> 

* In table form, panel data is a time index + one or more locations/keys.

* **Ex**: The % of outpatient doctor visits that are COVID-related in WA from Dec. 2021 to Feb. 2022 ([docs](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/doctor-visits.html)):
```{r panel-wa-ex}
head(epix_as_of(dv_wa, max_version = max(dv_wa$DT$version)))
```

<!-- Example: The estimated % of outpatient doctor visits that are COVID-related in WA from Dec. 2021 to Feb. 2022 -->

## Examples of panel data - COVID-19 cases

[[**JHU CSSE COVID cases per 100k **]{.primary}](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/jhu-csse.html) estimates the daily number of new confirmed COVID-19 cases per 100,000 population, averaged over the past 7 days.

```{r examples-panel-covid2}
#| echo: false
#| fig-width: 7
names <- c("COVID-19 cases", "CHNG-CLI", "CHNG-COVID", "COVID-19 hospital admissions")
units <- c("Reported cases per 100k people",
           "% doctor's visits due to CLI",
           "% doctor's visits due to COVID-19",
           "Hospital admissions per 100k people")

as_epi_df(panel_data[[1]]) %>%
  autoplot("value") +
  scale_color_delphi() +
  theme(legend.title = element_blank()) +
  xlab("Date") + ylab(units[1]) +
  scale_y_continuous(expand = expansion(c(0, 0.05)))
```

::: {.notes}

* WA switch to weekly reporting in 2022
* FL reports "whenever" (weekly, biweekly, three days in a row, then 4 zeros, etc.)
* API calculates change from cumulative, so no-report becomes a 0.
* If state decreases total, then we see a negative.

:::

<!--

## Examples of panel data - CHNG-CLI

[[**Change Healthcare COVID-like illness (CHNG-CLI)**]{.primary}](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/chng.html) reports the percentage of outpatient visits for COVID-related symptoms, based on deidentified Change Healthcare claims data.

```{r examples-chng-cli}
#| echo: false
as_epi_df(panel_data[[2]]) %>%
  autoplot("value") +
  scale_color_delphi() +
  theme(legend.title = element_blank()) +
  xlab("Date") + ylab(units[2]) +
  scale_y_continuous(expand = expansion(c(0, 0.05)))
```

## Examples of panel data - CHNG-COVID

[[**Change Healthcare COVID (CHNG-COVID)**]{.primary}](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/chng.html) reports the percentage of outpatient visits with confirmed COVID-19, based on Change Healthcare claims data.

```{r examples-chng-covid}
#| echo: false
as_epi_df(panel_data[[3]]) %>%
  autoplot("value") +
  scale_color_delphi() +
  theme(legend.title = element_blank()) +
  xlab("Date") + ylab(units[3]) +
  scale_y_continuous(expand = expansion(c(0, 0.05)))
```

-->

<!--  Numerator = denote the Covid counts. Denominator be the total count of visits. Scaling by population is not necessary here because the signal is already normalized to the total number of visits, which acts as a proxy for population size. -->


## Examples of panel data - HHS Admissions

[[**Confirmed COVID-19 Hospital Admissions per 100k**]{.primary}](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/hhs.html) estimates the daily sum of adult and pediatric confirmed COVID-19 hospital admissions, per 100,000 population, averaged over the past 7 days.

```{r examples-hhs-admissions}
#| echo: false
#| fig-width: 7
as_epi_df(panel_data[[4]]) %>%
  autoplot("value") +
  scale_color_delphi() +
  theme(legend.title = element_blank()) +
  xlab("Date") + ylab(units[4]) +
  scale_y_continuous(expand = expansion(c(0, 0.05)))
```


<!-- 
## All together - Visualizing multiple panel data signals
Example: gathering different signals + visualizing panel data

```{r multiple-signals-unscale}
#| echo: false
#| eval: false
# turn list into dataframe
df <- list_rbind(panel_data)
df$signal <- factor(df$signal, labels = names)

ggplot(df, aes(x = time_value, y = value, color = signal)) +
  geom_line() +
  scale_color_manual(breaks = names, values = colors) +
  labs(x = "Date", y = "Signal value") +
  scale_x_date(date_breaks = "3 months", date_labels = "%b %Y",
               date_minor_breaks = "1 month") +
  theme_bw() +
  theme(legend.position = "bottom", legend.title = element_blank())
```

## All together - Visualizing multiple panel data signals
Example: gathering different signals + **scaling** + visualizing panel data

```{r multiple-signals-scale}
#| echo: false
#| eval: false
# HIDE THIS: function that rescales signal value according to specified range
epi_rescale_signal = function(df, variable, scale_to = c(0, 1)) {
  Min <- function(x) min(x, na.rm = TRUE)
  Max <- function(x) max(x, na.rm = TRUE)
  rescaled <- df |>
    group_by(signal) |>
      mutate("{{variable}}" := ({{variable}} - Min({{variable}})) / 
               (Max({{variable}}) - Min({{variable}})) * scale_to[2] + 
               scale_to[1]) |>
    ungroup()
  return(rescaled)
}
```


```{r scaled-signals}
#| echo: false
#| eval: false
# minimum and maximum of cases (used to rescale data)
case_min <- min(data_list[[1]]$value)
case_max <- max(data_list[[1]]$value)

# rescale data
rescaled_df <- epi_rescale_signal(df, value, scale_to = c(case_min, case_max))

# plot
rescaled_df$signal <- factor(rescaled_df$signal, labels = names)

ggplot(rescaled_df, aes(x = time_value, y = value, color = signal)) +
  geom_line() +
  scale_color_manual(breaks = names, values = colors) +
  labs(x = "Date", y = "Signal value (scaled)") +
  scale_x_date(date_breaks = "3 months", date_labels = "%b %Y",
               date_minor_breaks = "1 month") +
  theme_bw() +
  theme(legend.position = "bottom", legend.title = element_blank())

#ggsave("fig_covidcast_signals/time_trends_national.pdf", width = 5, height = 3)
```
<div style="text-align: center;">
<small>[Figure 1 from Reinhart et al. (2021)](https://www.pnas.org/doi/10.1073/pnas.2111452118)</small>
</div>

**Takeaway:** The auxiliary signals track changes in the official reported cases quite well. This is clearer when they have all been placed on the same range as reported cases per 100,000 people.
-->


<!-- Not panel data, 2 signals, same location, over time (bivariate time-series)
## Examples of panel data - COVID-19 cases and deaths in CA
* [**Takeaway**]{.primary}: Cases appear to strongly correlate with deaths several weeks later.
* We'll see this again in an upcoming session...

```{r plot-ca-cases-deaths}
#| echo: false
source(here::here("_code/ca_cases_deaths.R"))
ggplot(ca |> 
         mutate(deaths = trans21(deaths)) |>
         pivot_longer(cols = c(cases, deaths), names_to = 'name'),
       aes(x = time_value, y = value)) + 
  geom_line(aes(color = name), key_glyph = "timeseries") +
  scale_color_delphi() +
  scale_y_continuous(
    expand = expansion(c(0, 0.05)),
    name = "Incident cases per 100k people", 
    limits = range1,
    sec.axis = sec_axis(
      transform = trans12, 
      name = "Incident deaths per 100k people")) +
  labs(x = "Date") +
  theme(legend.position = "right", legend.title = element_blank()) 
```

-->



# Versioned Data

## Intro to versioned data

* Many epidemic aggregates are subject to [reporting delays and revisions]{.primary}

* This is because individual-level data has delayed availability:
    
[Person comes to ER â†’ Has some tests â†’ Admitted â†’ Tests come back â†’ Entered into the system â†’ ...]{.fourth-colour}

* So, a "Hospital admission" may not attributable to a particular condition
until a few days have passed (the patient may even have been released)

* Aggregated data have a longer pipeline from the incident to the report.

* So we have to track both: [when the event occurred]{.primary} and 
[when it was reported]{.primary}

* Additionally, various mistakes lead to revisions

* This means there can be [many different values]{.primary} for the same date

## Versioned data

* The event time is indicated by `time_value` (aka `reference_date`)

* Now, we add a second time index to indicate the data `version` (aka `reporting_date`)

* `version` = the time at which we saw a particular `value` associated to a `time_value`
```{r versioned-ca-ex}
#| echo: false
dv_archive <- dv_versioned_panel |>
  as_epi_archive(compactify = TRUE)
dv_ca <- dv_archive$DT |> filter(geo_value == "ca")
head(dv_ca) |> as_tibble()
```

* Note that this feature can be indicated in different ways (ex. `version`, `issue`, `release`, `as_of`). 

## Versioned panel data
Estimated percentage of outpatient visits due to CLI across multiple versions.

<!--
with updates and revisions to past data as new issue dates are released:
-->


```{r versioned-panel-multi-states-ex-2}
#| fig-width: 7
dv_final <- dv_versioned_panel_final
max_version <- max(dv_archive$DT$version)
versions <- seq(as.Date("2020-06-01"), max_version - 1, by = "1 week")
weekly_snapshots <- map(versions, function(v) {
  epix_as_of(dv_archive, v) %>% mutate(version = v)
}) |> list_rbind()
weekly_snapshots |>
  filter(geo_value %in% c("ca", "fl")) |>
  ggplot(aes(x = time_value, y = percent_cli)) +
  facet_wrap(~geo_value) +
  geom_line(aes(color = version, group = factor(version))) +
  # geom_vline(aes(color = factor(version), xintercept = version), lty = 3) +
  geom_line(data = dv_final |> filter(geo_value %in% c("fl", "ca")), color = "black") +
  labs(x = "Reference date", y = "% doctor's visits with CLI") +
  expand_limits(y = 0) +
  scale_x_date(date_labels = "%m/%Y", expand = expansion(0)) +
  scale_y_continuous(expand = expansion(c(0, 0.05))) +
  theme_bw() +
  scale_color_viridis_c(trans = "date", labels = label_date(format = "%m/%Y"), name = "Version") 
```

## Latency and revision in signals

* [**Latency**]{.primary} the delay between data collection and availability

**Example**: A signal based on insurance claims may take several days to appear as claims are processed

* [**Revision**]{.primary} data is updated or corrected after initial publication

**Example**: COVID-19 case reports are revised reporting backlogs are cleared

## Latency and revision in signals - Example

* Recall the first example of panel & versioned data we've seen... 

* This signal is 4 days [**latent**]{.primary}: `min(version - time_value)`

```{r latency-ca-ex}
#| echo: false
x_dt_with_diff <- dv_ca |> mutate(version_time_diff = version - time_value) 
head(x_dt_with_diff |> group_by(time_value) |> slice(1) |> ungroup()) 
```

* And subject to [**revision**]{.primary} <!--over time (ex. consider Dec. 1's `percent_cli` across `version`):-->

```{r revision-ca-ex}
#| echo: false
head(x_dt_with_diff) |> as_tibble()
```

<!-- min_lag: the minimum time to any value min(as.integer(version) - as.integer(time_value)  -->
<!-- max_lag: the amount of time until the final (new) version -->
<!-- revision_summary computes some basic statistics about the revision behavior of an archive, returning a tibble summarizing the revisions per time_value+epi_key features. -->

## Revision triangle, Outpatient visits in WA 2022 

* 7-day trailing average to smooth day-of-week effects

```{r revision-triangle}
#| echo: false
#| dpi: 300
#| fig-format: png
#| fig-width: 7
dv_cli <- left_join(dv_wa_versioned, dv_wa_finalized, by = join_by(time_value)) |>
  mutate(value = zoo::rollmeanr(value, k = 7, na.pad = TRUE), 
         final_value = zoo::rollmeanr(final_value, k = 7, na.pad = TRUE),
         .by = issue)

p1 <- dv_cli |>
  filter(time_value > ymd("2021-12-31"), issue >= "2021-12-31") |>
  ggplot(aes(time_value, issue, fill = value / final_value * 100)) +
  geom_tile() +
  scale_x_date(expand = expansion(), name = "Reference date") +
  scale_y_date(expand = expansion(), name = "Report date") +
  scale_fill_viridis_c(
    name = "% final", 
    option = "B",
    direction = -1
  ) +
  theme_bw() +
  theme(legend.position = "bottom", legend.key.width = unit(1, "cm")) 

p2 <- dv_cli |>
  filter(issue >= "2021-12-31", time_value > ymd("2021-12-31")) |>
  ggplot(aes(time_value)) +
  geom_line(aes(y = value, colour = issue, group = issue)) +
  scale_x_date(expand = expansion(), name = "Reference date") +
  scale_y_continuous(
    expand = expansion(), 
    name = "% Outpatient visits b/c CLI",
  ) +
  scale_colour_viridis_c(
    name = "Report Date", 
    direction = -1,
    trans = "date",
    labels = scales::label_date("%b %d"),
    option = "B"
  ) +
  geom_line(aes(y = final_value), color = "black") +
  theme_bw() +
  theme(legend.position = "bottom", legend.key.width = unit(1, "cm")) 

cowplot::plot_grid(p1, p2)
```

## Revisions
Many data sources are subject to revisions:

* Case and death counts are frequently corrected or adjusted by authorities

* Medical claims can take weeks to be submitted and processed

<!--* In the previous slide's example because doctor's visits may be reported to the health system partners several days after they occur, these signals are typically available with several days of lag. This means that estimates for a specific day are only available several days later. -->

* Lab tests and medical records can be backlogged

* Surveys are not completed promptly

[An accurate revision log is crucial for researchers building forecasts]{.primary}

::: {.callout-important}
## Obvious but crucial

A forecast that is made today can only use data we have access to today
:::

## Three types of revisions

1. [**Sources that don't revise**]{.primary} (provisional and final are the same) 

Facebook Survey and Google symptoms

2. [**Predictable revisions**]{.secondary} 

Claims data (CHNG) and public health reports aligned by test, hospitalization, 
or death date

Almost always revised upward as additional claims enter the pipeline

3. [**Revisions that are large and erratic to predict**]{.tertiary} 

COVID cases and deaths

These are aligned by report date 

<!-- (which can be highly variable & less predictable compared to test data). -->

## Types of revisions - Comparison between 2. and 3.

* Revision behavior for two indicators in the HRR containing Charlotte, NC.

<!-- Each colored line corresponds to the data as reported on a particular date (as of dates varying from 28 September through 19 October). -->
* [**DV-CLI signal (left)**]{.secondary}: regularly revised, but effects fade

* [**JHU CSSE cases (right)**]{.tertiary} remain "as first reported" until a major correction is made on Oct. 19


```{r fig1-McDonald}
#| echo: false
#| fig-width: 7
# This is Figure 1 from https://www.pnas.org/doi/pdf/10.1073/pnas.2111453118
p1 <- dv_311_as_of |>
  mutate(as_of = fct_relabel(factor(as_of), function(x) strftime(x, "%b %d"))) |>
  ggplot(aes(x = time_value, y = value)) + 
  geom_line(aes(color = factor(as_of))) + 
  labs(title = "DV-CLI", x = "", y = "% doctor's visits due to CLI",
       color = "As of:") +
  theme_bw() + 
  scale_color_viridis_d(end = .9, begin = .1)

p2 <- cases_311_as_of |>
  mutate(as_of = fct_relabel(factor(as_of), function(x) strftime(x, "%b %d"))) |>
  ggplot(aes(x = time_value, y = value)) + 
  geom_line(aes(color = factor(as_of))) + 
  labs(title = "Cases", x = "", y = "Cases per 100,000 people",
       color = "As of:") +
  theme_bw() + 
  scale_color_viridis_d(end = .9, begin = .1)

suppressWarnings(leg <- cowplot::get_legend(
  p1 + 
    theme(legend.margin = margin(0,12,0,12), legend.background = element_blank())
))

cowplot::plot_grid(
  p1 + theme(legend.position = "none"), 
  p2 + theme(legend.position = "none"),
  leg,
  nrow = 1,
  rel_widths = c(1, 1, .3)
)
```

<!--
<div style="text-align: center;">
<small>[Figure 1 from McDonald et al. (2021)](https://www.pnas.org/doi/pdf/10.1073/pnas.2111453118)</small>
</div>
-->
## Key takeaways

Medical claims revisions
: More systematic and predictable

<br><br>

COVID-19 case report revisions
: Erratic and often unpredictable

<br><br>

Large spikes or anomalies can occur as
: Reporting backlogs are cleared
: Changes in case definitions are implemented

## Reporting backlogs - Example

In Bexar County, Texas, during the summer of 2020...

* Large backlog of case reports results in a spike
* Auxilliary signals show no such dramatic increase
* Reports themselves may not be trustworthy without context

<!--

* **Left**: On July 16, 4,810 [backlogged cases]{.primary} were reported, reflecting a 2-week delay. This caused a prolonged spike due to the 7-day trailing average applied to the counts.

* **Right**: CTIS estimates of CLI-in-community showed more stable underlying trends.

-->

```{r fig4-Reinhart}
#| echo: false
#| message: false
#| fig-width: 7.5
#| fig-height: 3

# Similar to Figure 4 from https://www.pnas.org/doi/10.1073/pnas.2111452118

sa_anomaly_date <- as.Date("2020-07-16")
sa_cross <- reinhart[[1]]$value[33]
sa_scale <- sd(reinhart[[1]]$value, na.rm = TRUE)
reinhart[-1] <- map(
  reinhart[-1], 
  ~ mutate(.x, value = (value - value[33]) / sd(value, na.rm = TRUE) *
             sa_scale + sa_cross
  )
)
reinhart <- list_rbind(reinhart)

g1 <- ggplot(reinhart |> filter(source == "jhu-csse"), aes(x = time_value, y = value)) +
  geom_vline(xintercept = sa_anomaly_date, color = "gray", linetype = "dashed",
             alpha = 0.75) +
  scale_x_date(date_breaks = "1 month", date_labels = "%b %Y") +
  geom_line() +
  labs(x = "", y = "Cases", title = "Cases") +
  theme_bw()

labels <- c(
  `fb-survey` = "Survey-based CLI",
  chng = "Outpatient CLI",
  `google-symptoms` = "Google searches",
  `doctor-visits` = "Insurance claims"
)


g2 <- reinhart |>
  filter(source != "jhu-csse") |>
  ggplot(aes(x = time_value, y = value, color = source)) +
  geom_vline(xintercept = sa_anomaly_date, color = "gray", linetype = "dashed",
             alpha = 0.75) +
  scale_x_date(date_breaks = "1 month", date_labels = "%b %Y") +
  geom_line() +
  scale_color_delphi(labels = labels, name = "") +
  labs(x = "", y = "Signal value (rescaled)", title = "Auxiliary signals") +
  theme_bw()

cowplot::plot_grid(g1, g2, ncol = 2, rel_widths = c(.38, .62))
```

## Reporting backlogs - Key takeaways

<br><br>

* [Reporting issues common across U.S. jurisdictions]{.primary}

<br><br>

* [Audits regularly discovered misclassified or unreported cases and deaths]{.primary}

<br><br>

* [Cross-checking data with external sources from different reporting systems]{.primary}


# Epidata Repository and API

## What is the Epidata repository

[**Epidata:**]{.primary} repository of aggregated epi-surveillance time series

Code is open-source. Signals can be either public or restricted.

* To date, it has accumulated over 5 billion records.

* At the peak of the pandemic, handled millions of API queries per day.

* Many aren't available elsewhere

Data from
: public health reporting, medical insurance claims, medical device data, Google search queries, wastewater, app-based mobility patterns.

<br>

Added value
: revision tracking, anomaly detection, trend detection, smoothing, imputation, geo-temporal-demographic disaggregation.


## Goals of Delphi Epidata platform and repository

1. **Provide many aggregated epi-surveillance time-series ("epi-signals")**
    + Mirror signals from other sources, especially if revisions are not tracked <!-- E.g. CDC's own NSSP, NWSS -->
    + Be the national historical repository of record & preserve the raw data
    
<!-- Hence: include also signals available elsewhere, especially if they don't keep data revisions - E.g. CDC's own NSSP, NWSS -->

2. **Be the go-to place for epi-signal discovery, including those held elsewhere**

3. **Add value to existing signals and synthesize new ones**
    + Via signal fusion, nowcasting, smoothing


::: {.callout-important appearance="simple"}
Make epi-surveillance more nimble, complete, standardized, robust, and real-time
:::




## Features of Delphi Epidata

* Built-in support for:
    1. Data revisions ("backfill"), including reporting dates and changes
    1. Geo levels w/ auto-aggregation (e.g. county, state, and nation) and specialized levels (e.g., DMA, sewer sheds)
    1. Demographic breakdown
    1. Representation for missingness and censoring
    1. Population sizes and fine-grained population density
    
* Pre-computed smoothing and normalization (customization planned)

* Access control

* Code is Open Source.  

* Signals are as accessible (w/ API, SDK) as allowed by DUAs

## Epidata Documentation

<br>

[Delphi's Epidata API](https://cmu-delphi.github.io/delphi-epidata/) real-time access to epidemiological surveillance data

<br>

The [main endpoint](https://cmu-delphi.github.io/delphi-epidata/api/covidcast.html) (covidcast) daily updates about COVID-19 and influenza in the U.S.

<br>

A [variety of other endpoints](https://cmu-delphi.github.io/delphi-epidata/api/README.html) international historical data for COVID-19, influenza, dengue, norovirus


## Some of our data sources


### Ongoing Sources:

Insurance claims
: %Covid `{inpatient, outpatient}`, by `county x day`

Google Symptom searches
: 7 symptoms groups, by `county x day`

Quidel/Ortho antigen tests
: %Covid by `age group x county x day`

NCHS Deaths
: all-cause, pneumonia, flu, Covid, by `state x week`

NSSP ED visits
: %Covid, %flu, %RSV, by `county x week`  (new!)

NWSS Covid
: wastewater by `sampling-site x day`  (in progress)

## Some of our data sources
### Active during pandemic, could be restarted for the next PHE:

HHS Hosp/ICU beds
: Covid, flu, by `{age-group x {state x day, facility x week}}`

CTIS ("Delphi Facebook Survey")
: many dozens of questions, by `county x day`

STLT-reported
: `{cases, deaths}` via `{JHU, USAFacts}`, by `country x day`

Safegraph mobility
: misc measures by `{county x day, county x week}`



## Severity pyramid

![](gfx/severity-pyramid.svg){fig-align=center}



# Find Data Sources & Signals

## Finding data sources and signals of interest

Diverse Data Streams

* [**Variety of Data**]{.primary}: medical claims data, cases and deaths, mobility data
* [**Geographic Coverage**]{.primary}: includes multiple regions, making it comprehensive yet complex
* [**Challenge**]{.primary}: difficulty in pinpointing the specific data stream of interest

Using the Documentation

* [**Comprehensive Listings**]{.primary}: details on data sources and signals for [various endpoints](https://cmu-delphi.github.io/delphi-epidata/api/covidcast_signals.html)

Docs are great for a deep dive into the data, while the apps & tools are useful to see what's available...




## Some tools to explore more easily


[Signal discovery app](https://delphi.cmu.edu/signals/), find available epi-signals in Delphi Epidata and elsewhere in the community

<br>

[Signal visualization tool](https://delphi.cmu.edu/epivis/)

<br>
[Signal dashboard](https://delphi.cmu.edu/covidcast/)  

<br>
"classic" [map-based version](https://delphi.cmu.edu/covidcast/classic/) visualize a core set of COVID-19 and flu indicators

<br>
[Covidcast signal export app](https://delphi.cmu.edu/covidcast/export/)
 
<br>
[Dashboard builder](https://delphi.cmu.edu/covidcast/dashboard/)





# `{epidatr}`


## Installing `{epidatr}`

(you already did this, but just for posterity...)

Install the CRAN version

```{r install-epidatr-cran}
#| echo: true
#| eval: false
# Install the CRAN version
pak::pkg_install("epidatr")
```

<br>

or the development version

```{r install-epidatr-dev}
#| eval: false
#| echo: true
# Install the development version from the GitHub dev branch
pak::pkg_install("cmu-delphi/epidatr@dev")
```

The CRAN listing is [here](https://cran.r-project.org/package=epidatr/index.html).

## Python

In Python, install [`delphi-epidata` from PyPI](https://pypi.org/project/delphi-epidata/) with 

``` sh
pip install delphi-epidata
```

<br>

`delphi-epidata` is soon to be replaced with `epidatpy`.

``` sh
# Latest dev version
pip install -e "git+https://github.com/cmu-delphi/epidatpy.git#egg=epidatpy"

# PyPI version (not yet available)
pip install epidatpy
```




## Using `{epidatr}` and `{epidatpy}`

```{r hhs-influenza-pub-covidcast}
#| echo: true
#| eval: false
library(epidatr)
hhs_flu_nc <- pub_covidcast(
  source = 'hhs', 
  signals = 'confirmed_admissions_influenza_1d', 
  geo_type = 'state', 
  time_type = 'day', 
  geo_values = 'nc',
  time_values = c(20240401, 20240405:20240414)
)
head(hhs_flu_nc, n = 3)
```

```{r hhs-influenza-pub-covidcast-2}
#| echo: false
head(hhs_flu_nc, n = 3)
```

<br>

Python equivalent:
``` python
res = Epidata.covidcast('hhs', 'confirmed_admissions_influenza_1d', 'day', 'state', [20240401, Epidata.range(20240405, 20240414)], 'nc')
print(res['result'], res['message'], len(res['epidata']))
```



## API keys

* Anyone may access the Epidata API anonymously without providing any personal data!!

* Anonymous API access is subject to some restrictions:
  <small>public datasets only; 60 requests per hour; only two parameters may have multiple selections</small>

* API key grants privledged access; can be obtained by [registering with us](https://api.delphi.cmu.edu/epidata/admin/registration_form) 

* Privileges of registration: no rate limit; no limit on multiple selections

* We just want to know which signals people care about and ensure we're providing benefit

<!-- rate limited to 60 requests per hour;  -->
::: {.callout-tip}
* The `{epidatr}` client automatically searches for the key in the `DELPHI_EPIDATA_KEY` environment variable. 
* We recommend storing it in your `.Renviron` file, which R reads by default. 
* More on setting your API key [here](https://rdrr.io/cran/epidatr/man/get_api_key.html).
:::




## Interactive tooling in R 

[**Find sources and signals in R?**]{.primary}

Functions to enhance data discovery in `{epidatr}`:

`avail_endpoints()`
: Lists all endpoints with brief descriptions
: Highlights endpoints that cover non-US locations

```{r avail-endpoints-fun}
#| echo: true
avail_endpoints()
```

##  Using the `covidcast_epidata()`

`covidcast_epidata()` details for signals at the COVIDcast endpoint

<!-- detailed insights into data sources from the COVIDcast endpoint. -->

Assign to an object 

``` r
cc_ed <- covidcast_epidata()
```

List data sources
: `cc_ed$sources`, with tibbles describing the included signals
    
Editor Support
: In RStudio or similar editors, use tab completion to explore:
: `cc_ed$source$` to view available data sources.
: `cc_ed$signals$` to see signal options with autocomplete assistance.
        
Filtering Convenience
: Signals are prefixed with their source for easier navigation

``` r
cc_ed <- covidcast_epidata()
head(cc_ed$sources, n = 2) # head(list, n = 2) will print the first two elements of the list
```

## Fetching data - COVIDcast main endpoint 

<br>

### `pub_covidcast()` accesses the `covidcast` endpoint

Need to specify the following arguments...

1. `source`: Data source name
1. `signals`: Signal name
1. `geo_type`: Geographic level 
1. `time_type`: Time resolution
1. `geo_values`: Location(s)
1. `time_values`: times of interest


## Fetching data - COVIDcast main endpoint 

```{r us-jhu-pub-covidcast}
#| echo: true
#| eval: false
library(epidatr)
library(dplyr)

jhu_us_cases <- pub_covidcast(
  source = "jhu-csse",
  signals = "confirmed_7dav_incidence_prop", 
  geo_type = "nation",
  time_type = "day",
  geo_values = "us",
  time_values = epirange(20210101, 20210401)
)
```

```{r head-us-jhu-pub-covidcast}
#| echo: false 
head(jhu_us_cases, n = 3) |> 
  select(geo_value, signal, source, geo_type, time_value, issue, lag, value)
```

`value` is the requested signal

* the number of daily new confirmed COVID-19 cases per 100,000 population
* from January to April 2021 <!-- (and standard error if it is applicable to the metric). -->


## Returned data - COVIDcast main endpoint 

`pub_covidcast()` outputs a tibble, where each row represents one observation

Each observation is aggregated by time and by geographic region

1. `time_value`: time period when the events occurred.
1. `geo_value`: geographic region where the events occurred.
1. `value`: estimated value.
1. `stderr`: standard error of the estimate, usually referring to the sampling error.
1. `sample_size`: number of events used in the estimation.

<!--For example, a number of COVID-19 antigen tests were performed in the state of New York on August 1. The `time_value` would be August 1, with `geo_value` indicating the state of New York, while the remaining fields would give the estimated test positivity rate (the percentage of tests that were positive for COVID-19), its standard error, and the number of tests used to calculate the estimate.-->

## Returned data - COVIDcast main endpoint 

[Also reports]{.primary}

* `issue`: The time this observation was published

* `lag`: The period between when the events occurred and when the observation was published

Tracks the complete revision history of the signal

Allows for historical reconstructions of information that was available at a specific times

[**More on this soon!**]{.primary}

<!-- * Meaning that unlike most other sources of COVID data, it tracks the complete revision history of the signal. -->
## Geographic levels

Signals are available at different geographic levels, depending on the endpoint

`confirmed_7dav_incidence_prop` is available by state

Change `geo_type` and `geo_values` in the previous example

```{r state-jhu-pub-covidcast}
#| echo: true
#| eval: false
# Obtain the most up-to-date version of the smoothed covid-like illness (CLI)
# signal from the COVID-19 Trends and Impact survey for all states
jhu_state_cases <- pub_covidcast(
  source = "jhu-csse",
  signals = "confirmed_7dav_incidence_prop",
  geo_type = "state",
  time_type = "day",
  geo_values = "*",
  time_values = epirange(20210101, 20210401)
)
```

```{r head-state-jhu-pub-covidcast}
#| echo: false
head(jhu_state_cases) |> 
  select(geo_value, signal, source, geo_type, time_value, issue, lag, value)
```


## COVIDcast main endpoint - Example query 

County `geo_values` are [FIPS codes](https://en.wikipedia.org/wiki/List_of_United_States_FIPS_codes_by_county): Orange County, California. 

```{r county-jhu-pub-covid}
#| echo: true
#| eval: false
jhu_county_cases <- pub_covidcast(
  source = "jhu-csse",
  signals = "confirmed_7dav_incidence_prop",
  geo_type = "county",
  time_type = "day",
  time_values = epirange(20210101, 20210401),
  geo_values = "06059"
)
```

```{r head-county-jhu-pub-covid}
#| echo: false
head(jhu_county_cases) |>
  select(geo_value, signal, source, geo_type, time_value, issue, lag, value)
```

::: {.callout-important appearance="simple" icon="false"}

The `covidcast` endpoint supports `*` in its time and geo fields. 

Signal values for all available counties: replace `geo_values = "06059"` with `geo_values = "*"`.
:::

## Example queries - Other endpoints: Hospitalizations

[**COVID-19 Hospitalization: Facility Lookup**]{.primary}

<small> API docs: <https://cmu-delphi.github.io/delphi-epidata/api/covid_hosp_facility_lookup.html> </small>

```{r hosp-facility-lookup}
#| echo: true
pub_covid_hosp_facility_lookup(city = "southlake")
```

```{r hosp-facility-lookup-wy}
#| echo: true
pub_covid_hosp_facility_lookup(state = "WY") |> head()
# A non-example (there is no city called New York in Wyoming)
# pub_covid_hosp_facility_lookup(state = "WY", city = "New York")
```


## Example queries - Other endpoints: Hospitalizations

[**COVID-19 Hospitalization by Facility**]{.primary}

<small> API docs: <https://cmu-delphi.github.io/delphi-epidata/api/covid_hosp_facility.html> </small>
```{r hosp-by-facility}
#| echo: true
pub_covid_hosp_facility(
  hospital_pks = "100075",
  collection_weeks = epirange(20200101, 20200501)
) |> head()
```

## Example queries - Other endpoints: Hospitalizations

[**COVID-19 Hospitalization by State**]{.primary}

<small> API docs: <https://cmu-delphi.github.io/delphi-epidata/api/covid_hosp.html> </small>
```{r hosp-by-state}
#| echo: true
pub_covid_hosp_state_timeseries(states = "MA", dates = "20200510")
```

## Example queries - Other endpoints: Flu endpoints

[**FluSurv hospitalization data**]{.primary} -- Data ends around 2020

<small> API docs: <https://cmu-delphi.github.io/delphi-epidata/api/flusurv.html> </small>
```{r flusurv}
#| echo: true
#| results: hide
pub_flusurv(locations = "ca", epiweeks = 202001) 
```

[**Fluview data**]{.primary} -- Remains active

<small> API docs: <https://cmu-delphi.github.io/delphi-epidata/api/fluview.html> </small>
```{r fluview}
#| echo: true
#| results: hide
pub_fluview(regions = "nat", epiweeks = epirange(201201, 202001))
```

::: {.callout-tip}
## Public vs private endpoints

Public endpoints are accessed with functions starting with `pub_`

Private data can be used with `pvt_` for authorized API keys

Store the key in your `.Reviron` file, or set is as an environment variables

[Examples](https://cmu-delphi.github.io/epidatr/articles/signal-discovery.html)
:::

<!-- Aside from these public methods (starting with `pub_`),
there are private methods (starting with `pvt_` when you type `avail_endpoints()`) that require private access keys. To run these locally, store the keys in your `.Reviron` file, or set them as environmental variables.
See [Private methods](https://cmu-delphi.github.io/epidatr/articles/signal-discovery.html) for examples of using private endpoints. -->

## Signal metadata

Some endpoints provide additional metadata

* [**Time Information**]{.primary}: available time frames and most recent update
* [**Geography Information**]{.primary}: available geographies 

Metadata accessors

* `pub_covidcast_meta()`: metadata for COVIDcast
* `pub_fluview_meta()`: metadata for FluView
* `pub_meta()`: general metadata for the Delphi Epidata API

# Versioning in `{epidatr}`

## Versioned data in `{epidatr}`

Epidata API contains each signal's estimate, location, date, and update timeline

Requesting Specific Data Versions:

* Use `as_of` or `issues` to specify data availability
* `as_of` always fetches one version
* `issues` can fetch multiple
* Only one may be used at a time
* Not all endpoints support both


## Obtaining data "as of" a specific date

[Doctor Visits](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/doctor-visits.html) (from the `covidcast` endpoint)

* The percentage of outpatient visits w/ Covid-like illness
* Pennsylvania on May 1, 2020:

```{r pa-may-1st-as-of}
#| echo: true
#| eval: false
dv_pa_as_of <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = "2020-05-01",
  geo_type = "state",
  geo_values = "pa",
  as_of = "2020-05-07"
)
```

```{r head-pa-may-1st-as-of}
#| echo: false
head(dv_pa_as_of) |> 
  select(geo_value, signal, source, time_value, issue, lag, value)
```

* Initial estimate *issued* on May 7, 2020 
* Due to delay from reporting and ingestion by the API

## Obtaining data "as of" a specific date

[Default behaviour:]{.primary} unspecified `as_of`, get the most recent data

```{r pa-may-1st-most-recent}
#| echo: true
#| eval: false
dv_pa_final <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = "2020-05-01",
  geo_type = "state",
  geo_values = "pa"
)
```

```{r head-pa-may-1st-most-recent}
#| echo: false
head(dv_pa_final) |> 
  select(geo_value, signal, source, time_value, issue, lag, value, stderr)
```

[**Estimate changed substantially**]{.primary}:

* Increased to ~6% from <3%
    
## Versioning is important for forecasting

<br>

* Backtesting requires using data that would have been available at the time

<br>

* Not later updates

<br>

* Overly optimistic


## Obtaining multiple specific issues for one state
Request all issues in a certain time period

```{r pa-multiple-issues}
#| echo: true
#| eval: false
#| code-line-numbers: "1,8,9"
dv_pa_issues <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = "2020-05-01",
  geo_type = "state",
  geo_values = "pa",
  issues = epirange("2020-05-01", "2020-05-15")
)
```

```{r head-pa-multiple-issues}
#| echo: false 
head(dv_pa_issues) |> 
  select(geo_value, signal, source, time_value, issue, lag, value, stderr)
```

## Obtaining multiple issues for one state

To get all issues up to a specific date, set an extreme lower bound

```{r extreme-lb-multiple-issues}
#| echo: true
#| eval: false
#| code-line-numbers: "1,8,9"
dv_pa_issues_sub <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = "2020-05-01",
  geo_type = "state",
  geo_values = "pa",
  issues = epirange("1900-01-01", "2020-05-15")
)
```

```{r head-extreme-lb-multiple-issues}
#| echo: false
head(dv_pa_issues_sub) |> 
  select(geo_value, signal, source, time_value, issue, lag, value, stderr)
```

No change here â€¢ Can matter if the latency or reporting lag is unknown

[API docs](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/doctor-visits.html)
show the earliest date available.

## Obtaining multiple issues for one state

At some point, nothing changes â€¢ It is [finalized]{.primary} â€¢ That will be the "last" issue

```{r extreme-lb-ub-multiple-issues}
#| echo: true
#| eval: false
#| code-line-numbers: "1,8,9"
dv_pa_issues_all <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = "2020-05-01",
  geo_type = "state",
  geo_values = "pa",
  issues = epirange("1900-01-01", "2024-12-11") # From the 1900s to today
)
```

```{r head-extreme-lb-ub-multiple-issues}
#| echo: false
tail(dv_pa_issues_all) |> 
  select(geo_value, signal, source, time_value, issue, lag, value, stderr)
```

* Avoid queries with too-late minimum too-early maximum issue
* Could be misleading results

<!-- * We caution against starting queries with too late a minimum issue or too early maximum issue, as it could lead to incorrect or misleading results. You're safest bet to capture all issues is on the next slide... -->

## Obtaining all issues for one state


```{r pa-all-issues}
#| echo: true
#| eval: false
#| code-line-numbers: "1,5,8,9"
dv_pa_issues_star <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = epirange("2020-05-01", "2020-05-07"),
  geo_type = "state",
  geo_values = "pa",
  issues = "*"
)
```

```{r head-pa-all-issues}
#| echo: false
head(dv_pa_issues_star, n = 8) |> 
  select(geo_value, signal, source, time_value, issue, lag, value, stderr)
```

## Obtaining all issues for all states

Using `*` gives all available

```{r all-the-states-and-issues}
#| echo: true
#| eval: false
#| code-line-numbers: "1,7-9"
dv_state_issues_star <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = epirange("2020-05-01", "2020-05-07"),
  geo_type = "state",
  geo_values = "*",
  issues = "*"
)
```

```{r head-all-the-states-and-issues}
#| echo: false
head(dv_state_issues_star) |> 
  select(geo_value, signal, source, time_value, issue, lag, value, stderr)
```


<!--

## Last but not least... The do nothing approach 

![](gfx/do-nothing.jpg){height="550px"}



## The do nothing approach 

* `geo_values = *` is the default
* `issues` defaults to "most recent"


```{r do-nothing}
#| echo: true
#| eval: false
dv_state_default <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = epirange("2020-05-01", "2020-05-07"),
  geo_type = "state"
)
```

-->

## Obtaining one issue for all states

<!--
[**Final question:**]{.primary}  What do you think happens when we adopt a "do nothing" approach to `geo_values` and `issues` (take both of them out)?

<small> [**Hint**]{.primary}: remember a couple slides ago, when we removed `as_of`, we got the most recent estimate for PA. </small>
-->

Defaults are intended to be "what you would expect"

```{r one-issue-all-states}
#| echo: true
#| eval: false
dv_state_default <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = epirange("2020-05-01", "2020-05-07"),
  geo_type = "state"
)
```

```{r head-one-issue-all-states}
#| echo: false
head(dv_state_default) |> 
  select(geo_value, signal, source, time_value, issue, lag, value, stderr)
```

<hr>

* most recent issue
* all states


<!-- ## Observations issued with a specific lag
<div style="font-size: 0.8em;">
* We can use the `lag` argument to request only data reported with a certain lag. 

* **Example**: Request  a lag of 7 days fetches only data issued exactly 7 days after the corresponding `time_value`:

```{r specific lag}
#| echo: false
#| eval: false
epidata <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = epirange("2020-05-01", "2020-05-07"),
  geo_type = "state",
  geo_values = "pa",
  lag = 7
)
```

```{r}
#| echo: false
#| eval: false
head(epidata) |> select(geo_value, signal, source, time_value, issue, lag, value, stderr)
```
</div>

## Query results exclusion
<div style="font-size: 0.8em;">
* Although the query we ran on the previous slide requested values from May 1 to May 7, May 3 and May 4 were not included due to a 7-day lag.

* Results for those dates appear only if updates are issued on the corresponding lag day (e.g., May 10).

```{r query results exclusion}
#| echo: false
#| eval: false
epidata <- pub_covidcast(
  source = "doctor-visits",
  signals = "smoothed_adj_cli",
  time_type = "day",
  time_values = epirange("2020-05-03", "2020-05-03"),
  geo_type = "state",
  geo_values = "pa",
  issues = epirange("2020-05-09", "2020-05-15")
)
```

```{r}
#| echo: false
#| eval: false
head(epidata) |> select(geo_value, signal, source, time_value, issue, lag, value, stderr)
```
</div>
-->

## Main takeaways

* [**Delphi Epidata:**]{.primary} platform for real-time epidemic data
    * provides (aggregated) signals for tracking and forecasting
    * sources like [**health records**]{.secondary}, [**mobility patterns**]{.tertiary}, and [**more**]{.fourth-colour}.

<!-- * [**Delphi Epidata:**]{.primary} A one-stop platform for real-time epidemic data, providing aggregated signals for disease tracking and forecasting from diverse sources like health records, mobility patterns, and more. -->

* [**Epidata API:**]{.primary} delivers up-to-date, granular epidemiological data + historical versions.

<!-- Open-access API delivering up-to-date, granular epidemiological data + makes all historical versions available. -->

* `{epidatr}`:{.primary} Client package for R

<!-- and interactive tools for discovering and analyzing health signals. -->

* [**Versioned Data and Latency:**]{.primary}
    1. `as_of`:  One version; the specific date when the data was last updated 
    1. `issues`: Multiple versions; with different `as_of` dates
    
Manages the record of revisions for transparency and accuracy in data analysis.

<!-- Panel data captures time-series trends, which are often subject to revision.  A standout feature of this API is its inclusion of two critical fields... -->

<!-- 1. as_of:  One version of the data, and referring to the specific date when the data was last updated (i.e. the data was updated `as_of` this date) -->

<!-- 2. `issues`: Multiple versions of the data, each corresponding to different `as_of` dates, capturing revisions over time. --> 
