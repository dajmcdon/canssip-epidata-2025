[
  {
    "objectID": "slides/lecture4.html#outline",
    "href": "slides/lecture4.html#outline",
    "title": "EpiData Workshop 2025",
    "section": "Outline",
    "text": "Outline\n\nFundamentals of Forecasting\nEvaluation\nA Workflow for Forecasting\nAdvanced Customizations\nBuild a Forecaster from Scratch\nAdvanced Topics"
  },
  {
    "objectID": "slides/lecture4.html#forecasting-is-not-magic",
    "href": "slides/lecture4.html#forecasting-is-not-magic",
    "title": "EpiData Workshop 2025",
    "section": "Forecasting is not magic",
    "text": "Forecasting is not magic\n\nForecasts are generally comprised of two parts: trend and seasonality\nMethods for detecting and projecting trends are not magic; in general they’re not qualitatively that different from what you can do with your eyeballs\nThat said, assimilating information from exogenous features (ideally, leading indicators) can lead highly nontrivial gains, beyond the eyeballs\nRemember … good data is just as (more?) important as a good model!\nSeasonality can help short-term forecasts. Long-term forecasts, absent of strong seasonality, are generally not very tractable"
  },
  {
    "objectID": "slides/lecture4.html#basics-of-linear-regression",
    "href": "slides/lecture4.html#basics-of-linear-regression",
    "title": "EpiData Workshop 2025",
    "section": "Basics of linear regression",
    "text": "Basics of linear regression\n\nAssume we observe a predictor \\(x_i\\) and an outcome \\(y_i\\) for \\(i = 1, \\dots, n\\).\nLinear regression supposes\n\n\\[\\mathbb{E}[y_i\\ \\vert\\ x_i] \\doteq \\beta_0 + \\beta_1 x_i,\\quad i=1,\\dots,n.\\]\n\nIn R, run lm(y ~ x), where y is the vector of responses and x the vector of predictors.\n\n\n\nGiven \\(p\\) different predictors\n\n\\[\n\\begin{aligned}\n\\mathbb{E}[y_i\\ \\vert\\ \\mathbf{x}_i] &\\doteq \\beta_0 + \\beta_1 x_{i1} + \\dots + \\beta_p x_{ip}\\\\\n&= \\mathbf{x}^\\mathsf{T}_i\\beta &i=1,\\dots,n.\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/lecture4.html#linear-regression-with-lagged-predictor",
    "href": "slides/lecture4.html#linear-regression-with-lagged-predictor",
    "title": "EpiData Workshop 2025",
    "section": "Linear regression with lagged predictor",
    "text": "Linear regression with lagged predictor\n\nIn time series, outcomes and predictors are usually indexed by time \\(t\\).\n\n\n\nGoal: predict future \\(y\\), given present \\(x\\).\n\n\n\n\nModel: linear regression with lagged predictor\n\n\\[\\mathbb{E}[y_t\\ \\vert\\ x_{t-k}] \\doteq \\beta + \\beta_0 x_{t-k}\\]\n\n\n\nEquivalent way to write the model:\n\n\\[\\mathbb{E}[y_{t+k}\\ \\vert\\ x_t] \\doteq \\beta + \\beta_0 x_t\\]"
  },
  {
    "objectID": "slides/lecture4.html#autoregressive-exogenous-input-arx-model",
    "href": "slides/lecture4.html#autoregressive-exogenous-input-arx-model",
    "title": "EpiData Workshop 2025",
    "section": "Autoregressive exogenous input (ARX) model",
    "text": "Autoregressive exogenous input (ARX) model\n\nPredict the outcome via a linear combination of its (own) lags and exogenous predictors\n\n\\[\\mathbb{E}[y_{t+h}\\ \\vert\\ \\mathbf{y}_{\\leq t}, \\mathbf{x}_{\\leq t}] \\doteq\n\\phi + \\sum_{i=0}^p \\phi_i y_{t-i} + \\sum_{j=0}^q \\beta_j x_{t-j}\\]\n\nNotice: we don’t need to include all contiguous lags, and we could estimate e.g.,\n\n\\[\\mathbb{E}[y_{t+h}\\ \\vert\\ \\mathbf{y}_{\\leq t}, \\mathbf{x}_{\\leq t}] \\doteq  \\phi +\n\\phi_0 y_{t} + \\phi_1 y_{t-7} + \\phi_2 y_{t-14} +\n\\beta_0 x_{t} + \\beta_1 x_{t-7} + \\beta_2 x_{t-14}\\]"
  },
  {
    "objectID": "slides/lecture4.html#popular-forecasting-frameworks",
    "href": "slides/lecture4.html#popular-forecasting-frameworks",
    "title": "EpiData Workshop 2025",
    "section": "Popular forecasting frameworks",
    "text": "Popular forecasting frameworks\n\nAutoregressive integrated model average (ARIMA) models\nExponential smoothing with trend and seasonality (ETS)\nProphet forecaster\nDeepAR (neural network)\n\nFirst two here are classic and standard, second two are more recent.\nNone are particularly well-suited for epi forecasting out-of-the-box (ask me about them if you’re curious)\nI’ll briefly mention ARIMA as it’s closest to the setup so far."
  },
  {
    "objectID": "slides/lecture4.html#dissecting-arima",
    "href": "slides/lecture4.html#dissecting-arima",
    "title": "EpiData Workshop 2025",
    "section": "Dissecting ARIMA",
    "text": "Dissecting ARIMA\n\nAR\n\nautoregressive\n\n\ninclude lags of response as features\n\nMA\n\nmoving average\n\n\ninclude lags of noise terms\n\n\ncorrelated noise model\n\nI\n\nintegrated\n\n\nmodel and forecast differences between successive observations rather than levels"
  },
  {
    "objectID": "slides/lecture4.html#arima-vs-arx",
    "href": "slides/lecture4.html#arima-vs-arx",
    "title": "EpiData Workshop 2025",
    "section": "ARIMA vs ARX",
    "text": "ARIMA vs ARX\nThe way lags are handled\n\nIn what you’ve seen, we can include arbitrary lags\nCould use a different engine (regularized linear, or general functional form)\nTraditional AR models require lags to be contiguous (e.g., all of 0–14, instead of 0, 7, 14)\n\nThe way multi-step forecasts are made\n\nIn what you’ve seen, we model h-step ahead directly\nTraditional AR models only do 1-step ahead prediction, and iterate this to get forecasts at longer horizons"
  },
  {
    "objectID": "slides/lecture4.html#arima-vs-arx-1",
    "href": "slides/lecture4.html#arima-vs-arx-1",
    "title": "EpiData Workshop 2025",
    "section": "ARIMA vs ARX",
    "text": "ARIMA vs ARX\nThe way nonstationarity is handled\n\nIn what you’ve seen, we address nonstationarity via trailing training windows (or observation weights more generally)\nTraditional ARIMA models use the I component for this: remove linear or quadratic trends by differences, add them back in at prediction time\n\nThe way exogenous features are included\n\nIn what you’ve seen, they appear directly as an exogenous predictor\nTraditional ARIMA models (software, such as {fable}) includes them in a different manner; they are effectively subject to the same lags as the AR and MA terms"
  },
  {
    "objectID": "slides/lecture4.html#supplementary-time-series-resources",
    "href": "slides/lecture4.html#supplementary-time-series-resources",
    "title": "EpiData Workshop 2025",
    "section": "Supplementary time series resources",
    "text": "Supplementary time series resources\n\nHyndman and Athanasopoulos, Forecasting: Principles and Practice\nRyan Tibshirani’s course notes, Introduction to Time Series"
  },
  {
    "objectID": "slides/lecture4.html#error-metrics",
    "href": "slides/lecture4.html#error-metrics",
    "title": "EpiData Workshop 2025",
    "section": "Error metrics",
    "text": "Error metrics\n\nAssume we have predictions \\(\\hat y_{t}\\) for the unseen observations \\(\\tilde y_{t}\\) over times \\(t = 1, \\dots, N\\).\n\nFour commonly used error metrics for point forecasts:\n\nmean squared error (MSE)\nmean absolute error (MAE)\nmean absolute percentage error (MAPE)\nmean absolute scaled error (MASE)\n\nInterval metrics:\n\ncoverage\ninterval score\nweighted interval score"
  },
  {
    "objectID": "slides/lecture4.html#error-metrics-mse-and-mae",
    "href": "slides/lecture4.html#error-metrics-mse-and-mae",
    "title": "EpiData Workshop 2025",
    "section": "Error metrics: MSE and MAE",
    "text": "Error metrics: MSE and MAE\n\\[\\textrm{MSE} = \\frac{1}{N} \\sum_{t=1}^N (\\tilde y_{t}- \\hat y_{t})^2\\] \\[\\textrm{MAE} = \\frac{1}{N} \\sum_{t=1}^N |\\tilde y_{t}- \\hat y_{t}|\\]\n\nMAE gives less importance to extreme errors than MSE.\nMSE is not on the same scale as the data (squared units), use RMSE instead.\nDrawback: both metrics are scale-dependent, so they are not universally interpretable.\n(For example, if \\(y\\) captures height, MSE and MAE will vary depending on whether we measure in feet or meters.)"
  },
  {
    "objectID": "slides/lecture4.html#error-metrics-mape",
    "href": "slides/lecture4.html#error-metrics-mape",
    "title": "EpiData Workshop 2025",
    "section": "Error metrics: MAPE",
    "text": "Error metrics: MAPE\nFixing scale-dependence:\n\\[\\textrm{MAPE} = 100 \\times \\frac{1}{N} \\sum_{t=1}^N\n\\left|\\frac{\\tilde y_{t}- \\hat y_{t}}{\\tilde y_{t}}\\right|\\]\nDrawbacks\n\nErratic behavior when \\(\\tilde y_{t}\\) is close to zero\nAssumes the unit of measurement has a meaningful zero\n(e.g. using Fahrenheit or Celsius to measure temperature will lead to different MAPE)"
  },
  {
    "objectID": "slides/lecture4.html#error-metrics-mase",
    "href": "slides/lecture4.html#error-metrics-mase",
    "title": "EpiData Workshop 2025",
    "section": "Error metrics: MASE",
    "text": "Error metrics: MASE\n\\[\\textrm{MASE} = 100 \\times \\frac{\\frac{1}{N} \\sum_{t=1}^N\n|\\tilde y_{t}- \\hat y_{t}|}\n{\\frac{1}{N-1} \\sum_{t=2}^N\n|\\tilde y_{t}- y_{t-1}|}\\]\nAdvantages\n\nuniversally interpretable (not scale dependent)\navoids the zero-pitfall (unless the first difference is 0… )\n\nHeuristic description: normalize the error of our forecasts by that of a naive method which always predicts the last observation."
  },
  {
    "objectID": "slides/lecture4.html#comparing-mae-mse-mape-and-mase",
    "href": "slides/lecture4.html#comparing-mae-mse-mape-and-mase",
    "title": "EpiData Workshop 2025",
    "section": "Comparing MAE, MSE, MAPE and MASE",
    "text": "Comparing MAE, MSE, MAPE and MASE\n\n\n\n\n\n\n\nMAE\nRMSE\nMAPE\nMASE\n\n\n\n\nyhat1\n2.873\n4.024\n43.140\n66.100\n\n\nyhat2\n5.382\n9.689\n36.083\n123.817"
  },
  {
    "objectID": "slides/lecture4.html#interval-metrics-1",
    "href": "slides/lecture4.html#interval-metrics-1",
    "title": "EpiData Workshop 2025",
    "section": "Interval metrics",
    "text": "Interval metrics\nGiven a set of predictive intervals \\((l_t^{\\alpha_1}, u_t^{\\alpha_1}), \\dots, (l_t^{\\alpha_K}, u_t^{\\alpha_K}),\\quad t=1,\\dots,N\\)\nCoverage\n\\[\\textrm{Coverage}(\\alpha) = \\frac{1}{N} \\sum_{t=1}^N \\mathbf{1}(l_t^{\\alpha} \\leq \\tilde y_{t} \\leq u_t^\\alpha)\\]\nInterval Score\n\\[\\textrm{IS}(\\alpha) = \\frac{1}{N} \\sum_{t=1}^N \\alpha|u_t^\\alpha - l_t^\\alpha| + 2(l_t^\\alpha - \\tilde y_t)_+ + 2(\\tilde y_t - u_t^\\alpha)_+\\]\nWeighted Interval Score\n\\[\\textrm{WIS} = \\sum_{k=1}^K\\textrm{IS}(\\alpha_k)\\]"
  },
  {
    "objectID": "slides/lecture4.html#defining-the-error-metrics-in-r",
    "href": "slides/lecture4.html#defining-the-error-metrics-in-r",
    "title": "EpiData Workshop 2025",
    "section": "Defining the error metrics in R",
    "text": "Defining the error metrics in R\n\nMSE &lt;- function(obs, pred) mean((obs - pred)^2)\n\nMAE &lt;- function(obs, pred) mean(abs(obs - pred))\n\nMAPE &lt;- function(obs, pred) 100 * mean(abs(obs - pred) / obs)\n\nMASE &lt;- function(obs, pred) 100 * MAE(obs, pred) / mean(abs(diff(obs)), na.rm = TRUE)\n\nCoverage &lt;- function(obs, ql, qu) mean(obs &gt;= ql & obs &lt;= qu)\n\nIS &lt;- function(obs, ql, qu, alpha) alpha * mean(abs(qu - ql)) + 2 * pmax(ql - obs, obs - qu)"
  },
  {
    "objectID": "slides/lecture4.html#estimating-the-prediction-error",
    "href": "slides/lecture4.html#estimating-the-prediction-error",
    "title": "EpiData Workshop 2025",
    "section": "Estimating the prediction error",
    "text": "Estimating the prediction error\nGiven an error metric, we want to estimate the prediction error under that metric.\nMethods we’ll discuss briefly\n\nTraining error\nSplit-sample error\nTime series cross-validation error"
  },
  {
    "objectID": "slides/lecture4.html#training-error",
    "href": "slides/lecture4.html#training-error",
    "title": "EpiData Workshop 2025",
    "section": "Training error",
    "text": "Training error\n\nThe easiest but worst estimate of the prediction error\nThe training error is\n\ngenerally too optimistic as an estimate of prediction error\nmore optimistic the more complex the model!\n\n\nTraining MSE\n\\[\\text{TrainMSE} = \\frac{1}{N-h} \\sum_{t = 1}^{N-h} (\\hat y_{t+h|N} - y_{t+h})^2\\]"
  },
  {
    "objectID": "slides/lecture4.html#split-sample-error",
    "href": "slides/lecture4.html#split-sample-error",
    "title": "EpiData Workshop 2025",
    "section": "Split-sample error",
    "text": "Split-sample error\nTo compute the split-sample error\n\nSplit data into training (up to time \\(t_0\\)), and test set (after \\(t_0\\))\nEstimate the model to the training data only\nMake predictions for the test set\nCompute the error metric on the test set only\n\n\n\n\nImportant\n\n\nSplit-sample estimates of prediction error don’t mimic real forecasting.\nWe would refit with new data.\nTherefore, split-sample is pessimistic if the relation between outcome and predictors changes over time."
  },
  {
    "objectID": "slides/lecture4.html#split-sample-mse",
    "href": "slides/lecture4.html#split-sample-mse",
    "title": "EpiData Workshop 2025",
    "section": "Split-sample MSE",
    "text": "Split-sample MSE\n\nWant \\(h\\)-step ahead predictions\nat time \\(t\\), forecast for \\(t+h\\).\n\nThen, the split-sample MSE is\n\\[\\text{SplitMSE} = \\frac{1}{N-h-t_0} \\sum_{t = t_0}^{N-h} (\\hat y_{t+h|t_0} - y_{t+h})^2\\]\n\n\\(\\hat y_{t+h|t_0}\\) is a prediction for \\(y\\) at time \\(t+h\\)\nthat was made with a model that was estimated on data up to time \\(t_0\\)."
  },
  {
    "objectID": "slides/lecture4.html#time-series-cross-validation-cv",
    "href": "slides/lecture4.html#time-series-cross-validation-cv",
    "title": "EpiData Workshop 2025",
    "section": "Time series cross-validation (CV)",
    "text": "Time series cross-validation (CV)\n\\(h\\)-step ahead predictions\nRe-estimate once new data are available\nTo get \\(h\\)-step ahead predictions, for each time \\(t = t_0, t_0+1, \\dots\\),\n\nEstimate the model using data up to time \\(t\\)\nMake a prediction for \\(t+h\\)\nRecord the prediction error\n\n\\[\\textrm{CVMSE} = \\frac{1}{N-h-t_0} \\sum_{t = t_0}^{N-h} (\\hat y_{t+h|t} - y_{t+h})^2\\]\n\n\\(\\hat y_{t+h|t}\\) is the forecast for \\(y\\) at time \\(t+h\\)\nthat was made with data available up to time \\(t\\)."
  },
  {
    "objectID": "slides/lecture4.html#care-with-your-data",
    "href": "slides/lecture4.html#care-with-your-data",
    "title": "EpiData Workshop 2025",
    "section": "Care with your data",
    "text": "Care with your data\n\nData splitting\n\nSome data you see. You can use it to create your model: Training data.\nSome data you don’t see. It may arrive later, or you may hold it out to validate your process.\n\n\n\n\nOnly training data can be used to create your model.\n\nMuch more subtle than it sounds.\nEverything about your model must flow from this\n\nChoosing the model: Compartmental vs Time Series, exogenous predictors\nEstimates of model parameters\nHow much regularization to use\nAny transformations you make of your data\n\n\n\n\n\nBut that point about transformations is VERY important. And often overlooked."
  },
  {
    "objectID": "slides/lecture4.html#preprocessing-correctly",
    "href": "slides/lecture4.html#preprocessing-correctly",
    "title": "EpiData Workshop 2025",
    "section": "Preprocessing correctly",
    "text": "Preprocessing correctly\n\nA standard proprecessing routine is to scale() each of the predictors.\nThis requires calculating the mean and standard deviation on the training data.\nAnd using those values when you make predictions\nThis is hard to do with standard R operations.\n\n\ndata(Chicago, package = \"modeldata\") \nChicago &lt;- select(Chicago, c(ridership, temp, humidity, percip))\n\nchicago_train &lt;- Chicago |&gt;\n  slice_head(prop = .8) |&gt;\n  mutate(across(everything(), scale))\nmod &lt;- lm(ridership ~ ., data = chicago_train)\n\nchicago_test &lt;- Chicago |&gt;\n  slice_tail(prop = .2) |&gt;\n  mutate(across(everything(), scale))\npreds &lt;- predict(mod, chicago_test)\n\n\n\nScaled the test set with their own means and variances.\nShould have used sample statistics from the training set\nWe didn’t save the means and variances from the training set.\nWe would also need to invert (postprocess) preds to get them in the original units\n\nThis is all wrong"
  },
  {
    "objectID": "slides/lecture4.html#tidymodels",
    "href": "slides/lecture4.html#tidymodels",
    "title": "EpiData Workshop 2025",
    "section": "{tidymodels}",
    "text": "{tidymodels}\n\nThe {tidymodels} suite of packages is intended to handle this situation correctly.\nIt’s written by programmers at Posit (the people behind {tidyverse})\nIt doesn’t work for panel data.\nThat’s what we need for Epidemiological Time Series\nWe’ve been working with their team to develop this functionality."
  },
  {
    "objectID": "slides/lecture4.html#anatomy-of-a-forecaster-framework",
    "href": "slides/lecture4.html#anatomy-of-a-forecaster-framework",
    "title": "EpiData Workshop 2025",
    "section": "Anatomy of a forecaster framework",
    "text": "Anatomy of a forecaster framework\n\n\nWe should build up modular components\nBe able to add/remove layers of complexity sequentially, not all at once\nWe should be able to make processing independent of the model\nFitting should also be independent (glm() vs lm() vs glmnet())\nWe should be able to postprocess the predictions\nThe framework shouldn’t contaminate test data with training data (data leakage)\nWe should be able to access intermediate portions"
  },
  {
    "objectID": "slides/lecture4.html#what-epipredict-provides",
    "href": "slides/lecture4.html#what-epipredict-provides",
    "title": "EpiData Workshop 2025",
    "section": "What {epipredict} provides",
    "text": "What {epipredict} provides\nBasic and easy to use “canned” forecasters:\n\nBaseline flat forecaster\nAutoregressive forecaster (ARX)\nAutoregressive classifier (also “ARX”)\nCDC FluSight flatline forecaster\nClimatological forecaster\n\n\nThese are supposed to work easily\n\nHandle lots of cases we’ve already seen\n\nWe’ll start here"
  },
  {
    "objectID": "slides/lecture4.html#what-epipredict-provides-1",
    "href": "slides/lecture4.html#what-epipredict-provides-1",
    "title": "EpiData Workshop 2025",
    "section": "What {epipredict} provides",
    "text": "What {epipredict} provides\n\nA framework for creating custom forecasters out of modular components.\nThis is highly customizable, extends {tidymodels} to panel data\nGood for building a new forecaster from scratch\nWe’ll do an example at the end\n\nThere are four of components:\n\nPreprocessor: do things to the data before model training\nTrainer: train a model on data, resulting in a fitted model object\nPredictor: make predictions, using a fitted model object\nPostprocessor: do things to the predictions before returning"
  },
  {
    "objectID": "slides/lecture4.html#examples-of-pre-processing",
    "href": "slides/lecture4.html#examples-of-pre-processing",
    "title": "EpiData Workshop 2025",
    "section": "Examples of pre-processing",
    "text": "Examples of pre-processing\n\nEDA type stuff\n\nMaking locations/signals commensurate (scaling)\nDealing with revisions\nDetecting and removing outliers\nImputing or removing missing data\n\n\n\nFeature engineering\n\nCreating lagged predictors\nDay of Week effects\nRolling averages for smoothing\nLagged differences\nGrowth rates instead of raw signals\nThe sky’s the limit"
  },
  {
    "objectID": "slides/lecture4.html#fit-arx_forecaster-on-training-set",
    "href": "slides/lecture4.html#fit-arx_forecaster-on-training-set",
    "title": "EpiData Workshop 2025",
    "section": "Fit arx_forecaster() on training set",
    "text": "Fit arx_forecaster() on training set\n\nARX(1) model for COVID Deaths per 100K (7 day average): \\(\\quad \\mathbb{E}[y_{t+28} | y_t,\\ x_t] \\doteq \\phi + \\phi_0 y_{t} + \\beta_0 x_{t}\\)\nOnly focus on California (for now)\n\n\nt0_date &lt;- as.Date('2021-04-01')\ntrain &lt;- ca |&gt; filter(time_value &lt;= t0_date)\ntest &lt;- ca |&gt; filter(time_value &gt; t0_date)\n\nca_arx &lt;- arx_forecaster(\n  epi_data = train |&gt; as_epi_df(), \n  outcome = \"deaths\", \n  predictors = c(\"cases\", \"deaths\"),\n  trainer = linear_reg(),\n  args_list = arx_args_list(lags = 0, ahead = 28, quantile_levels = c(0.1, 0.9))\n)"
  },
  {
    "objectID": "slides/lecture4.html#arx_forecaster-output",
    "href": "slides/lecture4.html#arx_forecaster-output",
    "title": "EpiData Workshop 2025",
    "section": "arx_forecaster() output",
    "text": "arx_forecaster() output\n\nA workflow object which can be used any time in the future to create forecasts ($epi_workflow).\n\nAll necessary preprocessing; both the sequence of steps, and any necessary statistics\nThe fitted model object\nThe sequence of steps for postprocessing\n\nA forecast (point prediction + interval) for 28 days after the last available time value in the data ($predictions)."
  },
  {
    "objectID": "slides/lecture4.html#arx_forecaster-output-1",
    "href": "slides/lecture4.html#arx_forecaster-output-1",
    "title": "EpiData Workshop 2025",
    "section": "arx_forecaster() output",
    "text": "arx_forecaster() output\n\nca_arx"
  },
  {
    "objectID": "slides/lecture4.html#extract-fitted-object",
    "href": "slides/lecture4.html#extract-fitted-object",
    "title": "EpiData Workshop 2025",
    "section": "Extract fitted object",
    "text": "Extract fitted object\n\nca_arx$epi_workflow\n\n\n══ Epi Workflow [trained] ══════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\nPostprocessor: Frosting\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n\n7 Recipe steps.\n1. step_epi_lag()\n2. step_epi_lag()\n3. step_epi_ahead()\n4. step_naomit()\n5. step_naomit()\n6. step_training_window()\n7. check_enough_data()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n (Intercept)   lag_0_cases  lag_0_deaths  \n   21.181007      0.008929      0.321781  \n\n── Postprocessor ───────────────────────────────────────────────────────────────\n\n5 Frosting layers.\n1. layer_predict()\n2. layer_residual_quantiles()\n3. layer_add_forecast_date()\n4. layer_add_target_date()\n5. layer_threshold()"
  },
  {
    "objectID": "slides/lecture4.html#extract-predictions",
    "href": "slides/lecture4.html#extract-predictions",
    "title": "EpiData Workshop 2025",
    "section": "Extract predictions",
    "text": "Extract predictions\n\nca_arx$predictions\n\n# A tibble: 1 × 5\n  geo_value .pred .pred_distn forecast_date target_date\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;qtls(3)&gt; &lt;date&gt;        &lt;date&gt;     \n1 ca         105.       [105] 2021-04-01    2021-04-29 \n\n\n\n\n\n\nNote\n\n\n\n.pred_distn is actually a “distribution”, parameterized by its quantiles\narx_forecaster() estimates the quantiles in a different way than lm()\n\n\n\n\n\n\n\nca_arx$predictions |&gt; pivot_quantiles_wider(.pred_distn)\n\n# A tibble: 1 × 7\n  geo_value .pred forecast_date target_date `0.1` `0.5` `0.9`\n  &lt;chr&gt;     &lt;dbl&gt; &lt;date&gt;        &lt;date&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 ca         105. 2021-04-01    2021-04-29   29.4  105.  180."
  },
  {
    "objectID": "slides/lecture4.html#plot-predictions",
    "href": "slides/lecture4.html#plot-predictions",
    "title": "EpiData Workshop 2025",
    "section": "Plot predictions",
    "text": "Plot predictions\n\nca_arx |&gt; autoplot() +\n  scale_y_continuous(expand = expansion(c(0, 0.05))) +\n  geom_vline(xintercept = ca_arx$predictions$forecast_date[1], alpha = .5, color = secondary)"
  },
  {
    "objectID": "slides/lecture4.html#split-sample-forecasting",
    "href": "slides/lecture4.html#split-sample-forecasting",
    "title": "EpiData Workshop 2025",
    "section": "Split sample forecasting",
    "text": "Split sample forecasting\n\narx_forecaster() estimates a model on the training set\nOutputs only the prediction for time \\(t_0+h\\)\nTo get predictions for the test set:\n\n\npredict(ca_arx$epi_workflow, test)\n\nAn `epi_df` object, 706 x 6 with metadata:\n* geo_type  = state\n* time_type = day\n* as_of     = 2025-04-21 14:26:40.214048\n\n# A tibble: 706 × 6\n   geo_value time_value .pred .pred_distn forecast_date target_date\n   &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;   &lt;qtls(3)&gt; &lt;date&gt;        &lt;date&gt;     \n 1 ca        2021-04-02 113.        [113] 2021-04-01    2021-04-29 \n 2 ca        2021-04-03  64.3      [64.3] 2021-04-01    2021-04-29 \n 3 ca        2021-04-04  50.9      [50.9] 2021-04-01    2021-04-29 \n 4 ca        2021-04-05  61.2      [61.2] 2021-04-01    2021-04-29 \n 5 ca        2021-04-06  71.9      [71.9] 2021-04-01    2021-04-29 \n 6 ca        2021-04-07  78.1      [78.1] 2021-04-01    2021-04-29 \n 7 ca        2021-04-08  89.2      [89.2] 2021-04-01    2021-04-29 \n 8 ca        2021-04-09 124.        [124] 2021-04-01    2021-04-29 \n 9 ca        2021-04-10 101.        [101] 2021-04-01    2021-04-29 \n10 ca        2021-04-11  64.7      [64.7] 2021-04-01    2021-04-29 \n# ℹ 696 more rows"
  },
  {
    "objectID": "slides/lecture4.html#time-series-prediction-with-arx-with-re-fitting",
    "href": "slides/lecture4.html#time-series-prediction-with-arx-with-re-fitting",
    "title": "EpiData Workshop 2025",
    "section": "Time series prediction with ARX (with re-fitting)",
    "text": "Time series prediction with ARX (with re-fitting)\n\n\nTo re-train the forecaster as new data arrives\nCombine arx_forecaster() with epi_slide()\nBut that isn’t version aware\nTo REALLY mimic what forecasts would have looked like\nSlide on an epi_archive with epix_slide()\nThis is the only justifiable way to evaluate forecasting models\nThis is the only justifiable way to evaluate forecasting models\nFrom now on, we will only used versioned data\nFor illustration and speed, we’ll make predictions once a week (daily data)"
  },
  {
    "objectID": "slides/lecture4.html#predict-with-arx-re-fitting-on-trailing-window",
    "href": "slides/lecture4.html#predict-with-arx-re-fitting-on-trailing-window",
    "title": "EpiData Workshop 2025",
    "section": "Predict with ARX (re-fitting on trailing window)",
    "text": "Predict with ARX (re-fitting on trailing window)\n\nfc_time_values &lt;- seq(from = t0_date, to = as.Date(\"2023-02-09\"), by = \"1 week\")\nh &lt;- 28         # horizon\nw &lt;- 120 + h    # trailing window length \n\npred_arx &lt;- ca_archive |&gt; epix_slide(\n  ~ arx_forecaster(epi_data = .x,\n                   outcome = \"deaths\", \n                   predictors = c(\"cases\", \"deaths\"), \n                   trainer = linear_reg(),\n                   args_list = arx_args_list(lags = 0, ahead = h, quantile_levels = c(0.1, 0.9))\n  ) |&gt; pluck(\"predictions\") |&gt; pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)"
  },
  {
    "objectID": "slides/lecture4.html#regression-on-a-trailing-window",
    "href": "slides/lecture4.html#regression-on-a-trailing-window",
    "title": "EpiData Workshop 2025",
    "section": "Regression on a trailing window",
    "text": "Regression on a trailing window\nFit the model on a window of data of length \\(w\\)\n\nstarting at \\(t-w\\) and ending at \\(t\\).\n\nAdvantage:\n\nif the predictor-outcome relation changes over time,\ntraining the forecaster on only recent data better captures the recent relationship\npotentially more relevant for near-term forecasts\n\n\n\nWindow length \\(w\\) considerations:\n\nif \\(w\\) is too big, the model can’t adapt to the recent predictors-outcome relation\nif \\(w\\) is too small, the fitted model may be too volatile (trained on too little data)"
  },
  {
    "objectID": "slides/lecture4.html#predict-with-arx",
    "href": "slides/lecture4.html#predict-with-arx",
    "title": "EpiData Workshop 2025",
    "section": "Predict with ARX",
    "text": "Predict with ARX\n\n\n\nNote (window length)\n\n\n\nSetting \\(w = 120 + h\\) actually only uses \\(N=120\\) observations\nIt filters to data within the window, then performs leads/lags\nTo make this explicit, for a horizon \\(h\\), we need to “back” \\(h\\) days to see which predictors align with it\n\n\n\n\n\n\n\nNote (all past)\n\n\nTo fitting on all past data up to the forecasting date use\nepix_slide(...,.before = Inf)"
  },
  {
    "objectID": "slides/lecture4.html#predict-with-arx-re-fitting-on-trailing-window-1",
    "href": "slides/lecture4.html#predict-with-arx-re-fitting-on-trailing-window-1",
    "title": "EpiData Workshop 2025",
    "section": "Predict with ARX (re-fitting on trailing window)",
    "text": "Predict with ARX (re-fitting on trailing window)\n\npred_arx \n\n# A tibble: 98 × 8\n   version    geo_value  .pred forecast_date target_date  `0.1`  `0.5` `0.9`\n * &lt;date&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;date&gt;        &lt;date&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 2021-04-01 ca        0.396  2021-03-31    2021-04-28  0.192  0.396  0.599\n 2 2021-04-08 ca        0.395  2021-04-07    2021-05-05  0.197  0.395  0.594\n 3 2021-04-15 ca        0.403  2021-04-14    2021-05-12  0.211  0.403  0.595\n 4 2021-04-22 ca        0.312  2021-04-21    2021-05-19  0.142  0.312  0.482\n 5 2021-04-29 ca        0.261  2021-04-28    2021-05-26  0.0879 0.261  0.433\n 6 2021-05-06 ca        0.209  2021-05-05    2021-06-02  0.0238 0.209  0.394\n 7 2021-05-13 ca        0.158  2021-05-12    2021-06-09  0      0.158  0.345\n 8 2021-05-20 ca        0.118  2021-05-19    2021-06-16  0      0.118  0.296\n 9 2021-05-27 ca        0.0775 2021-05-26    2021-06-23  0      0.0775 0.239\n10 2021-06-03 ca        0.0552 2021-06-02    2021-06-30  0      0.0552 0.137\n# ℹ 88 more rows"
  },
  {
    "objectID": "slides/lecture4.html#predict-with-arx-re-fitting-on-trailing-window-2",
    "href": "slides/lecture4.html#predict-with-arx-re-fitting-on-trailing-window-2",
    "title": "EpiData Workshop 2025",
    "section": "Predict with ARX (re-fitting on trailing window)",
    "text": "Predict with ARX (re-fitting on trailing window)\n\n\n\n\n\n\nMAE\nMASE\nCoverage 80\n\n\n\n\n0.08\n218.86\n0.43"
  },
  {
    "objectID": "slides/lecture4.html#customizing-arx_forecaster",
    "href": "slides/lecture4.html#customizing-arx_forecaster",
    "title": "EpiData Workshop 2025",
    "section": "Customizing arx_forecaster()",
    "text": "Customizing arx_forecaster()\n\narx_forecaster(\n  epi_data = train, \n  outcome = \"deaths\", \n  predictors = c(\"cases\", \"deaths\"),\n  trainer = linear_reg(),\n  args_list = arx_args_list(lags = 0, ahead = 28, quantile_levels = c(0.1, 0.9))\n)\n\n\n\narx_args_list(\n  lags = c(0L, 7L, 14L),\n  ahead = 7L,\n  n_training = Inf,\n  forecast_date = NULL,\n  target_date = NULL,\n  adjust_latency = c(\"none\", \"extend_ahead\", \"extend_lags\", \"locf\"),\n  warn_latency = TRUE,\n  quantile_levels = c(0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95),\n  symmetrize = TRUE,\n  nonneg = TRUE,\n  quantile_by_key = character(0L),\n  check_enough_data_n = NULL,\n  check_enough_data_epi_keys = NULL,\n  ...\n)"
  },
  {
    "objectID": "slides/lecture4.html#doctor-visits-instead-of-cases-in-predictor-set",
    "href": "slides/lecture4.html#doctor-visits-instead-of-cases-in-predictor-set",
    "title": "EpiData Workshop 2025",
    "section": "Doctor visits instead of cases in predictor set",
    "text": "Doctor visits instead of cases in predictor set\n\n\n\n\n\n\nMAE\nMASE\nCoverage 80\n\n\n\n\n0.06\n169.72\n0.52"
  },
  {
    "objectID": "slides/lecture4.html#customizing-arx_forecaster-1",
    "href": "slides/lecture4.html#customizing-arx_forecaster-1",
    "title": "EpiData Workshop 2025",
    "section": "Customizing arx_forecaster()",
    "text": "Customizing arx_forecaster()\nMultiple horizons\n\nh &lt;- c(7, 14, 21, 28)\nforecast_times &lt;- seq(from = t0_date, to = as.Date(\"2023-02-23\"), by = \"1 month\")\npred_h_days_ahead &lt;- function(epi_archive, ahead = 7) {\n  epi_archive |&gt;\n    epix_slide(~ arx_forecaster(epi_data = .x,\n                                outcome = \"deaths\", \n                                predictors = c(\"deaths\", \"doctor_visits\"), \n                                trainer = linear_reg(),\n                                args_list = arx_args_list(lags = 0, ahead = ahead, quantile_levels = c(0.1, 0.9))\n    )|&gt; pluck(\"predictions\") |&gt; pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = forecast_times\n  )\n}\nforecasts &lt;- bind_rows(map(h, ~ pred_h_days_ahead(ca_archive_dv, ahead = .x)))"
  },
  {
    "objectID": "slides/lecture4.html#predictions-multiple-horizons",
    "href": "slides/lecture4.html#predictions-multiple-horizons",
    "title": "EpiData Workshop 2025",
    "section": "Predictions (multiple horizons)",
    "text": "Predictions (multiple horizons)"
  },
  {
    "objectID": "slides/lecture4.html#changing-trainer",
    "href": "slides/lecture4.html#changing-trainer",
    "title": "EpiData Workshop 2025",
    "section": "Changing trainer",
    "text": "Changing trainer\n\narx_forecaster(epi_data = train |&gt; as_epi_df(), \n               outcome = \"deaths\", \n               predictors = c(\"cases\", \"deaths\"),\n               trainer = linear_reg() |&gt; set_engine(\"lm\"),\n               args_list = arx_args_list(lags = 0, ahead = 28,\n                                         quantile_levels = c(0.1, 0.9)))\n\nModify trainer to use a model that is not lm (default)\n\ne.g. trainer = rand_forest()\ncan use any {parsnip} models, see list\n{epipredict} has a number of custom engines as well"
  },
  {
    "objectID": "slides/lecture4.html#changing-trainer-1",
    "href": "slides/lecture4.html#changing-trainer-1",
    "title": "EpiData Workshop 2025",
    "section": "Changing trainer",
    "text": "Changing trainer\n\npred_arx_rf &lt;- ca_archive_dv |&gt;\n  epix_slide(\n    ~ arx_forecaster(epi_data = .x,\n                     outcome = \"deaths\", \n                     predictors = c(\"deaths\", \"doctor_visits\"), \n                     trainer = parsnip::rand_forest(mode = \"regression\"), # defaults to ranger\n                     args_list = arx_args_list(lags = 0, ahead = 28, quantile_levels = c(0.1, 0.9))\n    ) |&gt; pluck(\"predictions\") |&gt; pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)"
  },
  {
    "objectID": "slides/lecture4.html#predictions-trained-using-random-forest",
    "href": "slides/lecture4.html#predictions-trained-using-random-forest",
    "title": "EpiData Workshop 2025",
    "section": "Predictions (trained using random forest)",
    "text": "Predictions (trained using random forest)\n\n\n\n\n\n\nMAE\nMASE\nCoverage 80\n\n\n\n\n0.08\n226.43\n0.09\n\n\n\n\n\n\n\nRandom forests has really poor coverage here.\nThe reason is the way intervals are calculated.\nCan change engine to get better coverage:\n\nspecify parsnip::rand_forest(mode = \"regression\", engine = \"grf_quantiles\")"
  },
  {
    "objectID": "slides/lecture4.html#predictions-from-a-random-forest-with-grf_quantiles",
    "href": "slides/lecture4.html#predictions-from-a-random-forest-with-grf_quantiles",
    "title": "EpiData Workshop 2025",
    "section": "Predictions from a random forest with grf_quantiles()",
    "text": "Predictions from a random forest with grf_quantiles()\n\n\n\n\n\n\nMAE\nMASE\nCoverage 80\n\n\n\n\n0.09\n248.24\n0.39"
  },
  {
    "objectID": "slides/lecture4.html#what-are-these-intervals",
    "href": "slides/lecture4.html#what-are-these-intervals",
    "title": "EpiData Workshop 2025",
    "section": "What are these intervals?",
    "text": "What are these intervals?\n\n{epipredict} takes quantiles of training residuals to form its prediction intervals\nIn comparison to traditional (parametric) intervals from lm(), this is more flexible\nIt can in principle adapt to asymmetric or heavy-tailed error distributions\n\n\nTaking quantiles of training residuals can be problematic if the model is overfit.\n\nQuantile regression provides an alternative, wherein we estimate these quantiles directly\nTechnically, grf_quantiles() was using Quantile Loss with Random Forests"
  },
  {
    "objectID": "slides/lecture4.html#quantile-regression",
    "href": "slides/lecture4.html#quantile-regression",
    "title": "EpiData Workshop 2025",
    "section": "Quantile regression",
    "text": "Quantile regression\nNow we directly target conditional quantiles of the outcome over time.\nEstimating tail quantiles requires more data, so\n\nunsuitable for settings with small training set (e.g. trailing window on one state)\ncan benefit by combination with geo-pooling (much more data to train on)"
  },
  {
    "objectID": "slides/lecture4.html#geo-pooling",
    "href": "slides/lecture4.html#geo-pooling",
    "title": "EpiData Workshop 2025",
    "section": "Geo-pooling",
    "text": "Geo-pooling\n\nWhen we observe data over time from multiple locations (e.g. states or counties).\n\n\n\nWe could\n\nEstimate coefficients separately for each location (as we have done so far), or\nFit one model using all locations together at each time point (geo-pooling).\nEstimated coefficients will not be location specific.\n\n\n\n\nWe will now pool data from all US states to make predictions.\nAlso switch to using (linear) quantile regression (medians and intervals) quantreg::rq()"
  },
  {
    "objectID": "slides/lecture4.html#geo-pooling-1",
    "href": "slides/lecture4.html#geo-pooling-1",
    "title": "EpiData Workshop 2025",
    "section": "Geo-pooling",
    "text": "Geo-pooling\n\npred_arx_geo_pool &lt;- usa_archive_dv |&gt; epix_slide(\n  ~ arx_forecaster(epi_data = .x,\n                   outcome = \"deaths\", \n                   predictors = c(\"deaths\", \"doctor_visits\"), \n                   trainer = quantile_reg(),\n                   args_list = arx_args_list(ahead = 28, quantile_levels = c(0.1, 0.9))\n  ) |&gt; pluck(\"predictions\") |&gt; pivot_quantiles_wider(.pred_distn),\n  .before = w, \n  .versions = fc_time_values\n)\n\nNote: geo-pooling is the default in epipredict"
  },
  {
    "objectID": "slides/lecture4.html#predictions-geo-pooling-h28",
    "href": "slides/lecture4.html#predictions-geo-pooling-h28",
    "title": "EpiData Workshop 2025",
    "section": "Predictions (geo-pooling, \\(h=28\\))",
    "text": "Predictions (geo-pooling, \\(h=28\\))"
  },
  {
    "objectID": "slides/lecture4.html#geo-pooling-or-not",
    "href": "slides/lecture4.html#geo-pooling-or-not",
    "title": "EpiData Workshop 2025",
    "section": "Geo-pooling or not?",
    "text": "Geo-pooling or not?\n\nGeo-pooled predictions tend to be more stable\nGenerally with wider intervals (and better coverage)\nMeanwhile, predictions from state-specific models tend to be more volatile\n\nThe extent to which this occurs differs based on the horizon."
  },
  {
    "objectID": "slides/lecture4.html#build-a-forecaster-from-scratch-1",
    "href": "slides/lecture4.html#build-a-forecaster-from-scratch-1",
    "title": "EpiData Workshop 2025",
    "section": "Build a forecaster from scratch",
    "text": "Build a forecaster from scratch\n\nSo far, we performed manual pre-processing,\nand then relied on a canned forecaster\nto automatically perform more pre-processing, training, predicting, and post-processing.\n\n\n\n\nWhat if we want more direct control on each single step?"
  },
  {
    "objectID": "slides/lecture4.html#under-the-hood-of-arx_forecaster-roughly",
    "href": "slides/lecture4.html#under-the-hood-of-arx_forecaster-roughly",
    "title": "EpiData Workshop 2025",
    "section": "Under the hood of arx_forecaster() (roughly)",
    "text": "Under the hood of arx_forecaster() (roughly)\n\n# A preprocessing \"recipe\" that turns raw data into features / response\nrec &lt;- epi_recipe(ca) |&gt;\n  step_epi_lag(cases, lag = c(0, 7, 14)) |&gt;\n  step_epi_lag(deaths, lag = c(0, 7, 14)) |&gt;\n  step_epi_ahead(deaths, ahead = 28) |&gt;\n  step_epi_naomit()\n\n# Training engine\neng &lt;- quantile_reg(quantile_levels = c(.1, .5, .9))\n\n# A post-processing routine describing what to do to the predictions\nfrost &lt;- frosting() |&gt;\n  layer_predict() |&gt;\n  layer_threshold(.pred, lower = 0) |&gt; # predictions / intervals should be non-negative\n  layer_add_target_date() |&gt;\n  layer_add_forecast_date()\n\n# Bundle up the preprocessor, training engine, and postprocessor\n# We use quantile regression\newf &lt;- epi_workflow(rec, eng, frost)\n\n# Fit it to data (we could fit this to ANY data that has the same format)\ntrained_ewf &lt;- fit(ewf, data = ca)\n\n# Make predictions from the end of our training data\n# we could have made predictions using the same model on ANY test data\nfcasts &lt;- forecast(trained_ewf)"
  },
  {
    "objectID": "slides/lecture4.html#predicting-influenza-test-positivity",
    "href": "slides/lecture4.html#predicting-influenza-test-positivity",
    "title": "EpiData Workshop 2025",
    "section": "Predicting influenza test positivity",
    "text": "Predicting influenza test positivity\n\nPredict test positivity for 3 pathogens (flu, RSV, covid)\n6 regions (ON, BC, QC, Prairies, Atlantic, Territories) + National\nWorked with UGuelph to build AI4Casting Hub\n\n\n\nFrom November 25, 2024 until May 31, 2025\nEvery Saturday by 11pm EDT\nPredict -1, 0, 1, 2, 3 epiweeks ahead\nPoint forecast + 7 quantiles\nResponse is RVDSS % Test Positivity from PHAC\n\n\n\nThanks to Christine Chuong (UBC MSc Student)\nBuilt and ran this forecaster\nScraped RVDSS data, updates every week: https://github.com/dajmcdon/rvdss-canada/"
  },
  {
    "objectID": "slides/lecture4.html#almost-our-production-forecaster",
    "href": "slides/lecture4.html#almost-our-production-forecaster",
    "title": "EpiData Workshop 2025",
    "section": "Almost our production forecaster",
    "text": "Almost our production forecaster\n\nprod_forecaster &lt;- function(epidata, ahead) {\n  Logit &lt;- function(x, a = 0.01) log((x + a) / (1 - x + a))\n  Sigmd &lt;- function(y, a = 0.01) (exp(y) * (1 + a) - a) / (1 + exp(y))\n\n  quantile_levels &lt;- c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975)\n  forecast_date &lt;- attr(epidata, \"metadata\")$as_of\n  target_date &lt;- forecast_date + ahead - 7\n  r &lt;- epi_recipe(epidata) |&gt;\n    step_adjust_latency(recipes::all_outcomes(), fixed_forecast_date = forecast_date, method = \"extend_ahead\") |&gt;\n    recipes::step_mutate(flu_pct_positive =  Logit(flu_pct_positive / 100)) |&gt;\n    step_epi_lag(flu_pct_positive, lag = c(0, 7, 14)) |&gt;\n    step_epi_ahead(flu_pct_positive, ahead = ahead) |&gt;\n    step_climate(flu_pct_positive, forecast_ahead = ahead / 7, time_type = \"epiweek\", window_size = 3L) |&gt;\n    step_training_window(n_recent = 12) |&gt;\n    step_epi_naomit()\n  \n  e &lt;- quantile_reg(quantile_levels = c(0.025, 0.1, 0.25, 0.5, 0.75, 0.9, 0.975))\n  f &lt;- frosting() |&gt; layer_predict() |&gt; \n    layer_quantile_distn(quantile_levels = quantile_levels) |&gt;\n    layer_point_from_distn() |&gt;\n    layer_add_forecast_date(forecast_date = forecast_date) |&gt;\n    layer_add_target_date()\n  \n  ewf &lt;- epi_workflow(r, e, f)\n  trained_ewf &lt;- ewf |&gt; fit(epidata)\n  \n  preds &lt;- forecast(trained_ewf) |&gt;\n    pivot_quantiles_wider(.pred_distn) |&gt;\n    mutate(across(c(.pred, `0.025`:`0.975`), ~ Sigmd(.x) * 100)) |&gt;\n    select(-time_value)\n\n  preds\n}"
  },
  {
    "objectID": "slides/lecture4.html#make-the-forecasts-for-all-dates-this-season",
    "href": "slides/lecture4.html#make-the-forecasts-for-all-dates-this-season",
    "title": "EpiData Workshop 2025",
    "section": "Make the forecasts for all dates this season",
    "text": "Make the forecasts for all dates this season\n\naheads &lt;- 1:4 * 7\nfcast_dates &lt;- seq(ymd(\"2024-11-23\"), ymd(\"2025-04-12\"), by = \"1 week\")\nrvdss_forecasts &lt;- function(archive, .ahead) {\n  epix_slide(archive, ~ prod_forecaster(.x, .ahead), .versions = fcast_dates)\n}\nall_forecasts &lt;- bind_rows(map(aheads, ~ rvdss_forecasts(rvdss_data, .ahead = .x)))"
  },
  {
    "objectID": "slides/lecture4.html#ensembling",
    "href": "slides/lecture4.html#ensembling",
    "title": "EpiData Workshop 2025",
    "section": "Ensembling",
    "text": "Ensembling\nInstead of choosing one model, we can combine the predictions from multiple base models.\n\nuntrained: combine base models, agnostic to past performance\ntrained: weight base models, accounting for past performance\n\nSimplest untrained method: simple average of base model forecasts\n\\[\n\\hat{y}^{\\text{avg}}_{t+h|t} = \\frac{1}{p} \\sum_{j=1}^p \\hat{y}^j_{t+h|t}\n\\]\nA more robust option: simple median of base model forecasts\n\\[\n\\hat{y}^{\\text{med}}_{t+h|t} = \\mathrm{median}\\Big\\{ \\hat{y}^j_{t+h|t} : j = 1,\\dots,p \\Big\\}\n\\]"
  },
  {
    "objectID": "slides/lecture4.html#example-from-the-covid-19-forecast-hub",
    "href": "slides/lecture4.html#example-from-the-covid-19-forecast-hub",
    "title": "EpiData Workshop 2025",
    "section": "Example from the Covid-19 Forecast Hub",
    "text": "Example from the Covid-19 Forecast Hub"
  },
  {
    "objectID": "slides/lecture4.html#two-key-goals-of-ensembling",
    "href": "slides/lecture4.html#two-key-goals-of-ensembling",
    "title": "EpiData Workshop 2025",
    "section": "Two key goals of ensembling",
    "text": "Two key goals of ensembling\n\n1. Compete-with-best:\nensemble should have accuracy competitive with best individual constituent model\n\n2. Robustness-over-all:\nensemble should have greater robustness than any individual constituent model\n\n\nTypically these are hard to accomplish simultaneously,\n\nuntrained methods excel at point 2,\ntrained methods can achieve point 1"
  },
  {
    "objectID": "slides/lecture4.html#linear-stacking-trained-ensemble",
    "href": "slides/lecture4.html#linear-stacking-trained-ensemble",
    "title": "EpiData Workshop 2025",
    "section": "Linear stacking (trained ensemble)",
    "text": "Linear stacking (trained ensemble)\n\ndirectly fit a weighted combination of base forecasts to optimize accuracy (MSE, MAE, etc.),\noften called linear stacking: e.g., to form the forecast at time \\(t\\), we solve\n\n\\[\n\\begin{aligned}\n&\\mathop{\\mathrm{minimize}}_{w \\in \\mathbb{R}^p} \\sum_{s=t_0+1}^t \\bigg( y_s - \\sum_{j=1}^p\nw_j \\cdot \\hat{y}^j_{s|s-h} \\bigg)^2 \\\\   \n&\\text{subject to} \\quad \\sum_{j=1}^p w_j = 1, \\;\\;\\text{and} \\;\\; w_j \\geq 0, \\;\nj=1,\\dots,p\n\\end{aligned}\n\\]\nthen use\n\\[\n\\hat{y}^{\\text{stack}}_{t+h|t} = \\sum_{j=1}^p \\hat{w}^t_j \\cdot\n\\hat{y}^j_{t+h|t}\n\\]\n\nThe stacking optimization problem uses forward-looking predictions\n(as in time series cross-validation)"
  },
  {
    "objectID": "slides/lecture4.html#recalibration",
    "href": "slides/lecture4.html#recalibration",
    "title": "EpiData Workshop 2025",
    "section": "Recalibration",
    "text": "Recalibration\n\nPrediction intervals often have empirical coverage \\(\\ll\\) nominal coverage\n\ne.g., our 80% predictive intervals in practice cover \\(\\approx\\) 60% of the time\n\n\nRecalibration methods adjust the intervals so that\n\nnominal coverage \\(\\approx\\) empirical coverage"
  },
  {
    "objectID": "slides/lecture4.html#quantile-tracking",
    "href": "slides/lecture4.html#quantile-tracking",
    "title": "EpiData Workshop 2025",
    "section": "Quantile tracking",
    "text": "Quantile tracking\nProduces calibrated prediction intervals from base forecasts and scores.\nIn the simplest case, we can take the score to be absolute error of point forecasts:\n\\[e_t = |y_t - \\hat y_{t|t-1}|\\]\n\nLet \\(\\hat q_{t}^{1-\\alpha}\\) be a predicted level \\(1-\\alpha\\) quantile of the distribution of \\(e_t\\)\nDefine \\(I_{t|t-1}^{1-\\alpha} = [\\hat{y}_{t|t-1} - \\hat{q}_t^{1-\\alpha}, \\;     \\hat{y}_{t|t-1} + \\hat{q}_t^{1-\\alpha}]\\).\nNote that \\(e_t \\leq \\hat{q}_t^{1-\\alpha} \\iff y_t \\in I_{t|t-1}^{1-\\alpha}\\)\nTherefore we the reduced the problem of producing prediction intervals \\(I_{t|t-1}^{1-\\alpha}\\) to one of tracking a quantile of \\(e_t\\)"
  },
  {
    "objectID": "slides/lecture4.html#quantile-updates",
    "href": "slides/lecture4.html#quantile-updates",
    "title": "EpiData Workshop 2025",
    "section": "Quantile updates",
    "text": "Quantile updates\n\nbegin with some estimate \\(\\hat{q}_{t_0+1}^{1-\\alpha}\\) based on a burn-in set.\nThen, for a step size \\(\\eta &gt; 0\\), repeat the following updates as \\(t\\) increases:\n\n\\[\\hat q_{t+1}^{1-\\alpha} = \\begin{cases}\n\\hat q_{t}^{1-\\alpha} + \\eta(1-\\alpha) \\quad \\text{if } y_t\\notin I_{t|t-1}^{1-\\alpha} \\\\\n\\hat q_{t}^{1-\\alpha} - \\eta\\alpha \\quad \\quad \\quad \\,\\,\\, \\text{if } y_t\\in I_{t|t-1}^{1-\\alpha}\n\\end{cases}\\]\nIn words:\n\nif the latest interval does not cover, then we increase the quantile (make the next interval wider),\notherwise we decrease the quantile by (make the next interval narrower).\n\n\nThis method has the following guarantee:\n\\[\n\\Bigg| \\frac{1}{T} \\sum_{t=t_0+1}^{t_0+T} 1 \\big\\{ y_t \\in I_{t|t-1}^{1-\\alpha} \\big\\} - (1-\\alpha) \\Bigg| \\leq \\frac{b/\\eta + 1}{T}\n\\]\nwhere \\(b\\) is a bound on the errors (largest error possible/observable)."
  },
  {
    "objectID": "slides/lecture4.html#summary-and-more-worksheet",
    "href": "slides/lecture4.html#summary-and-more-worksheet",
    "title": "EpiData Workshop 2025",
    "section": "Summary and more worksheet?",
    "text": "Summary and more worksheet?\n\nBasics of time series\nEvaluating forecasts\nCreating forecasters with {epipredict}\nWhilrwind of advanced ideas"
  },
  {
    "objectID": "slides/lecture2.html#outline",
    "href": "slides/lecture2.html#outline",
    "title": "EpiData Workshop 2025",
    "section": "Outline",
    "text": "Outline\n\nWarmup: Examining Snapshots\nSignal processing with snapshots\nTracking Revisions\nNowcasting Using {epiprocess}\nNowcasting with Regression"
  },
  {
    "objectID": "slides/lecture2.html#now-that-you-have-data-what-do-you-do-with-it",
    "href": "slides/lecture2.html#now-that-you-have-data-what-do-you-do-with-it",
    "title": "EpiData Workshop 2025",
    "section": "Now that you have data, what do you do with it?",
    "text": "Now that you have data, what do you do with it?\n\n\n\nR4DS by Wickham, Çetinkaya-Rundel, and Grolemund\n\n\n\nComplications\n\nUsually panel data (multiple locations at once)\nUsually accessing in real time\nData have revisions\nData are reported irregularly, NA’s are frequent\nIndividual streams have high signal-to-noise ratio\n\n\n\nResult: spend lots of time doing processing and dealing with corner behaviour"
  },
  {
    "objectID": "slides/lecture2.html#r-packages-we-maintain-to-facilitate-typical-analyses",
    "href": "slides/lecture2.html#r-packages-we-maintain-to-facilitate-typical-analyses",
    "title": "EpiData Workshop 2025",
    "section": "R packages we maintain to facilitate typical analyses",
    "text": "R packages we maintain to facilitate typical analyses"
  },
  {
    "objectID": "slides/lecture2.html#epi_df-snapshot-of-a-data-set",
    "href": "slides/lecture2.html#epi_df-snapshot-of-a-data-set",
    "title": "EpiData Workshop 2025",
    "section": "epi_df: snapshot of a data set",
    "text": "epi_df: snapshot of a data set\n\na tibble with a couple of required columns, geo_value and time_value.\narbitrary additional columns containing measured values, called signals\nadditional keys that index subsets (health region, age_group, ethnicity, etc.)\n\n\n\n\n\n\n\nepi_df\n\n\nRepresents a snapshot that contains the most up-to-date values of the signal variables, as of a given time."
  },
  {
    "objectID": "slides/lecture2.html#epi_df-snapshot-of-a-dataset",
    "href": "slides/lecture2.html#epi_df-snapshot-of-a-dataset",
    "title": "EpiData Workshop 2025",
    "section": "epi_df: Snapshot of a dataset",
    "text": "epi_df: Snapshot of a dataset\n\ncan_edf &lt;- can_cases_deaths |&gt;\n  rename(geo_value = region) |&gt;\n  as_epi_df(as_of = \"2024-04-13\", other_keys = \"hr\")\ncan_edf\n\nAn `epi_df` object, 150,951 x 5 with metadata:\n* geo_type  = nation\n* time_type = day\n* other_keys = hr\n* as_of     = 2024-04-13\n\n# A tibble: 150,951 × 5\n   geo_value hr       time_value cases deaths\n * &lt;chr&gt;     &lt;chr&gt;    &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n 1 AB        South    2020-03-05     0      0\n 2 AB        Calgary  2020-03-05     1      0\n 3 AB        Central  2020-03-05     0      0\n 4 AB        Edmonton 2020-03-05     0      0\n 5 AB        North    2020-03-05     0      0\n 6 AB        Other    2020-03-05     0      0\n 7 AB        South    2020-03-06     0      0\n 8 AB        Calgary  2020-03-06     0      0\n 9 AB        Central  2020-03-06     0      0\n10 AB        Edmonton 2020-03-06     0      0\n# ℹ 150,941 more rows"
  },
  {
    "objectID": "slides/lecture2.html#warm-up-plotting",
    "href": "slides/lecture2.html#warm-up-plotting",
    "title": "EpiData Workshop 2025",
    "section": "Warm up: plotting",
    "text": "Warm up: plotting\n\ncan_edf |&gt;\n  filter(geo_value == \"MB\") |&gt;\n  autoplot(cases, deaths) +\n  scale_y_continuous(name = \"\", expand = expansion(c(0, .05))) + xlab(\"\") + scale_color_delphi(name = \"\")\n\n\n\nWeird reporting behaviour.\n\nMB stopped reporting deaths by HR.\nPut them all in “Other”\nLots of missing values"
  },
  {
    "objectID": "slides/lecture2.html#warm-up-handling-missingness",
    "href": "slides/lecture2.html#warm-up-handling-missingness",
    "title": "EpiData Workshop 2025",
    "section": "Warm up: handling missingness",
    "text": "Warm up: handling missingness\nTwo types of missing data\n\nExplicit missingness means that there’s an NA\nImplicit missingness means that a combination of time_value and geo_value is not in the data.\n\n\ncan_edf &lt;- can_edf |&gt;\n  complete(time_value = full_seq(time_value, period = 1), fill = list(cases = 0, deaths = 0)) \ncan_edf\n\nAn `epi_df` object, 150,951 x 5 with metadata:\n* geo_type  = nation\n* time_type = day\n* other_keys = hr\n* as_of     = 2024-04-13\n\n# A tibble: 150,951 × 5\n   time_value geo_value hr                               cases deaths\n   &lt;date&gt;     &lt;chr&gt;     &lt;chr&gt;                            &lt;dbl&gt;  &lt;dbl&gt;\n 1 2020-01-15 ON        Algoma                               0      0\n 2 2020-01-15 ON        Brant                                0      0\n 3 2020-01-15 ON        Durham                               0      0\n 4 2020-01-15 ON        Grey Bruce                           0      0\n 5 2020-01-15 ON        Haldimand-Norfolk                    0      0\n 6 2020-01-15 ON        Haliburton, Kawartha, Pine Ridge     0      0\n 7 2020-01-15 ON        Halton                               0      0\n 8 2020-01-15 ON        Hamilton                             0      0\n 9 2020-01-15 ON        Hastings and Prince Edward           0      0\n10 2020-01-15 ON        Chatham-Kent                         0      0\n# ℹ 150,941 more rows"
  },
  {
    "objectID": "slides/lecture2.html#warm-up-aggregating",
    "href": "slides/lecture2.html#warm-up-aggregating",
    "title": "EpiData Workshop 2025",
    "section": "Warm up: aggregating",
    "text": "Warm up: aggregating\n\ncan_prov &lt;- can_edf |&gt;\n  sum_groups_epi_df(c(cases, deaths), group_cols = \"geo_value\")\ncan_prov\n\nAn `epi_df` object, 16,862 x 4 with metadata:\n* geo_type  = nation\n* time_type = day\n* as_of     = 2024-04-13\n\n# A tibble: 16,862 × 4\n   geo_value time_value cases deaths\n   &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n 1 AB        2020-03-05     1      0\n 2 AB        2020-03-06     0      0\n 3 AB        2020-03-07     1      0\n 4 AB        2020-03-08     1      0\n 5 AB        2020-03-09     4      0\n 6 AB        2020-03-10     9      0\n 7 AB        2020-03-11     7      0\n 8 AB        2020-03-12     3      0\n 9 AB        2020-03-13     8      0\n10 AB        2020-03-14    22      0\n# ℹ 16,852 more rows"
  },
  {
    "objectID": "slides/lecture2.html#warm-up-per-capita-scaling",
    "href": "slides/lecture2.html#warm-up-per-capita-scaling",
    "title": "EpiData Workshop 2025",
    "section": "Warm up: per capita scaling",
    "text": "Warm up: per capita scaling\n\ncan_prov &lt;- can_prov |&gt;\n  inner_join(prov_pop, by = join_by(geo_value == region)) |&gt;\n  mutate(case_rate = cases / pop * 1e5, death_rate = deaths / pop * 1e6) |&gt;\n  select(-pop)\n\n\n\n\nNegative incidence is often due to cummulatives being differenced\nBut sometimes due to correcting an error.\nWith luck, the source would make an adjustment.\n\n\n\nAn `epi_df` object, 15 x 4 with metadata:\n* geo_type  = nation\n* time_type = day\n* as_of     = 2024-04-13\n\n# A tibble: 15 × 4\n   geo_value time_value cases deaths\n   &lt;chr&gt;     &lt;date&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n 1 AB        2020-10-08   186     -1\n 2 AB        2021-04-26  1547     -7\n 3 AB        2021-06-21    67     -2\n 4 AB        2021-08-05   365     -4\n 5 AB        2021-12-08   354     -1\n 6 AB        2021-12-15   467     -1\n 7 AB        2022-03-15   578    -12\n 8 AB        2022-07-11   176     -4\n 9 AB        2023-01-23    50     -5\n10 AB        2023-03-13    60     -3\n11 AB        2023-03-27    40   -700\n12 NL        2021-08-25     2     -1\n13 NS        2021-05-15    86     -1\n14 SK        2020-12-28     0     -1\n15 SK        2021-04-03   281     -1"
  },
  {
    "objectID": "slides/lecture2.html#examples-of-signal-processing",
    "href": "slides/lecture2.html#examples-of-signal-processing",
    "title": "EpiData Workshop 2025",
    "section": "Examples of signal processing",
    "text": "Examples of signal processing\n\n\nCorrelating signals across location or time\nComputing growth rates\nDetecting and removing outliers\nCalculating summaries with rolling windows"
  },
  {
    "objectID": "slides/lecture2.html#correlations-at-different-lags-province-level",
    "href": "slides/lecture2.html#correlations-at-different-lags-province-level",
    "title": "EpiData Workshop 2025",
    "section": "Correlations at different lags (province-level)",
    "text": "Correlations at different lags (province-level)\n\ncor0 &lt;- epi_cor(can_prov, case_rate, death_rate, cor_by = geo_value)\ncor21 &lt;- epi_cor(can_prov, case_rate, death_rate, cor_by = geo_value, dt1 = -21)\n\n\n\n\nAre case and death rates linearly associated across all days for each geography?\nDeaths and cases likely not contemporaneous, expect cases to precede deaths."
  },
  {
    "objectID": "slides/lecture2.html#lag-analysis-more-systematically",
    "href": "slides/lecture2.html#lag-analysis-more-systematically",
    "title": "EpiData Workshop 2025",
    "section": "Lag analysis more systematically",
    "text": "Lag analysis more systematically\n\nlags &lt;- 0:35\ncan_lag_cors &lt;- map(lags, \\(l) epi_cor(can_prov, case_rate, death_rate, cor_by = geo_value, dt1 = -l)) |&gt;\n  set_names(lags) |&gt; \n  list_rbind(names_to = \"lag\") |&gt;\n  summarize(mean_cor = mean(cor, na.rm = TRUE), .by = lag) |&gt;\n  mutate(lag = as.numeric(lag))\n\n\n\n\nReally strong weekly pattern.\nBut we can fix that."
  },
  {
    "objectID": "slides/lecture2.html#quickly-compute-rolling-functions-by-group",
    "href": "slides/lecture2.html#quickly-compute-rolling-functions-by-group",
    "title": "EpiData Workshop 2025",
    "section": "Quickly compute rolling functions by group",
    "text": "Quickly compute rolling functions by group\n\n# trailing by default, new names are automatically created\ncan_prov &lt;- epi_slide_mean(can_prov, c(case_rate, death_rate), .window_size = 7L)\ncan_lag_cors &lt;- map(\n  lags, \n  \\(l) epi_cor(can_prov, case_rate_7dav, death_rate_7dav, cor_by = geo_value, dt1 = -l)\n)"
  },
  {
    "objectID": "slides/lecture2.html#notes-on-lagged-correlations",
    "href": "slides/lecture2.html#notes-on-lagged-correlations",
    "title": "EpiData Workshop 2025",
    "section": "Notes on lagged correlations",
    "text": "Notes on lagged correlations\n Trailing average pushes the correlation backward\n But weekly reporting aggregates incidence forward\n These may roughly offset, but better if you know the probability of reports and deconvolve\nmore on this later\n We were only averaging over 13 provinces + territories\n Implicitly assuming that reporting / testing / disease behaviour is stable over 4 years"
  },
  {
    "objectID": "slides/lecture2.html#compare-to-the-us",
    "href": "slides/lecture2.html#compare-to-the-us",
    "title": "EpiData Workshop 2025",
    "section": "Compare to the US",
    "text": "Compare to the US\n\n# Only consider the 50 US states (no territories)\nus_edf &lt;- covid_case_death_rates |&gt; filter(geo_value %in% tolower(state.abb)) \ncor0 &lt;- epi_cor(us_edf, case_rate, death_rate, cor_by = geo_value)\ncor21 &lt;- epi_cor(us_edf, case_rate, death_rate, cor_by = geo_value, dt1 = -21)"
  },
  {
    "objectID": "slides/lecture2.html#compare-to-the-us-1",
    "href": "slides/lecture2.html#compare-to-the-us-1",
    "title": "EpiData Workshop 2025",
    "section": "Compare to the US",
    "text": "Compare to the US\n\n\nAggregate cases tend to lead deaths by ≈23 days (arg max \\(\\rho\\))\n Same was true for Canada after smoothing, but lower correlation"
  },
  {
    "objectID": "slides/lecture2.html#examining-how-correlations-change-over-time",
    "href": "slides/lecture2.html#examining-how-correlations-change-over-time",
    "title": "EpiData Workshop 2025",
    "section": "Examining how correlations change over time",
    "text": "Examining how correlations change over time\n\ncor0 &lt;- epi_cor(us_edf, case_rate, death_rate, cor_by = time_value, method = \"kendall\")\ncor21 &lt;- epi_cor(us_edf, case_rate, death_rate, cor_by = time_value, method = \"kendall\", dt1 = -21)"
  },
  {
    "objectID": "slides/lecture2.html#compute-growth-rates",
    "href": "slides/lecture2.html#compute-growth-rates",
    "title": "EpiData Workshop 2025",
    "section": "Compute growth rates",
    "text": "Compute growth rates\n\nedfg &lt;- filter(can_prov, geo_value %in% c(\"MB\", \"BC\"), !is.na(case_rate_7dav)) |&gt;\n  mutate(gr_cases = growth_rate(case_rate_7dav, time_value, method = \"linear_reg\", h = 21L), .by = geo_value)"
  },
  {
    "objectID": "slides/lecture2.html#outlier-detection",
    "href": "slides/lecture2.html#outlier-detection",
    "title": "EpiData Workshop 2025",
    "section": "Outlier detection",
    "text": "Outlier detection\n\noutliers &lt;- outliers |&gt;\n  mutate(detect_outlr_rm(time_value, cases), .by = geo_value)"
  },
  {
    "objectID": "slides/lecture2.html#advanced-sliding-on-an-epi_df",
    "href": "slides/lecture2.html#advanced-sliding-on-an-epi_df",
    "title": "EpiData Workshop 2025",
    "section": "Advanced sliding on an epi_df",
    "text": "Advanced sliding on an epi_df\n\nCompute rolling summaries of signals.\nThese depend on the reference time\nComputed separately over geographies (and other groups).\n\n\nepi_slide(\n  .x,\n  .f,\n  ..., # for tidy-evaluation\n  .window_size = NULL,\n  .align = c(\"right\", \"center\", \"left\"),\n  .ref_time_values = NULL, # at which time values do I calculate the function\n  .new_col_name = NULL, # add a new column with this name rather than the default\n  .all_rows = FALSE # do return all available time_values, or only the ones with a result\n)\n\n\n.f “sees” a data set with a time value and other columns\nThat data is labeled with\n\nA reference time (the time around which the window is taken)\nA grouping key\n\n\n\n\nepi_slide() is very general, often too much so.\nWe already saw the most common special case epi_slide_mean()\nFor other common cases, there is epi_slide_opt()"
  },
  {
    "objectID": "slides/lecture2.html#really-ugly-but-actually-deployed-slide-functions",
    "href": "slides/lecture2.html#really-ugly-but-actually-deployed-slide-functions",
    "title": "EpiData Workshop 2025",
    "section": "Really ugly, but actually deployed slide functions",
    "text": "Really ugly, but actually deployed slide functions\nFunction to flag outliers for corrections during late-2020 and early-2021\n\nflag_covid_outliers &lt;- function(signal, sig_cut = 2.75, size_cut = 20, sig_consec = 1.2) {\n  signal &lt;- rlang::enquo(signal)\n  function(x, g, t) {\n    .fns &lt;- list(m = ~ mean(.x, na.rm = TRUE), med = ~ median(.x, na.rm = TRUE), \n                 sd = ~ sd(.x, na.rm = TRUE), mad = ~ median(abs(.x - median(.x)))\n    )\n    fs &lt;- filter(x, time_value &lt;= t) |&gt; summarise(across(!!signal, .fns, .names = \"{.fn}\"))\n    ss &lt;- summarise(x, across(!!signal, .fns, .names = \"{.fn}\"))\n    mutate(\n      x, \n      ftstat = abs(!!signal - fs$med) / fs$sd, # mad in denominator is wrong scale, \n      ststat = abs(!!signal - ss$med) / ss$sd, # basically results in all the data flagged\n      flag = \n        (abs(!!signal) &gt; size_cut & !is.na(ststat) & ststat &gt; sig_cut) | # best case\n        (is.na(ststat) & abs(!!signal) &gt; size_cut & !is.na(ftstat) & ftstat &gt; sig_cut) | \n        # use filter if smoother is missing\n        (!!signal &lt; -size_cut & (!is.na(ststat) | !is.na(ftstat))), # big negative\n      flag = flag | # these allow smaller values to also be outliers if they are consecutive\n        (lead(flag) & !is.na(ststat) & ststat &gt; sig_consec) | \n        (lag(flag) & !is.na(ststat) & ststat &gt; sig_consec) |\n        (lead(flag) & is.na(ststat) & ftstat &gt; sig_consec) |\n        (lag(flag) & is.na(ststat) & ftstat &gt; sig_consec)\n    ) |&gt; filter(time_value == t) |&gt; pull(flag)\n  }\n}"
  },
  {
    "objectID": "slides/lecture2.html#really-ugly-but-actually-deployed-slide-functions-1",
    "href": "slides/lecture2.html#really-ugly-but-actually-deployed-slide-functions-1",
    "title": "EpiData Workshop 2025",
    "section": "Really ugly, but actually deployed slide functions",
    "text": "Really ugly, but actually deployed slide functions\nFunction to back distribute data randomly\n\ncorrections_multinom_roll &lt;- function(x, excess, flag, time_value, max_lag = 30L, reweight = exp_w) {\n  locs &lt;- which(flag)\n  if (length(locs) == 0) return(x)\n  for (ii in locs) {\n    if (ii &lt;= max_lag) ii_lag &lt;- seq_len(ii)\n    else ii_lag &lt;- seq(ii - max_lag + 1, ii)\n    w &lt;- reweight(length(ii_lag)) / length(ii_lag)\n    x[ii] &lt;- x[ii] - excess[ii]\n    prop &lt;- x[ii_lag] + sign(excess[ii]) * rmultinom(1, abs(excess[ii]), w)\n    x[ii_lag] &lt;- prop\n  }\n  x\n}\nexp_w &lt;- function(n, std_decay = 30L, b0 = 8, a = exp(1) / 2){\n  w &lt;- (1:std_decay) / std_decay\n  w &lt;- tail(w, n)\n  1 / (1 + exp(-w * b0 + a))\n}"
  },
  {
    "objectID": "slides/lecture2.html#roll-our-outlier-detector-then-calculate-the-corrections",
    "href": "slides/lecture2.html#roll-our-outlier-detector-then-calculate-the-corrections",
    "title": "EpiData Workshop 2025",
    "section": "Roll our outlier detector, then calculate the corrections",
    "text": "Roll our outlier detector, then calculate the corrections\n\ncorrections_df &lt;- epi_slide(\n  corrections_df, .align = \"center\", .window_size = 14L, .new_col_name = \"flag\",\n  .f = flag_covid_outliers(deaths)\n) |&gt; mutate(corrected_deaths = corrections_multinom_roll(deaths, deaths, flag, time_value), .by = geo_value)"
  },
  {
    "objectID": "slides/lecture2.html#epi_archive-collection-of-epi_dfs",
    "href": "slides/lecture2.html#epi_archive-collection-of-epi_dfs",
    "title": "EpiData Workshop 2025",
    "section": "epi_archive: Collection of epi_dfs",
    "text": "epi_archive: Collection of epi_dfs\n\nFull version history of a data set\nActs like a bunch of epi_df’s — but stored compactly\nSimilar functionality as we saw but using only data that would have been available at the time\n\n\n\n\n\n\n\nRevisions\n\n\nEpidemiology data gets revised frequently.\n\nWe may want to use the data as it looked in the past.\nor we may want to examine the history of revisions."
  },
  {
    "objectID": "slides/lecture2.html#epi_archive-collection-of-epi_dfs-1",
    "href": "slides/lecture2.html#epi_archive-collection-of-epi_dfs-1",
    "title": "EpiData Workshop 2025",
    "section": "epi_archive: Collection of epi_dfs",
    "text": "epi_archive: Collection of epi_dfs\nSubset of daily COVID-19 doctor visits (Optum) and cases (JHU CSSE) from all U.S. states in archive format:\n\narchive_cases_dv_subset_all_states"
  },
  {
    "objectID": "slides/lecture2.html#summarize-revision-behaviour",
    "href": "slides/lecture2.html#summarize-revision-behaviour",
    "title": "EpiData Workshop 2025",
    "section": "Summarize revision behaviour",
    "text": "Summarize revision behaviour\n\nrevision_data &lt;- revision_summary(archive_cases_dv_subset, case_rate_7d_av)\nrevision_data"
  },
  {
    "objectID": "slides/lecture2.html#visualize-revision-patterns",
    "href": "slides/lecture2.html#visualize-revision-patterns",
    "title": "EpiData Workshop 2025",
    "section": "Visualize revision patterns",
    "text": "Visualize revision patterns"
  },
  {
    "objectID": "slides/lecture2.html#finalized-data",
    "href": "slides/lecture2.html#finalized-data",
    "title": "EpiData Workshop 2025",
    "section": "Finalized data",
    "text": "Finalized data\n\nCounts are revised as time proceeds\nWant to know the final value\nOften not available until weeks/months later\n\n\nBackcasting\n\nAt time \\(t\\), predict the final value for time \\(t-h\\), \\(h &lt; 0\\)\n\n\n\n\nNowcasting\n\nAt time \\(t\\), predict the final value for time \\(t\\)\n\n\n\n\nForecasting\n\nAt time \\(t\\), predict the final value for time \\(t+h\\), \\(h &gt; 0\\)"
  },
  {
    "objectID": "slides/lecture2.html#sliding-computations-over-archives",
    "href": "slides/lecture2.html#sliding-computations-over-archives",
    "title": "EpiData Workshop 2025",
    "section": "Sliding computations over archives",
    "text": "Sliding computations over archives\n\nepix_slide(\n  .x,\n  .f,\n  ...,\n  .before = Inf,\n  .versions = NULL,\n  .new_col_name = NULL,\n  .all_versions = FALSE\n)\n\n\n\nTo perform nowcasts we need to track how values get revised\nTo evaluate forecasting models, we need to test them on the data we would have seen"
  },
  {
    "objectID": "slides/lecture2.html#why-this-matters",
    "href": "slides/lecture2.html#why-this-matters",
    "title": "EpiData Workshop 2025",
    "section": "Why this matters",
    "text": "Why this matters\n\nEvery week BC CDC released COVID-19 hospitalization data.\nThe following week, they revised the number upward (by ~25%) due to lagged reports.\n\n\n\nComparing preliminary to revised data often shows a decline.\nDue to backfill"
  },
  {
    "objectID": "slides/lecture2.html#backfill-american-edition---nchs-covid-19-mortality",
    "href": "slides/lecture2.html#backfill-american-edition---nchs-covid-19-mortality",
    "title": "EpiData Workshop 2025",
    "section": "Backfill American edition - NCHS COVID-19 mortality",
    "text": "Backfill American edition - NCHS COVID-19 mortality"
  },
  {
    "objectID": "slides/lecture2.html#the-revision-triangle",
    "href": "slides/lecture2.html#the-revision-triangle",
    "title": "EpiData Workshop 2025",
    "section": "The revision triangle",
    "text": "The revision triangle\n\n\n\nOn day \\(t\\), predict the finalized value of signal \\(y_t\\)\nWe may have a provisional value for \\(y_t\\) (subject to revision)\nMost likely, we only have provisional values for earlier dates\nWe may only have “finalized” values for \\(y_{t-s}\\), \\(s\\gg0\\)"
  },
  {
    "objectID": "slides/lecture2.html#formal-analysis-of-versioning-behavior",
    "href": "slides/lecture2.html#formal-analysis-of-versioning-behavior",
    "title": "EpiData Workshop 2025",
    "section": "Formal analysis of versioning behavior",
    "text": "Formal analysis of versioning behavior\n\nLatency\n\nthe time difference between Reference Date and Initial Report Date\n\nBackfill\n\nthe characteristics of updates after initial report (typical positive)\n\n\n\n# same as before, but the NCHS data\nrevision_data &lt;- revision_summary(nchs_archive, mortality, within_latest = .05, return_only_tibble = TRUE)\nrevision_data |&gt; filter(geo_value == \"ca\", time_value %in% nchs_versions) |&gt; print(width = 120)\n\n# A tibble: 12 × 11\n   time_value geo_value n_revisions min_lag max_lag  lag_near_latest spread\n   &lt;date&gt;     &lt;chr&gt;           &lt;dbl&gt; &lt;drtn&gt;  &lt;drtn&gt;   &lt;drtn&gt;           &lt;dbl&gt;\n 1 2024-01-07 ca                 19 1 weeks 47 weeks 10 weeks           170\n 2 2024-01-14 ca                 11 1 weeks 21 weeks  6 weeks           144\n 3 2024-01-21 ca                 12 1 weeks 29 weeks  5 weeks           111\n 4 2024-01-28 ca                 13 1 weeks 23 weeks 10 weeks           113\n 5 2024-02-04 ca                 13 1 weeks 42 weeks  9 weeks           102\n 6 2024-02-11 ca                  9 1 weeks 14 weeks  5 weeks            89\n 7 2024-02-18 ca                 10 1 weeks 37 weeks 11 weeks            81\n 8 2024-02-25 ca                 10 1 weeks 53 weeks  8 weeks            74\n 9 2024-03-03 ca                  8 1 weeks 14 weeks  8 weeks            46\n10 2024-03-10 ca                 11 1 weeks 50 weeks  9 weeks            63\n11 2024-03-17 ca                  7 1 weeks 25 weeks  8 weeks            50\n12 2024-03-24 ca                  8 1 weeks 12 weeks 10 weeks            28\n   rel_spread min_value max_value median_value\n        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n 1      0.859        28       198        190. \n 2      0.754        47       191        184  \n 3      0.730        41       152        148  \n 4      0.785        31       144        136. \n 5      0.685        47       149        140. \n 6      0.856        15       104         99.5\n 7      0.779        23       104         97  \n 8      0.712        30       104         97  \n 9      0.639        26        72         67  \n10      0.851        11        74         70.5\n11      0.769        15        65         60.5\n12      0.683        13        41         37"
  },
  {
    "objectID": "slides/lecture2.html#revision-pattern-visualization",
    "href": "slides/lecture2.html#revision-pattern-visualization",
    "title": "EpiData Workshop 2025",
    "section": "Revision pattern visualization",
    "text": "Revision pattern visualization"
  },
  {
    "objectID": "slides/lecture2.html#building-training-data-for-nowcasting",
    "href": "slides/lecture2.html#building-training-data-for-nowcasting",
    "title": "EpiData Workshop 2025",
    "section": "Building training data for nowcasting",
    "text": "Building training data for nowcasting\n\nCan’t estimate any statistical model, unless I “see” the response\nThe finalized value, is often very slow (~ 1 year for this signal)\nSo a compromise is to use something close, here I’m using 95% of the finalized value\n\n\nrevision_ca &lt;- filter(revision_data, geo_value == \"ca\")\nrevision_ca |&gt; select(geo_value, time_value, lag_near_latest) |&gt; slice_sample(n = 5)\n\n# A tibble: 5 × 3\n  geo_value time_value lag_near_latest\n  &lt;chr&gt;     &lt;date&gt;     &lt;drtn&gt;         \n1 ca        2021-07-11 16 weeks       \n2 ca        2024-03-17  8 weeks       \n3 ca        2021-04-04  9 weeks       \n4 ca        2024-03-03  8 weeks       \n5 ca        2023-03-19  6 weeks       \n\n(lag_quantiles &lt;- quantile(revision_data$lag_near_latest))\n\nTime differences in weeks\n  0%  25%  50%  75% 100% \n   1    6    8   13  156 \n\napprox_final_lag &lt;- lag_quantiles[\"75%\"]\n\n\n\nPretend that for time \\(s\\), the \\(Y_s\\) with version \\(s +\\) 13 weeks is “final”.\nAt time \\(t\\), the most recent data in our training set will be 13 weeks old."
  },
  {
    "objectID": "slides/lecture2.html#what-about-features",
    "href": "slides/lecture2.html#what-about-features",
    "title": "EpiData Workshop 2025",
    "section": "What about features?",
    "text": "What about features?\nMust use features that would have been available at test time.\nMust have enough samples to ensure sensible estimation results.\n\nprovisional value(s) for time \\(t\\)\nprovisional value(s) for time \\(t-\\ell\\)\nexogenous signals that may be available\n\n\nPotential model\nPredictors are\n\nProvisional values for time \\(t-\\ell\\), \\(\\ell =\\) 1 week, 2 weeks when available\nProvisional \\(Z_{t-k}\\) for HHS/NHSN COVID-19 hospitalizations (these are daily, so different lags)\n\nExclude a potential predictor if it doesn’t have much training data available."
  },
  {
    "objectID": "slides/lecture2.html#operationalizing",
    "href": "slides/lecture2.html#operationalizing",
    "title": "EpiData Workshop 2025",
    "section": "Operationalizing",
    "text": "Operationalizing\n\nFunction needs to work on multiple nowcast dates\nSometimes reporting changes, so we should adjust, not error\nIf a predictor isn’t available, we remove it from the model and proceed\nMake sure we have “enough” training data to fit a model\nThe nowcaster needs access to all versions prior to the nowcast date\nWe want to retrain at every date: epix_slide(..., .all_versions = TRUE)\nAllow for linear regression or median regression"
  },
  {
    "objectID": "slides/lecture2.html#big-ugly-function",
    "href": "slides/lecture2.html#big-ugly-function",
    "title": "EpiData Workshop 2025",
    "section": "Big ugly function",
    "text": "Big ugly function\n\nGoal: eventually refactor and put in {epipredict}\n\n\nregression_nowcaster &lt;- function(archive, model_settings, return_info = FALSE) {\n  if (!inherits(archive, \"epi_archive\")) stop(\"`archive` isn't an `epi_archive`\")\n  if (n_distinct(archive$DT$geo_value) != 1L) stop(\"Expected exactly one unique `geo_value`\")\n  if (archive$time_type == \"day\") archive &lt;- thin_daily_to_weekly_archive(archive)\n  nowcast_date &lt;- archive$versions_end\n  target_time_value &lt;- nowcast_date\n  latest_edf &lt;- archive |&gt; epix_as_of(nowcast_date)\n\n  predictor_descriptions &lt;-\n    latest_edf |&gt;\n    mutate(lag_days = as.integer(nowcast_date - time_value)) |&gt;\n    select(-c(geo_value, time_value)) |&gt;\n    pivot_longer(-lag_days, names_to = \"varname\", values_to = \"value\") |&gt;\n    drop_na(value) |&gt;\n    inner_join(model_settings$predictors, by = \"varname\", unmatched = \"error\") |&gt;\n    filter(abs(lag_days) &lt;= max_abs_shift_days) |&gt;\n    arrange(varname, abs(lag_days)) |&gt;\n    group_by(varname) |&gt;\n    filter(seq_len(n()) &lt;= max_n_shifts[[1]]) |&gt;\n    ungroup() |&gt;\n    mutate(predictor_name = paste0(varname, \"_lag\", lag_days, \"_realtime\")) |&gt;\n    select(varname, lag_days, predictor_name)\n\n  predictor_edfs &lt;- predictor_descriptions |&gt;\n    pmap(function(varname, lag_days, predictor_name) get_predictor_training_data(archive, varname, lag_days, predictor_name)) |&gt;\n    lapply(na.omit) |&gt;\n    keep(~ nrow(.x) &gt;= model_settings$min_n_training_per_predictor)\n\n  if (length(predictor_edfs) == 0) stop(\"Couldn't find acceptable predictors in the latest data.\")\n\n  predictors &lt;- reduce(predictor_edfs, full_join, by = c(\"geo_value\", \"time_value\"))\n  target &lt;- latest_edf |&gt;\n    filter(time_value &lt;= max(time_value) - model_settings$days_until_target_semistable) |&gt;\n    select(geo_value, time_value, mortality_semistable = mortality)\n\n  training_and_nowcast &lt;- full_join(predictors, target, by = c(\"geo_value\", \"time_value\"))\n\n  training &lt;- training_and_nowcast |&gt;\n    drop_na() |&gt;\n    slice_max(time_value, n = model_settings$max_n_training_intersection)\n\n  nowcast_features &lt;- training_and_nowcast |&gt; filter(time_value == nowcast_date)\n\n  form &lt;- as.formula(\"mortality_semistable ~ .\")\n  fit_fun &lt;- switch(\n    model_settings$method,\n    rq = function(x) { quantreg::rq(data = x, formula = form, tau = 0.5) },\n    lm = function(x) { lm(formula = form, data = x) }\n  )\n  the_fit &lt;- training |&gt;\n    select(any_of(predictor_descriptions$predictor_name), mortality_semistable) |&gt;\n    fit_fun()\n      \n  pred &lt;- tibble(\n    geo_value = \"ca\",\n    nowcast_date = nowcast_date,\n    target_date = target_time_value,\n    prediction = unname(predict(the_fit, nowcast_features))\n  )\n\n  if (return_info) return(tibble(coefficients = list(coef(fit)), predictions = list(pred)))\n  return(pred)\n}"
  },
  {
    "objectID": "slides/lecture2.html#model-settings",
    "href": "slides/lecture2.html#model-settings",
    "title": "EpiData Workshop 2025",
    "section": "Model settings",
    "text": "Model settings\nWe’ll compare 4 different configurations:\n\nUsing lm() and only mortality predictors\nUsing lm() with mortality and hospitalizations as a predictor\nUsing rq() and only mortality predictors\nUsing rq() with mortality and hospitalizations as a predictor\n\n\nreg1_settings &lt;- list(\n  predictors = tribble(\n    ~varname,    ~max_abs_shift_days, ~max_n_shifts,\n    \"mortality\",                  35,             3,\n    ),\n  min_n_training_per_predictor = 30, # or else exclude predictor\n  days_until_target_semistable = 7 * 7, # filter out unstable when training (and evaluating)\n  min_n_training_intersection = 20, # or else raise error\n  max_n_training_intersection = Inf # or else filter down rows\n)"
  },
  {
    "objectID": "slides/lecture2.html#comparison-linear-regression",
    "href": "slides/lecture2.html#comparison-linear-regression",
    "title": "EpiData Workshop 2025",
    "section": "Comparison: linear regression",
    "text": "Comparison: linear regression"
  },
  {
    "objectID": "slides/lecture2.html#comparison-quantile-regression",
    "href": "slides/lecture2.html#comparison-quantile-regression",
    "title": "EpiData Workshop 2025",
    "section": "Comparison: quantile regression",
    "text": "Comparison: quantile regression"
  },
  {
    "objectID": "slides/lecture2.html#evaluations",
    "href": "slides/lecture2.html#evaluations",
    "title": "EpiData Workshop 2025",
    "section": "Evaluations",
    "text": "Evaluations\n\n\n\n\n\nNowcaster\nMAE\nMAPE\n\n\n\n\nBaseline\n197.43\n75.28\n\n\nLinReg\n172.03\n106.74\n\n\nLinReg + hosp\n100.49\n58.17\n\n\nQuantReg\n103.70\n48.81\n\n\nQuantReg + hosp\n93.33\n48.94"
  },
  {
    "objectID": "slides/lecture2.html#aside-on-nowcasting",
    "href": "slides/lecture2.html#aside-on-nowcasting",
    "title": "EpiData Workshop 2025",
    "section": "Aside on nowcasting",
    "text": "Aside on nowcasting\n\nTo many Epis, nowcasting means estimate the instantaneous reproduction number, \\(R_t\\)\nExample: Reported COVID-19 cases in British Columbia (Jan. 2020 – Apr. 2023)\n\n\n\nMore after lunch…"
  },
  {
    "objectID": "slides/lecture2.html#more-practice-with-the-worksheet",
    "href": "slides/lecture2.html#more-practice-with-the-worksheet",
    "title": "EpiData Workshop 2025",
    "section": "More practice with the worksheet",
    "text": "More practice with the worksheet\n\nSignal processing and exploratory data analysis\nExamining revision and latency patterns\nThinking about the revision triangle and how to use it\nBasics of statistical nowcasting"
  },
  {
    "objectID": "worksheet/index.html",
    "href": "worksheet/index.html",
    "title": "Processing and Forecasting with Epidemic Surveillance Data",
    "section": "",
    "text": "The goal of this worksheet is to practice some of the techniques discussed during the lectures. The plan is to take a “phased” approach, with 15-30 minutes of work after each of the four lectures. But the idea is to roughly continue on the same problem."
  },
  {
    "objectID": "worksheet/index.html#computer-setup",
    "href": "worksheet/index.html#computer-setup",
    "title": "Processing and Forecasting with Epidemic Surveillance Data",
    "section": "Computer setup",
    "text": "Computer setup\nThe following are packages needed for this worksheet. With luck, you would need only a few more (perhaps none!) to build all the slides in this workshop. But I make no guarantees.\n\ninstall.packages(\"remotes\")\ninstall.packages(\"tidyverse\")\ninstall.packages(\"tidymodels\")\ninstall.packages(\"glmnet\")\nremotes::install_github(\"cmu-delphi/epidatr\")\nremotes::install_github(\"cmu-delphi/epidatasets\")\nremotes::install_github(\"cmu-delphi/epiprocess@dev\")\nremotes::install_github(\"cmu-delphi/epipredict@dev\")\nremotes::install_github(\"dajmcdon/rtestim\")\n\nNote that both {epiprocess} and {epipredict} are set to install from the development branch rather than from the main branch. So this is the most up-to-date version, but it is also potentially unstable.\nThe best place for package documentation is typically the website rather than the R help files. So some useful links are here:\n\nhttps://cmu-delphi.github.io/epidatr\nhttps://cmu-delphi.github.io/epiprocess\nhttps://cmu-delphi.github.io/epipredict\nhttps://tidyverse.org\nhttps://tidymodels.org\nhttps://dajmcdon.github.io/rtestim"
  },
  {
    "objectID": "worksheet/index.html#lecture-1-introduction-to-panel-data-in-epidemiology",
    "href": "worksheet/index.html#lecture-1-introduction-to-panel-data-in-epidemiology",
    "title": "Processing and Forecasting with Epidemic Surveillance Data",
    "section": "Lecture 1: Introduction to Panel Data in Epidemiology",
    "text": "Lecture 1: Introduction to Panel Data in Epidemiology\nLet’s examine two different sources of versioned panel data.\n\nSource 1: Respiratory Virus Detection Surveillance System\nNavigate to the Dashboard maintained by the Public Health Agency of Canada: https://health-infobase.canada.ca/respiratory-virus-detections/. Let’s focus on Figure 4.\n\nWhen was it last updated?\nWhat is the reference date for the most recent data?\nWhat geographic regions are available for different data streams?\nAre the revisions tracked?\n\n\n\nSource 2: Delphi Epi Portal\n\nBrowse the table.\nWhat sorts of signals are available?\nFor what regions?\nSelect a signal with at least state-level geographic coverage that is “Ongoing” (For example, “Covid-Related Doctor Visits”)\nAre revisions tracked?\nWhat sort of latency does it have?\n\n\n\nExtra credit\n\nDownload this season’s RVDSS data. This is most easily done by following the instructions at https://github.com/dajmcdon/rvdss-canada. (My team scrapes the data weekly. Just use the R code at the bottom of the README to “Read in data for a single season”)\nDownload the signal from the Delphi Epidata API that you chose above using {epidatr}.\nExplore and examine both signals using graphics or summary statistics."
  },
  {
    "objectID": "worksheet/index.html#lecture-2-data-cleaning-versioning-and-nowcasting",
    "href": "worksheet/index.html#lecture-2-data-cleaning-versioning-and-nowcasting",
    "title": "Processing and Forecasting with Epidemic Surveillance Data",
    "section": "Lecture 2: Data Cleaning, Versioning, and Nowcasting",
    "text": "Lecture 2: Data Cleaning, Versioning, and Nowcasting\n\nIf you didn’t get a chance earlier, download this season’s RVDSS data.\nFilter to only those rows with geo_type != \"province\". (This is a bit of a misnomer, we’re keeping some provinces and some regions.)\nConvert it to an epi_archive with as_epi_archive().\nExamine the revision behaviour for one of the signals. The best way is with a plot. (Unfortunately, revision_summary() won’t work for the moment.)\nIs there much backfill? Latency?\nUse epix_as_of_current() to get the most recent snapshot.\nLet’s look at just flu_pct_positive. Calculate the average correlation across geographies at lag 7 and lag 14.\nCalculate the correlation between flu_pct_positive and sarscov2_pct_positive over time and plot the result.\n\nIf there’s still time, try to calculate the growth rate for flu_pct_positive."
  },
  {
    "objectID": "worksheet/index.html#lecture-3",
    "href": "worksheet/index.html#lecture-3",
    "title": "Processing and Forecasting with Epidemic Surveillance Data",
    "section": "Lecture 3:",
    "text": "Lecture 3:\nHere’s a modified version of the SIR simulation function that returns only the new infections:\n\nsim_SIR &lt;- function(TT, N = 1000, beta = .1, gamma = .01) {\n  S &lt;- double(TT)\n  I &lt;- double(TT)\n  R &lt;- double(TT)\n  S[1] &lt;- N - 1\n  I[1] &lt;- 1\n  i &lt;- double(TT)\n  i[1] &lt;- 1\n  for (tt in 2:TT) {\n    contagions &lt;- rbinom(1, size = S[tt - 1], prob = beta * I[tt - 1] / N)\n    removals &lt;- rbinom(1, size = I[tt - 1], prob = gamma)\n    S[tt] &lt;- S[tt - 1] - contagions\n    I[tt] &lt;- I[tt - 1] + contagions - removals\n    R[tt] &lt;- R[tt - 1] + removals\n    i[tt] &lt;- contagions\n  }\n  tibble(infections = i, time = seq(TT))\n}\n\n\nContinuing with the RVDSS data (most recent snapshot), make a plot of flu_positive_tests for your favourite region.\nAdjust the parameters N, beta, and gamma to calibrate an SIR model that fits the data closely.\nUse {rtestim} to estimate \\(R_t\\) for your favourite region."
  },
  {
    "objectID": "worksheet/index.html#lecture-4-forecasting-and-advanced-topics",
    "href": "worksheet/index.html#lecture-4-forecasting-and-advanced-topics",
    "title": "Processing and Forecasting with Epidemic Surveillance Data",
    "section": "Lecture 4: Forecasting and Advanced Topics",
    "text": "Lecture 4: Forecasting and Advanced Topics\n\nContinuing with the RVDSS data (most recent snapshot), use arx_forecaster() to produce forecasts 1, 2, and 3 weeks after of the most recent data for flu_pct_positive.\nYou can plot them as follows (for example):\n\n\nh1 &lt;- arx_forecaster(rvdss, ..., args_list = arx_args_list(ahead = 7))\nautoplot(h1)\n\n\nAdjust the arguments however you like. You can add other predictors, adjust lags, change forecasting engines, etc.\n\nIf you have time, try “Building a forecaster from scratch” this is more difficult to plot, but you can borrow the code from the lecture slides."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "EpiData Workshop 2025",
    "section": "Schedule",
    "text": "Schedule\nIn this workshop, we plan to demonstrate how to use R to load, process, inspect, and forecast aggregate epi surveillance data. We will be presenting a few case studies to motivate the entire pipeline from signal discovery to the production of nowcasts and forecasts.\n\nLecture 1: Introduction to Panel Data\nLecture 2: Data Cleaning, Versioning, and Nowcasting\nLecture 3: Compartmental Models, Renewal Equations, and \\(R_t\\) Estimation\nLecture 4: Forecasting and Advanced Topics\n\nWorksheet"
  },
  {
    "objectID": "index.html#contributors-and-collaborators",
    "href": "index.html#contributors-and-collaborators",
    "title": "EpiData Workshop 2025",
    "section": "Contributors and collaborators",
    "text": "Contributors and collaborators\nInstructor: Daniel J. McDonald\nWith help from:\n\nRyan J. Tibshirani\nLogan C. Brooks\nRachel Lobay\nAlice Clima\nOlivia Liu, Elvis Cai, and Paul Gustafson"
  },
  {
    "objectID": "slides/lecture1.html#outline",
    "href": "slides/lecture1.html#outline",
    "title": "EpiData Workshop 2025",
    "section": "Outline",
    "text": "Outline\n\nAbout\nWorkshop Overview and System Setup\nPanel Data\nVersioned Data\nEpidata Repository and API\n{epidatr} and Other Data\nVersioning in {epidatr}"
  },
  {
    "objectID": "slides/lecture1.html#daniel-j.-mcdonald",
    "href": "slides/lecture1.html#daniel-j.-mcdonald",
    "title": "EpiData Workshop 2025",
    "section": "Daniel J. McDonald",
    "text": "Daniel J. McDonald\n\nPhD in Statistics from Carnegie Mellon University\nRisk Bounds for Time series, esp. macroeconomic forecasting\nSubsequent research and teaching on machine learning (model selection, optimization, regularization, nonparametrics)\nBegan working on epidemiology in mid-2020 with Delphi Research Group\nFocus is largely on forecasting and nowcasting epidemic aggregates\nFunding from US CDC (ongoing?), CSTE, NSERC, CANSSI"
  },
  {
    "objectID": "slides/lecture1.html#about-delphi",
    "href": "slides/lecture1.html#about-delphi",
    "title": "EpiData Workshop 2025",
    "section": "About Delphi",
    "text": "About Delphi\n\nFounded in 2012 at Carnegie Mellon University, now expanded to UC Berkeley, and University of British Columbia.\nCurrently 5 faculty, ~10 PhD students, ~15 staff (mostly software engineers).\nEasy to join us from anywhere (lots of volunteers during Covid-19 pandemic).\nWe are:\n\nCDC Center of Excellence for Influenza and Covid-19 Forecasting (2019-24).\nCDC Innovation Center for Outbreak Analytics and Disease Modeling (2024-29).\n\n\nOur mission: To develop the theory and practice of epidemic detection, tracking and forecasting, and their use in decision making, both public and private."
  },
  {
    "objectID": "slides/lecture1.html#what-does-delphi-do",
    "href": "slides/lecture1.html#what-does-delphi-do",
    "title": "EpiData Workshop 2025",
    "section": "What does Delphi do?",
    "text": "What does Delphi do?\n\nProcure real-time, aggregated data streams informative of infectious diseases and syndromes, in collaboration with partners in industry and government.\nExtract signals and make them widely available via the Epidata platform & API.\nDevelop and deploy algorithms for epidemic detection, tracking, forecasting.\nDevelop and maintain statistical software packages for these tasks.\nMake it all production-grade, maximally-accessible, and open-source (to serve CDC, state and local public health agencies, epi-forecasting researchers, data journalists, the public)"
  },
  {
    "objectID": "slides/lecture1.html#what-we-provide",
    "href": "slides/lecture1.html#what-we-provide",
    "title": "EpiData Workshop 2025",
    "section": "What we provide",
    "text": "What we provide"
  },
  {
    "objectID": "slides/lecture1.html#acknowledgements",
    "href": "slides/lecture1.html#acknowledgements",
    "title": "EpiData Workshop 2025",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nMost of this material was developed for the InsightNet Tooling Workshop in December 2024.\n\n\n\nThanks to major contributors\n\nRyan J. Tibshirani\n\n\nRachel Lobay\n\n\nAlice Clima\n\n\nLogan Brooks\n\n\nDelphi Tooling and Forecasting Team\n\n\nElvis Cai, Olivia Liu, Paul Gustafson\n\n\n\n\n\nFunding\n\nCenter for Forecasting and Outbreak Analytics\n\n\nCouncil of State and Territorial Epidemiologists\n\n\nNSERC\n\n\nCANSSI"
  },
  {
    "objectID": "slides/lecture1.html#what-we-will-cover",
    "href": "slides/lecture1.html#what-we-will-cover",
    "title": "EpiData Workshop 2025",
    "section": "What we will cover",
    "text": "What we will cover\n\nCharacteristics of panel data in epidemiology\nTools for processing and plotting panel data\nStatistical background on nowcasting and forecasting\nTools for building nowcasting and forecasting models\nPlenty of examples throughout of real case studies"
  },
  {
    "objectID": "slides/lecture1.html#goals-part-i",
    "href": "slides/lecture1.html#goals-part-i",
    "title": "EpiData Workshop 2025",
    "section": "Goals part I",
    "text": "Goals part I\nPresent a statistical way of thinking about now/forecasting\n\nBasic mindsets\n\n\ndata versioning and structure\n\n\n\n\nthe importance of empirical validation using techniques like time series cross-validation are ubiquitous\n\n\nCertain basic modeling considerations\n\n\nstarting simple and building up complexity\n\n\n\n\ntaming variance through regularization,\n\n\n\n\naddressing nonstationarity with trailing training windows"
  },
  {
    "objectID": "slides/lecture1.html#goals-part-ii",
    "href": "slides/lecture1.html#goals-part-ii",
    "title": "EpiData Workshop 2025",
    "section": "Goals part II",
    "text": "Goals part II\n\nPresent software whichs aid processing, tracking, nowcasting, and forecasting with panel data\nThese tools are still in development and we welcome your feedback\nWe have tried hard to get the framework right; but many individual pieces themselves could still be improved\nIf these aren’t working for you, then we want to hear from you!\nWe welcome collaboration, and everything we do is open source"
  },
  {
    "objectID": "slides/lecture1.html#a-disclaimer",
    "href": "slides/lecture1.html#a-disclaimer",
    "title": "EpiData Workshop 2025",
    "section": "A disclaimer",
    "text": "A disclaimer\n\nMy background is primarily in statistics and computer science\nThis obviously influences my way of thinking and my approach to nowcasting and forecasting\nI don’t have nearly as much experience with traditional epi models, but I do have opinions about the pros/cons.\nAsk me at any point if you have a question about why I’m doing things a certain way\n\n\n\nThis workshop is supposed to be useful for YOU. Ask questions if you have them, don’t be shy\nWe may not (likely won’t?) cover everything. Hopefully the materials will be a resource for you beyond this workshop"
  },
  {
    "objectID": "slides/lecture1.html#system-setup",
    "href": "slides/lecture1.html#system-setup",
    "title": "EpiData Workshop 2025",
    "section": "System setup",
    "text": "System setup\n\ninstall.packages(\"remotes\")\ninstall.packages(\"tidyverse\")\ninstall.packages(\"tidymodels\")\ninstall.packages(\"glmnet\")\nremotes::install_github(\"cmu-delphi/epidatr\")\nremotes::install_github(\"cmu-delphi/epidatasets\")\nremotes::install_github(\"cmu-delphi/epiprocess@dev\")\nremotes::install_github(\"cmu-delphi/epipredict@dev\")\nremotes::install_github(\"dajmcdon/rtestim\")\n\n\nLet’s take a few moments here.\nYou may also navigate to the GitHub repo and Clone/Fork the entire thing."
  },
  {
    "objectID": "slides/lecture1.html#panel-data-1",
    "href": "slides/lecture1.html#panel-data-1",
    "title": "EpiData Workshop 2025",
    "section": "Panel data",
    "text": "Panel data\n\nPanel data is cross-sectional measurements of subjects over time.\nWith aggregated data, the subjects are geographic units (e.g. provinces, states).\nTime index + one or more locations/keys.\n\n\n\n# A tibble: 549 × 3\n   time_value geo_value percent_cli\n   &lt;date&gt;     &lt;chr&gt;           &lt;dbl&gt;\n 1 2020-06-01 ca               2.75\n 2 2020-06-02 ca               2.57\n 3 2020-06-03 ca               2.48\n 4 2020-06-04 ca               2.41\n 5 2020-06-05 ca               2.57\n 6 2020-06-06 ca               2.63\n 7 2020-06-07 ca               2.73\n 8 2020-06-08 ca               3.04\n 9 2020-06-09 ca               2.97\n10 2020-06-10 ca               2.99\n# ℹ 539 more rows\n\n\nThe % of outpatient doctor visits that are COVID-related in CA, between June 2020 to Dec. 2021"
  },
  {
    "objectID": "slides/lecture1.html#examples-of-panel-data",
    "href": "slides/lecture1.html#examples-of-panel-data",
    "title": "EpiData Workshop 2025",
    "section": "Examples of panel data",
    "text": "Examples of panel data\nJHU CSSE COVID-19 cases per 100k\n\n\n\nWA switch to weekly reporting in 2022\nFL reports “whenever” (weekly, biweekly, three days in a row, then 4 zeros, etc.)\nAPI calculates change from cumulative, so no-report becomes a 0.\nIf state decreases total, then we see a negative."
  },
  {
    "objectID": "slides/lecture1.html#examples-of-panel-data-1",
    "href": "slides/lecture1.html#examples-of-panel-data-1",
    "title": "EpiData Workshop 2025",
    "section": "Examples of panel data",
    "text": "Examples of panel data\nConfirmed COVID-19 Hospital Admissions per 100k, 7day average\n\n\nThe \\(x\\)-axis is\nDate of report\nNot “date of event”"
  },
  {
    "objectID": "slides/lecture1.html#more-disclaimers",
    "href": "slides/lecture1.html#more-disclaimers",
    "title": "EpiData Workshop 2025",
    "section": "More disclaimers…",
    "text": "More disclaimers…\n\nMost of this workshop will focus on panel data\nTypical for the tasks my group has focused on\nTypically analyze aggregate signals\nSimultaneously across geographies\nContrasts with “single geo models”\nNot working with “line list data”"
  },
  {
    "objectID": "slides/lecture1.html#intro-to-versioned-data",
    "href": "slides/lecture1.html#intro-to-versioned-data",
    "title": "EpiData Workshop 2025",
    "section": "Intro to versioned data",
    "text": "Intro to versioned data\n\n\n→ Person comes to ER\n→ Admitted\n→ Has some tests\n→ Tests come back\n→ Entered into the system\n→ …\n\n\n\nEpidemic aggregates are subject to reporting delays and revisions\n\n\n\nA “Hospital admission” may not attributable to a particular condition until a few days have passed\n\n\n\nAdditionally, various mistakes lead to revisions\n\n\n\nTrack both: when the event occurred and when it was reported"
  },
  {
    "objectID": "slides/lecture1.html#intro-to-versioned-data-1",
    "href": "slides/lecture1.html#intro-to-versioned-data-1",
    "title": "EpiData Workshop 2025",
    "section": "Intro to versioned data",
    "text": "Intro to versioned data\n\nEpidemic aggregates are subject to reporting delays and revisions\n\n\n\nA “Hospital admission” may not attributable to a particular condition until a few days have passed\n\n\n\nAdditionally, various mistakes lead to revisions\n\n\n\nTrack both: when the event occurred and when it was reported"
  },
  {
    "objectID": "slides/lecture1.html#versioned-data-1",
    "href": "slides/lecture1.html#versioned-data-1",
    "title": "EpiData Workshop 2025",
    "section": "Versioned data",
    "text": "Versioned data\n\nThe event time is indicated by time_value (or reference_date)\nSecond time index indicates the data version (or reporting_date)\n\nversion = the time at which we saw a value associated to a time_value\n\n\n# A tibble: 6 × 4\n  time_value geo_value percent_cli version   \n  &lt;date&gt;     &lt;chr&gt;           &lt;dbl&gt; &lt;date&gt;    \n1 2020-06-01 ca               2.14 2020-06-06\n2 2020-06-01 ca               2.14 2020-06-08\n3 2020-06-01 ca               2.11 2020-06-09\n4 2020-06-01 ca               2.13 2020-06-10\n5 2020-06-01 ca               2.20 2020-06-11\n6 2020-06-01 ca               2.23 2020-06-12"
  },
  {
    "objectID": "slides/lecture1.html#versioned-panel-data",
    "href": "slides/lecture1.html#versioned-panel-data",
    "title": "EpiData Workshop 2025",
    "section": "Versioned panel data",
    "text": "Versioned panel data\nEstimated percentage of outpatient visits due to CLI across multiple versions."
  },
  {
    "objectID": "slides/lecture1.html#latency-and-revision-in-signals",
    "href": "slides/lecture1.html#latency-and-revision-in-signals",
    "title": "EpiData Workshop 2025",
    "section": "Latency and revision in signals",
    "text": "Latency and revision in signals\n\nLatency the delay between data collection and availability\n\n\n\n\nExample\n\n\nA signal based on insurance claims may take several days to appear as claims are processed\n\n\n\n\n\n\nRevision data is updated or corrected after initial publication\n\n\n\n\nExample\n\n\nCOVID-19 case reports are revised as reporting backlogs are cleared"
  },
  {
    "objectID": "slides/lecture1.html#latency-and-revision-in-signals---example",
    "href": "slides/lecture1.html#latency-and-revision-in-signals---example",
    "title": "EpiData Workshop 2025",
    "section": "Latency and revision in signals - Example",
    "text": "Latency and revision in signals - Example\n\nRecall the first example of panel & versioned data we’ve seen…\n\n\nIn June 2020, this signal is typically 4 days latent\n\n\n\n# A tibble: 5 × 5\n  time_value geo_value percent_cli version    latency\n  &lt;date&gt;     &lt;chr&gt;           &lt;dbl&gt; &lt;date&gt;     &lt;drtn&gt; \n1 2020-06-01 ca               2.14 2020-06-06 5 days \n2 2020-06-02 ca               1.96 2020-06-06 4 days \n3 2020-06-03 ca               1.77 2020-06-06 3 days \n4 2020-06-04 ca               1.65 2020-06-08 4 days \n5 2020-06-05 ca               1.60 2020-06-09 4 days \n\n\n\nand subject to revision\n\n\n# A tibble: 5 × 5\n  time_value geo_value percent_cli version    latency\n  &lt;date&gt;     &lt;chr&gt;           &lt;dbl&gt; &lt;date&gt;     &lt;drtn&gt; \n1 2020-06-01 ca               2.14 2020-06-06  5 days\n2 2020-06-01 ca               2.14 2020-06-08  7 days\n3 2020-06-01 ca               2.11 2020-06-09  8 days\n4 2020-06-01 ca               2.13 2020-06-10  9 days\n5 2020-06-01 ca               2.20 2020-06-11 10 days"
  },
  {
    "objectID": "slides/lecture1.html#revision-triangle-insurance-claims-wa-january-2022",
    "href": "slides/lecture1.html#revision-triangle-insurance-claims-wa-january-2022",
    "title": "EpiData Workshop 2025",
    "section": "Revision triangle, Insurance Claims WA January 2022",
    "text": "Revision triangle, Insurance Claims WA January 2022\n\n7-day trailing average to smooth day-of-week effects"
  },
  {
    "objectID": "slides/lecture1.html#revisions",
    "href": "slides/lecture1.html#revisions",
    "title": "EpiData Workshop 2025",
    "section": "Revisions",
    "text": "Revisions\nMany data sources are subject to revisions:\n\n\nCase and death counts are corrected or adjusted by authorities\nMedical claims can take weeks to be submitted and processed\nSurveys are not completed promptly\n\n\n\nAn accurate revision log is crucial for researchers building nowcasts and forecasts\n\n\n\n\n\n\n\n\nObvious but crucial\n\n\nA forecast that is made today can only use data available “as of” today"
  },
  {
    "objectID": "slides/lecture1.html#three-types-of-revisions",
    "href": "slides/lecture1.html#three-types-of-revisions",
    "title": "EpiData Workshop 2025",
    "section": "Three types of revisions",
    "text": "Three types of revisions\n\nSources that don’t revise (provisional and final are the same)\n\nFacebook Survey and Google symptoms\n\n\nPredictable revisions\n\nClaims data and public health reports aligned by test, hospitalization, or death date\nAlmost always revised upward as additional claims enter the pipeline\n\n\n\nRevisions that are large and erratic to predict\n\nCOVID cases and deaths\nThese are aligned by report date"
  },
  {
    "objectID": "slides/lecture1.html#types-of-revisions---comparison-between-2.-and-3.",
    "href": "slides/lecture1.html#types-of-revisions---comparison-between-2.-and-3.",
    "title": "EpiData Workshop 2025",
    "section": "Types of revisions - Comparison between 2. and 3.",
    "text": "Types of revisions - Comparison between 2. and 3.\n\nRevision behavior for two indicators in the HRR containing Charlotte, NC.\nDV-CLI signal (left): regularly revised, but effects fade\nJHU CSSE cases (right) remain “as first reported” until a major correction is made on Oct. 19"
  },
  {
    "objectID": "slides/lecture1.html#reporting-backlogs---example",
    "href": "slides/lecture1.html#reporting-backlogs---example",
    "title": "EpiData Workshop 2025",
    "section": "Reporting backlogs - Example",
    "text": "Reporting backlogs - Example\nBexar County, Texas, summer of 2020…\n\nLarge backlog of case reports results in a spike\nAuxilliary signals show continued decline\nReports are not be trustworthy without context"
  },
  {
    "objectID": "slides/lecture1.html#what-is-the-epidata-repository",
    "href": "slides/lecture1.html#what-is-the-epidata-repository",
    "title": "EpiData Workshop 2025",
    "section": "What is the Epidata repository",
    "text": "What is the Epidata repository\nEpidata: repository of aggregated epi-surveillance time series\nSignals can be either public or restricted.\n\nCurrently contains over 5 billion records\nDuring pandemic, handled millions of API queries per day\nMany signals aren’t available elsewhere\n\n\n\n\n\n\n\nMake epi-surveillance more nimble, complete, standardized, robust, and real-time"
  },
  {
    "objectID": "slides/lecture1.html#features-of-delphi-epidata",
    "href": "slides/lecture1.html#features-of-delphi-epidata",
    "title": "EpiData Workshop 2025",
    "section": "Features of Delphi Epidata",
    "text": "Features of Delphi Epidata\n\nBuilt-in support for:\n\nData revisions (“backfill”), including reporting dates and changes\nGeo levels w/ auto-aggregation (e.g. county, state, and nation) and specialized levels (e.g., DMA, sewer sheds)\nDemographic breakdown\nRepresentation for missingness and censoring\nPopulation sizes and fine-grained population density\n\nCustomized smoothing and normalization\nAccess control\nCode is Open Source.\nSignals are as accessible (w/ API, SDK) as allowed by DUAs"
  },
  {
    "objectID": "slides/lecture1.html#severity-pyramid",
    "href": "slides/lecture1.html#severity-pyramid",
    "title": "EpiData Workshop 2025",
    "section": "Severity pyramid",
    "text": "Severity pyramid\n\n\nhttps://delphi.cmu.edu/epiportal/"
  },
  {
    "objectID": "slides/lecture1.html#installing-epidatr",
    "href": "slides/lecture1.html#installing-epidatr",
    "title": "EpiData Workshop 2025",
    "section": "Installing {epidatr}",
    "text": "Installing {epidatr}\n(you already did this, but just for posterity…)\nInstall the CRAN version\n\n# Install the CRAN version\ninstall.packages(\"epidatr\")\n\n\nor the development version\n\n# Install the development version from the GitHub dev branch\nremotes::install_github(\"cmu-delphi/epidatr@dev\")\n\nThe CRAN listing is here."
  },
  {
    "objectID": "slides/lecture1.html#python",
    "href": "slides/lecture1.html#python",
    "title": "EpiData Workshop 2025",
    "section": "Python",
    "text": "Python\nIn Python, install delphi-epidata from PyPI with\npip install delphi-epidata\n\ndelphi-epidata is soon to be replaced with epidatpy.\n# Latest dev version\npip install -e \"git+https://github.com/cmu-delphi/epidatpy.git#egg=epidatpy\"\n\n# PyPI version (not yet available)\npip install epidatpy"
  },
  {
    "objectID": "slides/lecture1.html#using-epidatr-and-epidatpy",
    "href": "slides/lecture1.html#using-epidatr-and-epidatpy",
    "title": "EpiData Workshop 2025",
    "section": "Using {epidatr} and {epidatpy}",
    "text": "Using {epidatr} and {epidatpy}\n\nlibrary(epidatr)\nhhs_flu_nc &lt;- pub_covidcast(\n  source = 'hhs', \n  signals = 'confirmed_admissions_influenza_1d', \n  geo_type = 'state', \n  time_type = 'day', \n  geo_values = 'nc',\n  time_values = c(20240401, 20240405:20240414)\n)\nhead(hhs_flu_nc, n = 3)\n\n\n\n# A tibble: 3 × 15\n  geo_value signal     source geo_type time_type time_value direction issue     \n  &lt;chr&gt;     &lt;chr&gt;      &lt;chr&gt;  &lt;fct&gt;    &lt;fct&gt;     &lt;date&gt;         &lt;dbl&gt; &lt;date&gt;    \n1 nc        confirmed… hhs    state    day       2024-04-01        NA 2024-04-22\n2 nc        confirmed… hhs    state    day       2024-04-05        NA 2024-04-22\n3 nc        confirmed… hhs    state    day       2024-04-06        NA 2024-04-22\n# ℹ 7 more variables: lag &lt;dbl&gt;, missing_value &lt;dbl&gt;, missing_stderr &lt;dbl&gt;,\n#   missing_sample_size &lt;dbl&gt;, value &lt;dbl&gt;, stderr &lt;dbl&gt;, sample_size &lt;dbl&gt;\n\n\n\nPython equivalent:\nres = Epidata.covidcast('hhs', 'confirmed_admissions_influenza_1d', 'day', \n  'state', [20240401, Epidata.range(20240405, 20240414)], 'nc')"
  },
  {
    "objectID": "slides/lecture1.html#api-keys",
    "href": "slides/lecture1.html#api-keys",
    "title": "EpiData Workshop 2025",
    "section": "API keys",
    "text": "API keys\n\nAnyone may access the Epidata API anonymously without providing any personal data!!\nAnonymous API access is subject to some restrictions: public datasets only; 60 requests per hour; only two parameters may have multiple selections\nAPI key grants privileged access; can be obtained by registering with us\nPrivileges of registration: no rate limit; no limit on multiple selections\nWe just want to know which signals people care about to ensure we’re providing benefit\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe {epidatr} client automatically searches for the key in the DELPHI_EPIDATA_KEY environment variable.\nWe recommend storing it in your .Renviron file, which R reads by default.\nMore on setting your API key here."
  },
  {
    "objectID": "slides/lecture1.html#interactive-tooling-in-r",
    "href": "slides/lecture1.html#interactive-tooling-in-r",
    "title": "EpiData Workshop 2025",
    "section": "Interactive tooling in R",
    "text": "Interactive tooling in R\n\navail_endpoints()\n\n# A tibble: 28 × 2\n   Endpoint                          Description                                \n   &lt;chr&gt;                             &lt;chr&gt;                                      \n 1 pub_covid_hosp_facility()         COVID hospitalizations by facility         \n 2 pub_covid_hosp_facility_lookup()  Helper for finding COVID hospitalization f…\n 3 pub_covid_hosp_state_timeseries() COVID hospitalizations by state            \n 4 pub_covidcast()                   Various COVID and flu signals via the COVI…\n 5 pub_covidcast_meta()              Metadata for the COVIDcast endpoint        \n 6 pub_delphi()                      Delphi's ILINet outpatient doctor visits f…\n 7 pub_dengue_nowcast()              Delphi's PAHO dengue nowcasts (North and S…\n 8 pub_ecdc_ili()                    ECDC ILI incidence (Europe)                \n 9 pub_flusurv()                     CDC FluSurv flu hospitalizations           \n10 pub_fluview()                     CDC FluView ILINet outpatient doctor visits\n11 pub_fluview_clinical()            CDC FluView flu tests from clinical labs   \n12 pub_fluview_meta()                Metadata for the FluView endpoint          \n13 pub_gft()                         Google Flu Trends flu search volume        \n14 pub_kcdc_ili()                    KCDC ILI incidence (Korea)                 \n15 pub_meta()                        Metadata for the Delphi Epidata API        \n16 pub_nidss_dengue()                NIDSS dengue cases (Taiwan)                \n17 pub_nidss_flu()                   NIDSS flu doctor visits (Taiwan)           \n18 pub_nowcast()                     Delphi's ILI Nearby nowcasts               \n19 pub_paho_dengue()                 PAHO dengue data (North and South America) \n20 pub_wiki()                        Wikipedia webpage counts by article        \n21 pvt_cdc()                         CDC total and by topic webpage visits      \n22 pvt_dengue_sensors()              PAHO dengue digital surveillance sensors (…\n23 pvt_ght()                         Google Health Trends health topics search …\n24 pvt_meta_norostat()               Metadata for the NoroSTAT endpoint         \n25 pvt_norostat()                    CDC NoroSTAT norovirus outbreaks           \n26 pvt_quidel()                      Quidel COVID-19 and influenza testing data \n27 pvt_sensors()                     Influenza and dengue digital surveillance …\n28 pvt_twitter()                     HealthTweets total and influenza-related t…"
  },
  {
    "objectID": "slides/lecture1.html#fetching-data---covidcast-main-endpoint",
    "href": "slides/lecture1.html#fetching-data---covidcast-main-endpoint",
    "title": "EpiData Workshop 2025",
    "section": "Fetching data - COVIDcast main endpoint",
    "text": "Fetching data - COVIDcast main endpoint\n\njhu_us_cases &lt;- pub_covidcast(\n  source = \"jhu-csse\",                        # this endpoint contains many different sources\n  signals = \"confirmed_7dav_incidence_prop\",  # other signals: deaths, cumulative, etc.\n  geo_type = \"nation\",                        # the geographic resolution (nation, state, hrr, msa, etc.)\n  time_type = \"day\",                          # or week or year\n  geo_values = \"us\",                          # optional\n  time_values = epirange(20210101, 20210401), # optional\n  ...                                         # additional arguments\n)\n\n\n\n# A tibble: 3 × 8\n  geo_value signal             source geo_type time_value issue        lag value\n  &lt;chr&gt;     &lt;chr&gt;              &lt;chr&gt;  &lt;fct&gt;    &lt;date&gt;     &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 us        confirmed_7dav_in… jhu-c… nation   2021-01-01 2023-03-10   798  61.9\n2 us        confirmed_7dav_in… jhu-c… nation   2021-01-02 2023-03-10   797  64.2\n3 us        confirmed_7dav_in… jhu-c… nation   2021-01-03 2023-03-10   796  67.1\n\n\nvalue is the requested signal\nThere are some other columns in the usual output that I’ve hidden"
  },
  {
    "objectID": "slides/lecture1.html#get-everything-for-a-source-signal",
    "href": "slides/lecture1.html#get-everything-for-a-source-signal",
    "title": "EpiData Workshop 2025",
    "section": "Get everything for a source + signal",
    "text": "Get everything for a source + signal\n\njhu_us_cases &lt;- pub_covidcast(\n  source = \"jhu-csse\",                  # this endpoint contains many different sources\n  signals = \"confirmed_incidence_num\",  # raw cases during the entire pandemic reporting until ~ April 2024\n  geo_type = \"county\",                  # the geographic resolution (nation, state, hrr, msa, etc.)\n  time_type = \"day\",                    # lowest resolution\n  geo_values = \"*\",                     # (default) \n  time_values = \"*\",                    # (default) \n  ...                                   # additional arguments\n)\n\n\n\nThis query takes a few minutes to run, so I don’t recommend it.\nBut there is support for automatic caching,\nand using \"*\" speeds things up relative to specifying many specific ranges.\n\n\nThe result has about 3.75M rows and occupies 400Mb."
  },
  {
    "objectID": "slides/lecture1.html#versioned-data-in-epidatr",
    "href": "slides/lecture1.html#versioned-data-in-epidatr",
    "title": "EpiData Workshop 2025",
    "section": "Versioned data in {epidatr}",
    "text": "Versioned data in {epidatr}\n\nTwo important, mutually exclusive parameters\n\nissues = c(mdy1, mdy2, ..., )\n\nfetches the data that the source made available on the requested dates\nDatabase stores only the diffs, so that’s typically what you get\nEven if the source republishes the entire history every time they make an update\n\nas_of = mdy\n\nfetches the all available data as it would have looked on mdy\nThink of it as winding back the clock to the date mdy\nAPI only accepts a single date here"
  },
  {
    "objectID": "slides/lecture1.html#example-issues-query",
    "href": "slides/lecture1.html#example-issues-query",
    "title": "EpiData Workshop 2025",
    "section": "Example issues query",
    "text": "Example issues query\n\nI wanted to display a major reporting error.\n\n\nversions &lt;- as.Date(c(\"2021-02-15\", \"2021-02-20\", \"2021-02-25\", \"2021-03-01\", \"2023-01-01\")) \npub_covidcast(\n  \"jhu-csse\", \"deaths_7dav_incidence_num\", \n  geo_type = \"state\", \n  geo_values = \"oh\",\n  time_type = \"day\",\n  time_values = epirange(20210101,20210301),\n  issues = versions\n) |&gt;\n  select(geo_value, time_value, version = issue, deaths = value)\n\n# A tibble: 4 × 4\n  geo_value time_value version    deaths\n  &lt;chr&gt;     &lt;date&gt;     &lt;date&gt;      &lt;dbl&gt;\n1 oh        2021-02-14 2021-02-15  670. \n2 oh        2021-02-19 2021-02-20   43.1\n3 oh        2021-02-24 2021-02-25   42.3\n4 oh        2021-02-28 2021-03-01   68.7\n\n\n\n\nNot what I wanted.\nGot only the diff on each issue.\nI wanted to view the whole history on each of those dates."
  },
  {
    "objectID": "slides/lecture1.html#correct-as_of-query",
    "href": "slides/lecture1.html#correct-as_of-query",
    "title": "EpiData Workshop 2025",
    "section": "Correct as_of query",
    "text": "Correct as_of query\n\nres &lt;- map(versions, # same set as before\n           .f = \\(v) { \n             pub_covidcast(\n               \"jhu-csse\", \"deaths_7dav_incidence_num\", \n               geo_type = \"state\", \n               geo_values = \"oh\",\n               time_type = \"day\",\n               time_values = epirange(20210101,20210301),\n               as_of = v \n             ) |&gt;\n               select(geo_value, time_value, deaths = value) |&gt;\n               mutate(version = v)\n           }) |&gt;\n  list_rbind()\nres |&gt; head(7)\n\n# A tibble: 7 × 4\n  geo_value time_value deaths version   \n  &lt;chr&gt;     &lt;date&gt;      &lt;dbl&gt; &lt;date&gt;    \n1 oh        2021-01-01   72.3 2021-02-15\n2 oh        2021-01-02   77.3 2021-02-15\n3 oh        2021-01-03   81   2021-02-15\n4 oh        2021-01-04   81.7 2021-02-15\n5 oh        2021-01-05   75   2021-02-15\n6 oh        2021-01-06   73.3 2021-02-15\n7 oh        2021-01-07   71.4 2021-02-15\n\n\n\n\nGot the data as it would have appeared for each of the 4 dates.\nBut as_of can only accept a scalar, not vector of dates.\nHad to “loop” over them.\nWe’ll see a more efficient way to do this later this morning."
  },
  {
    "objectID": "slides/lecture1.html#now-i-can-show-you-why-i-wanted-that-query",
    "href": "slides/lecture1.html#now-i-can-show-you-why-i-wanted-that-query",
    "title": "EpiData Workshop 2025",
    "section": "Now I can show you why I wanted that query",
    "text": "Now I can show you why I wanted that query"
  },
  {
    "objectID": "slides/lecture1.html#versioning-in-nowcasting-and-forecasting",
    "href": "slides/lecture1.html#versioning-in-nowcasting-and-forecasting",
    "title": "EpiData Workshop 2025",
    "section": "Versioning in nowcasting and forecasting",
    "text": "Versioning in nowcasting and forecasting\n\nRevision patterns can be used to inform understanding of current situation\nOften, predicting “today” is more about predicting the revisions than the process\nForecasting often requires adjustments for revision/reporting patterns\nBacktesting requires using data that would have been available at the time, not current data\nOnly looking at the most recent data is a huge blunder"
  },
  {
    "objectID": "slides/lecture1.html#wrapup-and-worksheet-discussion",
    "href": "slides/lecture1.html#wrapup-and-worksheet-discussion",
    "title": "EpiData Workshop 2025",
    "section": "Wrapup and worksheet discussion",
    "text": "Wrapup and worksheet discussion\n\nVersioned Data and Latency\n\nas_of: One version; the specific date when the data was last updated\nissues: Multiple versions; with different as_of dates\n\nEpidata API: delivers up-to-date, granular epidemiological data + historical versions.\n{epidatr}: Client package for R\nVersioning and panel structure are key first steps for analysis"
  },
  {
    "objectID": "slides/lecture3.html#outline",
    "href": "slides/lecture3.html#outline",
    "title": "EpiData Workshop 2025",
    "section": "Outline",
    "text": "Outline\n\nCompartmental Models\nOperationalizing Compartmental Models\nWhat is \\(R_t\\)?\nEstimating \\(R_t\\)\nResults and features of {rtestim}"
  },
  {
    "objectID": "slides/lecture3.html#mathematical-modelling-of-disease-epidemics-is-very-old",
    "href": "slides/lecture3.html#mathematical-modelling-of-disease-epidemics-is-very-old",
    "title": "EpiData Workshop 2025",
    "section": "Mathematical modelling of disease / epidemics is very old",
    "text": "Mathematical modelling of disease / epidemics is very old\n\nDaniel Bernoulli (1760) - studies inoculation against smallpox\nJohn Snow (1855) - cholera epidemic in London tied to a water pump\nRonald Ross (1902) - Nobel Prize in Medicine for work on malaria\nKermack and McKendrick (1927-1933) - basic epidemic (mathematical) model\n\n\n\n\nSource: Shiode, et al., “The mortality rates and the space-time patterns of John Snow’s cholera epidemic map,” (2015)"
  },
  {
    "objectID": "slides/lecture3.html#sir-type-compartmental-models---stochastic-version",
    "href": "slides/lecture3.html#sir-type-compartmental-models---stochastic-version",
    "title": "EpiData Workshop 2025",
    "section": "SIR-type (compartmental) models - Stochastic Version",
    "text": "SIR-type (compartmental) models - Stochastic Version\n\n\nSuppose each of N people in a bucket at time t:\nSusceptible(t) : not sick, but could get sick\nInfected(t) : sick, can make others sick\nRemoved(t) : recovered or dead; not sick, can’t get sick\n\n\n\nDuring period \\(h\\), each \\(S\\) meets \\(kh\\) people.\nAssume \\(P( S \\textrm{ meets } I \\textrm{ and becomes } I ) = c\\).\nThen \\(P( S(t) \\rightarrow I(t+h) ) = 1 - (1 - c I(t)  / N )^{hk} \\approx kchI(t) / N\\).\nTherefore, \\(I(t+h) | S(t),\\ I(t) \\sim \\textrm{Binom}(S(t),\\ kchI(t) / N)\\).\nAssume \\(P( I(t) \\rightarrow R(t+h)) = \\gamma h,\\ \\forall t\\).\nThen \\(R(t+h) | I_t \\sim \\textrm{Binom}(I(t),\\ \\gamma h)\\)."
  },
  {
    "objectID": "slides/lecture3.html#sir-type-compartmental-models---stochastic-version-1",
    "href": "slides/lecture3.html#sir-type-compartmental-models---stochastic-version-1",
    "title": "EpiData Workshop 2025",
    "section": "SIR-type (compartmental) models - Stochastic Version",
    "text": "SIR-type (compartmental) models - Stochastic Version\n\n\n\\[\\begin{aligned}\nC(t+h) & =  \\mathrm{Binom}\\left(S(t),\\ \\frac{\\beta}{N} h I(t)\\right)\\\\\nD(t+h) & =  \\mathrm{Binom}\\left(I(t),\\ \\gamma h\\right)\\\\\nS(t+h) & =  S(t) - C(t+h)\\\\\nI(t+h) & =  I(t) + C(t+h) - D(t+h)\\\\\nR(t+h) & =  R(t) + D(t+h)\n\\end{aligned}\\]\n\n\nIn the deterministic limit, \\(h\\rightarrow 0\\)\n\\[\\begin{aligned}\n\\frac{dS}{dt} & =  -\\frac{\\beta}{N} S(t)I(t)\\\\\n\\frac{dI}{dt} & =  \\frac{\\beta}{N} I(t)S(t) - \\gamma I(t)\\\\\n\\frac{dR}{dt} & =  \\gamma I(t)\n\\end{aligned}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nTHE SIR model is often ambiguous between these.\nTypically, people mean the deterministic, continuous time version."
  },
  {
    "objectID": "slides/lecture3.html#data-issues",
    "href": "slides/lecture3.html#data-issues",
    "title": "EpiData Workshop 2025",
    "section": "Data issues",
    "text": "Data issues\n\nIdeally we’d observe \\(S(t)\\), \\(I(t)\\), \\(R(t)\\) at all times \\(t\\)\nEasier to observe new infections, \\(I(t+h) - I(t)\\)\nRemovals by death are easier to observe than removals by recovery,\nso we mostly see \\((R(t+h) - R(t)) \\times \\textrm{(death rate)}\\)\nThe interval between measurements, say \\(\\Delta\\), is often \\(\\gg h\\)\nMeasuring \\(I(t)\\) and \\(R(t)\\) (or their rates of change) is hard\n\ntesting/reporting is sporadic and error prone\nNeed to model test error (false positives, false negatives) and who gets tested\nNeed to model lag between testing and reporting\n\nParameters (especially, \\(\\beta\\)) change during the epidemic\n\nChanging behavior, changing policy, environmental factors, vaccines, variants, …"
  },
  {
    "objectID": "slides/lecture3.html#connecting-to-data",
    "href": "slides/lecture3.html#connecting-to-data",
    "title": "EpiData Workshop 2025",
    "section": "Connecting to Data",
    "text": "Connecting to Data\n\nLikelihood calculations are straightforward if we can measure \\(I_t\\), \\(R_t\\) at all times \\(0, h, 2h, \\dots, T\\)\nOr \\(I_0\\), \\(R_0\\) and all the increments \\(I_{t+h} - I_t\\), \\(R_{t+h} - R_t\\)\nStill have to optimize numerically\nLikelihood calculations already become difficult if the time between observations \\(\\Delta \\gg h\\)\n\nGenerally, \\(\\Delta \\approx\\) 1 day\nIn principle, this just defines another Markov process, with a longer interval \\(\\Delta\\) between steps, but to get the likelihood of a \\(\\Delta\\) step we have to sum over all possible paths of \\(h\\) steps adding up to it\n\nOther complications if we don’t observe all the compartments, and/or have a lot of noise in our observations\n\nWe don’t and we do."
  },
  {
    "objectID": "slides/lecture3.html#connecting-to-data-1",
    "href": "slides/lecture3.html#connecting-to-data-1",
    "title": "EpiData Workshop 2025",
    "section": "Connecting to Data",
    "text": "Connecting to Data\n\n\n\nMore tractable to avoid likelihood (Conditional least squares, simulation-based inference)\nIntrinsic issue: Initially, everything looks exponential\n\nHard to discriminate between distinct models\nIf SIR is true, easier to estimate \\(\\beta - \\gamma\\) than \\((\\beta, \\gamma)\\) or \\(\\beta/\\gamma\\)\n\nCan sometimes calibrate or fix the parameters based on other sources\n\nE.g., \\(1/\\gamma =\\) average time someone is infectious in clinical studies\n\n\n\n\n\n\n\nI have been thinking about how different people interpret data differently. And made this xkcd style graphic to illustrate this. pic.twitter.com/a8LvlmZxT7\n\n— Jens von Bergmann (@vb_jens) March 17, 2021"
  },
  {
    "objectID": "slides/lecture3.html#these-models-can-fit-well-in-sample",
    "href": "slides/lecture3.html#these-models-can-fit-well-in-sample",
    "title": "EpiData Workshop 2025",
    "section": "These models can fit well in-sample",
    "text": "These models can fit well in-sample\n\nTrack observed cases closely (they should)\nCan provide nuanced policy advice on some topics\nMany questions depend on modulating \\(\\beta\\)\n\nWhat happens if we lock down?\nWhat happens if we mask?\nWhat happens if we have school online?\nVaccine passport?\n\nVaccination modeling is easier, directly removes susceptibles\n\n\nWhat about out-of-sample?"
  },
  {
    "objectID": "slides/lecture3.html#what-does-this-look-like",
    "href": "slides/lecture3.html#what-does-this-look-like",
    "title": "EpiData Workshop 2025",
    "section": "What does this “look like”?",
    "text": "What does this “look like”?\n\nsim_SIR &lt;- function(TT, N = 1000, beta = .1, gamma = .01) {\n  \n  S &lt;- double(TT)\n  I &lt;- double(TT)\n  R &lt;- double(TT)\n  S[1] &lt;- N - 1\n  I[1] &lt;- 1\n  \n  for (tt in 2:TT) {\n    contagions &lt;- rbinom(1, size = S[tt - 1], prob = beta * I[tt - 1] / N)\n    removals &lt;- rbinom(1, size = I[tt - 1], prob = gamma)\n    S[tt] &lt;- S[tt - 1] - contagions\n    I[tt] &lt;- I[tt - 1] + contagions - removals\n    R[tt] &lt;- R[tt - 1] + removals\n  }\n  tibble(S = S, I = I, R = R, time = seq(TT))\n}"
  },
  {
    "objectID": "slides/lecture3.html#what-does-this-look-like-1",
    "href": "slides/lecture3.html#what-does-this-look-like-1",
    "title": "EpiData Workshop 2025",
    "section": "What does this “look like”?",
    "text": "What does this “look like”?"
  },
  {
    "objectID": "slides/lecture3.html#so-far-just-simulations-how-do-you-fit-one",
    "href": "slides/lecture3.html#so-far-just-simulations-how-do-you-fit-one",
    "title": "EpiData Workshop 2025",
    "section": "So far, just simulations, how do you fit one?",
    "text": "So far, just simulations, how do you fit one?\n\\[\n\\begin{aligned}\nx_{t+1} &= \\textrm{OdeSolve}(x_t) + \\epsilon_t\\\\\ny_{t+1} &= \\textrm{NegBinom}(\\textrm{mean} = g(x_t),\\ \\kappa)\n\\end{aligned}\n\\]\n\n\\(x_t\\) is all the compartments\n\\(y_t\\) are some observations (cases and/or hospitalizations and/or deaths)\nPut priors on all the parameters (they are criminally underidentified)\n\n\nTurn Bayesian Crank in Stan or similar until you’re done."
  },
  {
    "objectID": "slides/lecture3.html#covidseir-model",
    "href": "slides/lecture3.html#covidseir-model",
    "title": "EpiData Workshop 2025",
    "section": "{covidseir} model",
    "text": "{covidseir} model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR package: https://seananderson.github.io/covidseir/index.html\nPaper link: https://doi.org/10.1371/journal.pcbi.1008274"
  },
  {
    "objectID": "slides/lecture3.html#fit-it-to-bc-data-and-produce-a-forecast",
    "href": "slides/lecture3.html#fit-it-to-bc-data-and-produce-a-forecast",
    "title": "EpiData Workshop 2025",
    "section": "Fit it to BC data and produce a forecast",
    "text": "Fit it to BC data and produce a forecast\n\nsamp_frac &lt;- c(rep(0.14, 13), rep(0.21, 38), rep(0.37, nrow(early_bc) - 51))\nf_seg &lt;- with(early_bc, case_when(time_value == \"2020-03-01\" ~ 0, time_value &gt;= \"2020-06-01\" ~ 3,\n  time_value &gt;= \"2020-05-01\" ~ 2, time_value &gt; \"2020-03-01\" ~ 1))\nfit &lt;- covidseir::fit_seir(daily_cases = early_bc$cases,\n                           f_seg = f_seg, # change points in transmission\n                           samp_frac_fixed = samp_frac,  # fraction of infections that are tested\n                           iter = 500, # number of posterior samples\n                           fit_type = \"optimizing\") # for speed only"
  },
  {
    "objectID": "slides/lecture3.html#using-this-or-similar-for-forecasting",
    "href": "slides/lecture3.html#using-this-or-similar-for-forecasting",
    "title": "EpiData Workshop 2025",
    "section": "Using this or similar for forecasting",
    "text": "Using this or similar for forecasting\nNeeded to make lots of assumptions about future epi parameters\n\nFuture transmission rate\nFuture case ascertainment rate\nNo new variants, or vaccinations, or influx of population\nPeople don’t lose immunity\nEtc., etc., etc.\n\n\nMore on these as forecasters a bit later.\nBetter described as scenario models."
  },
  {
    "objectID": "slides/lecture3.html#r_0-basic-reproduction-number",
    "href": "slides/lecture3.html#r_0-basic-reproduction-number",
    "title": "EpiData Workshop 2025",
    "section": "\\(R_0\\) basic reproduction number",
    "text": "\\(R_0\\) basic reproduction number\nDates at least to Alfred Lotka (1920s) and others (Feller, Blackwell, etc.)\n\n\nThe expected number of secondary infections due to a primary infection\n\n\n\n\n\n\\(R_0 &lt; 1\\) ⟹ the epidemic will die out\n\n\n\n\\(R_0 &gt; 1\\) ⟹ the epidemic will grow until everyone is infected\n\n\n\n\n\n\n\n\n\n\n\n\nSource: Katelyn Jetelina, “YLE Newsletter,” 21 April 2025.\n\n\n\n\n\n\n\nSource: Public Health Ontario, 21 April 2025."
  },
  {
    "objectID": "slides/lecture3.html#r_0-is-entirely-retrospective",
    "href": "slides/lecture3.html#r_0-is-entirely-retrospective",
    "title": "EpiData Workshop 2025",
    "section": "\\(R_0\\) is entirely retrospective",
    "text": "\\(R_0\\) is entirely retrospective\n\nIt’s a property of the pathogen in a fully susceptible (infinite) population\nEach outbreak is like a new sample\nTo estimate something like this from data, the “bonehead” way is to\n\nWait until the epidemic is over (no more infections circulating)\nContact trace the primary infection responsible for each secondary infection\nTake a sample average of the number caused by each primary\nPossibly repeat over many outbreaks\n\n\n\n\n\n\nSource: Guerra, et al., “The basic reproduction number (R0) of measles,” (2019).\n\n\n\n\nOf course no one actually does that\n\nLots of work on how to estimate \\(R_0\\)"
  },
  {
    "objectID": "slides/lecture3.html#effective-reproduction-number",
    "href": "slides/lecture3.html#effective-reproduction-number",
    "title": "EpiData Workshop 2025",
    "section": "Effective reproduction number",
    "text": "Effective reproduction number\nSuppose \\(s\\)% of the population is susceptible\nThen, “the” effective reproduction number \\(R=sR_0\\)\nAllows you to reason about things like\n\n\nThe level of vaccine coverage necessary to prevent an outbreak from growing uncontrollably.\n\n\n\nSo, for measles, if \\(R_0\\approx 15\\), the disease will die out if immunity is\n\\[\nsR_0 \\leq 1 \\Longrightarrow 1-s \\leq 1-1/R_0 \\approx 93\\%\n\\]"
  },
  {
    "objectID": "slides/lecture3.html#rt-instantaneous-reproduction-number",
    "href": "slides/lecture3.html#rt-instantaneous-reproduction-number",
    "title": "EpiData Workshop 2025",
    "section": "\\(R(t)\\) — instantaneous reproduction number",
    "text": "\\(R(t)\\) — instantaneous reproduction number\n\nThe effective reproduction number in the middle of an outbreak\nSome of the population is immune, others are infected, others susceptible\n\n\nThe expected number of secondary infections at time \\(t\\) caused by an earlier primary infection\n\n\n\\(f(a) \\geq 0,\\ \\forall a\\) — the rate at which an infection of age \\(a\\) produces new infections\n\\[\n\\begin{aligned}\nR_0 &= \\int_{0}^\\infty f(a)\\mathsf{d}a, \\\\\ng(a) &= \\frac{f(a)} {\\int_{0}^\\infty f(a)\\mathsf{d}a} = f(a) / R_0.\n\\end{aligned}\n\\]\n\n\nCan allow \\(g(t, a)\\), hold this fixed for now."
  },
  {
    "objectID": "slides/lecture3.html#the-generation-interval-distribution-ga",
    "href": "slides/lecture3.html#the-generation-interval-distribution-ga",
    "title": "EpiData Workshop 2025",
    "section": "The generation interval distribution \\(g(a)\\)",
    "text": "The generation interval distribution \\(g(a)\\)\n\n\n\n\n\nSource: US CDC Center for Forecasting Analytics, “Behind the Model.”"
  },
  {
    "objectID": "slides/lecture3.html#rt-and-r_t-renewal-equation",
    "href": "slides/lecture3.html#rt-and-r_t-renewal-equation",
    "title": "EpiData Workshop 2025",
    "section": "\\(R(t)\\) and \\(R_t\\) — renewal equation",
    "text": "\\(R(t)\\) and \\(R_t\\) — renewal equation\n\\(R(t)\\) is defined implicitly through the renewal equation\n\\[\nx(t) = R(t)\\int_0^\\infty x(t-a)g(a)\\mathsf{d}a,\n\\]\nwhere \\(x(t)\\) are infections at time \\(t\\).\n\n\nIn discrete time,\n\\[\nx_{t+1} = R_t\\sum_{a=0}^\\infty x_{t-a}\\widetilde{g}_a = R_t (x * \\widetilde{g}).\n\\]\n\n\n\nAnd stochasticly,\n\\[\n\\mathbb{E}\\big[x_{t+1}\\ |\\ x_1,\\ldots,x_{t}\\big] = R_t\\sum_{a=0}^\\infty x_{t-a}\\widetilde{g}_a = R_t (x * \\widetilde{g}).\n\\]\n\nMost estimators start here: \\[\n\\mathbb{E}\\big[x_{t+1}\\ |\\ x_1,\\ldots,x_{t}\\big] = R_t\\sum_{a=0}^\\infty x_{t-a}\\widetilde{g}_a.\n\\]\n\nAssume \\(\\widetilde{g}\\) is known\nModel \\(x_t\\ |\\ x_1,\\ldots,x_{t-1}\\) as Poisson or Negative Binomial\nTurn some inferential crank"
  },
  {
    "objectID": "slides/lecture3.html#r_t-for-covid-19-in-the-us",
    "href": "slides/lecture3.html#r_t-for-covid-19-in-the-us",
    "title": "EpiData Workshop 2025",
    "section": "\\(R_t\\) for COVID-19 in the US",
    "text": "\\(R_t\\) for COVID-19 in the US\n\n\nSource: US CDC Center for Forecasting Analytics"
  },
  {
    "objectID": "slides/lecture3.html#r_t-in-compartmental-models",
    "href": "slides/lecture3.html#r_t-in-compartmental-models",
    "title": "EpiData Workshop 2025",
    "section": "\\(R_t\\) in compartmental models",
    "text": "\\(R_t\\) in compartmental models\nThere is an equivalence between a compartmental model and the renewal equation.\n\\[\n\\begin{aligned}\nR_0 &= \\beta / \\gamma\\\\\nx_{t+1} &= \\beta S_{t} \\sum_{k = 0}^t \\big[(1-\\gamma)^{k}\\big] x_{t-k}\n= R_0 S_{t} \\sum_{k = 0}^t \\big[\\gamma(1-\\gamma)^{k}\\big] x_{t-k} = R_{t}\\sum_{k = 0}^t g(k)x_{t-k}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/lecture3.html#data-issues-1",
    "href": "slides/lecture3.html#data-issues-1",
    "title": "EpiData Workshop 2025",
    "section": "Data issues",
    "text": "Data issues\n\\(x_t\\) is Infections, but we don’t ever see those\n\n\n\n\nSource: US CDC Center for Forecasting Analytics, “Behind the Model.”\n\n\n\n\n\nReplace infections with cases\nReplace generation interval with serial interval\nAssume we have the serial interval"
  },
  {
    "objectID": "slides/lecture3.html#serial-interval-distribution",
    "href": "slides/lecture3.html#serial-interval-distribution",
    "title": "EpiData Workshop 2025",
    "section": "Serial interval distribution",
    "text": "Serial interval distribution"
  },
  {
    "objectID": "slides/lecture3.html#standard-model-for-r_t",
    "href": "slides/lecture3.html#standard-model-for-r_t",
    "title": "EpiData Workshop 2025",
    "section": "Standard model for \\(R_t\\)",
    "text": "Standard model for \\(R_t\\)\n\\[\n\\begin{aligned}\n\\eta_t &= \\sum_{a=0}^\\infty y_{t-a}p_a,\\\\ \\\\\ny_t\\ |\\ y_1,\\ldots,y_{t-1} &\\sim \\textrm{Poisson}(R_t\\eta_t).\n\\end{aligned}\n\\]\n\nUsing \\(y\\) instead of \\(x\\) to be cases or hospitalizations or deaths, incidence\nUsing \\(p\\) for serial interval distribution (discretized)\nThe MLE for \\(R_t\\) is just \\(y_t / \\eta_t\\).\nThis has really high variance, but unbiased.\nSo everybody smooths it."
  },
  {
    "objectID": "slides/lecture3.html#the-state-of-the-art",
    "href": "slides/lecture3.html#the-state-of-the-art",
    "title": "EpiData Workshop 2025",
    "section": "The state of the art",
    "text": "The state of the art\n\n\n\n{EpiEstim} (Cori, et al., 2013)\n\n\n\n\nGamma prior on \\(R_t\\), but use a trailing window\nSuper fast computationally\nSmoothness is ad hoc\n\n\n\n\n\n\n{EpiFilter} (Parag, 2020)\n\n\n\n\nState space model\nOne step smoothness: \\(R_{s+1} \\sim \\textrm{Gaussian}(R_s,\\ \\alpha R_s)\\)\nUses a discretized particle filter-type algorithm\n\n\n\n\n\n\n{EpiLPS} (Gressani, et al., 2022)\n\n\n\n\nNegative Binomial likelihood\nSmoothness via \\(\\log(R_t\\eta_t) = \\mathbf{B}_{t,:}\\beta\\)\n\\(\\mathbf{B}\\) is cubic B-spline basis, weighted Ridge penalty on \\(\\beta\\)\nMore priors, use Metropolis Adjusted Langevin Algorithm\n\n\n\n\n\n{EpiNow2} (CDC + CFA, Abbott, et al., 2023ish)\n\n\nNegative Binomial likelihood\nSmoothness via a GP prior\nAccommodates the sequence of delays from infection \\(\\longrightarrow\\) ??\nAdjusts for real-time issues like partial reporting\nBig Bayesian MCMC in Stan. Very slow."
  },
  {
    "objectID": "slides/lecture3.html#our-model",
    "href": "slides/lecture3.html#our-model",
    "title": "EpiData Workshop 2025",
    "section": "Our model",
    "text": "Our model\nLet \\(\\theta_t := \\log(R_t)\\).\nUse Poisson likelihood.\n\\[\n\\begin{aligned}\n\\widehat{R} &= \\exp(\\widehat{\\theta}) &\\widehat{\\theta} &= \\mathop{\\mathrm{argmin}}_\\theta\\; \\eta^{\\mathsf{T}}\\exp(\\theta) -\n\\mathbf{y}^{\\mathsf{T}}\\theta + \\lambda\\Vert D^{(k+1)}\\theta\\Vert_1\n\\end{aligned}\n\\]\n\n\nConvex, has a global optimum\n\\(\\lambda\\) controls smoothness relative to data fidelity\n\\(\\ell_1\\) penalty produces adaptive piecewise polynomials of order \\(k+1\\)\nNear minimax optimal for functions with bounded total variation"
  },
  {
    "objectID": "slides/lecture3.html#local-adaptivity-ell_1-vs.-ell_2",
    "href": "slides/lecture3.html#local-adaptivity-ell_1-vs.-ell_2",
    "title": "EpiData Workshop 2025",
    "section": "Local adaptivity — \\(\\ell_1\\) vs. \\(\\ell_2\\)",
    "text": "Local adaptivity — \\(\\ell_1\\) vs. \\(\\ell_2\\)"
  },
  {
    "objectID": "slides/lecture3.html#polynomial-order-k0",
    "href": "slides/lecture3.html#polynomial-order-k0",
    "title": "EpiData Workshop 2025",
    "section": "Polynomial order, \\(k=0\\)",
    "text": "Polynomial order, \\(k=0\\)\n\n\n \\[\n\\begin{aligned}\nD^{(1)} &= \\begin{bmatrix}\n1 & -1 &  &  & & \\\\\n& 1 & -1 &  & & \\\\\n  &   &    & \\ddots && \\\\\n&   &   &  & 1 & -1\n\\end{bmatrix} \\\\ \\\\\n&\\in \\mathbb{R}^{(n-1)\\times n}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/lecture3.html#polynomial-order-k1",
    "href": "slides/lecture3.html#polynomial-order-k1",
    "title": "EpiData Workshop 2025",
    "section": "Polynomial order, \\(k=1\\)",
    "text": "Polynomial order, \\(k=1\\)\n\n\n \\[\n\\begin{aligned}\nD^{(2)} &= \\begin{bmatrix}\n1 & -2 & 1 &  & & \\\\\n& 1 & -2 & 1 & & \\\\\n  &   &    & \\ddots && \\\\\n&   &   & 1 & -2 & 1\n\\end{bmatrix} \\\\ \\\\\n&= D^{(1)}D^{(1)}\\\\ \\\\\n&\\in \\mathbb{R}^{(n-k-1)\\times n}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/lecture3.html#polynomial-order-k2",
    "href": "slides/lecture3.html#polynomial-order-k2",
    "title": "EpiData Workshop 2025",
    "section": "Polynomial order, \\(k=2\\)",
    "text": "Polynomial order, \\(k=2\\)\n\n\n \\[\n\\begin{aligned}\nD^{(3)} &= \\begin{bmatrix}\n-1 & 3 & -3 & 1  & & \\\\\n& -1 & 3 & -3 &1 & \\\\\n  &   &    & \\ddots && \\\\\n&   &  -1 & 3 & -3 & 1\n\\end{bmatrix} \\\\ \\\\\n&= D^{(1)}D^{(2)}\\\\ \\\\\n&\\in \\mathbb{R}^{(n-k-1)\\times n}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/lecture3.html#estimation-algorithm",
    "href": "slides/lecture3.html#estimation-algorithm",
    "title": "EpiData Workshop 2025",
    "section": "Estimation algorithm",
    "text": "Estimation algorithm\n\\[\n\\mathop{\\mathrm{minimize}}_\\theta\\; \\eta^{\\mathsf{T}}\\exp(\\theta) -\n\\mathbf{y}^{\\mathsf{T}}\\theta + \\lambda\\Vert D^{(k+1)}\\theta\\Vert_1\n\\]"
  },
  {
    "objectID": "slides/lecture3.html#estimation-algorithm-1",
    "href": "slides/lecture3.html#estimation-algorithm-1",
    "title": "EpiData Workshop 2025",
    "section": "Estimation algorithm",
    "text": "Estimation algorithm\n\\[\n\\mathop{\\mathrm{minimize}}_{\\theta,\\ {\\color{BurntOrange} \\alpha}}\\;\n\\eta^{\\mathsf{T}}\\exp(\\theta) -\n\\mathbf{y}^{\\mathsf{T}}\\theta +\n\\lambda\\Vert D^{(1)}{\\color{BurntOrange} \\alpha}\\Vert_1\\quad\n{\\color{BurntOrange} \\textrm{subject to}\\quad \\alpha = D^{(k)}\\theta}\n\\]"
  },
  {
    "objectID": "slides/lecture3.html#estimation-algorithm-2",
    "href": "slides/lecture3.html#estimation-algorithm-2",
    "title": "EpiData Workshop 2025",
    "section": "Estimation algorithm",
    "text": "Estimation algorithm\n\\[\n\\mathop{\\mathrm{minimize}}_{\\theta,\\ \\alpha}\\;\n\\eta^{\\mathsf{T}}\\exp(\\theta) -\n\\mathbf{y}^{\\mathsf{T}}\\theta +\n\\lambda\\Vert D^{(1)} \\alpha\\Vert_1\\quad\n\\textrm{subject to}\\quad \\alpha = D^{(k)}\\theta\n\\]\n\n\n\nAlternating direction method of multipliers (ADMM)\n\\[\n\\begin{aligned}\n\\theta &\\longleftarrow \\mathop{\\mathrm{argmin}}_\\theta\\ \\eta^{\\mathsf{T}}\\exp(\\theta) -\n\\mathbf{y}^{\\mathsf{T}}\\theta +\n  \\frac{\\rho}{2}\\Vert D^{(k)}\\theta - \\alpha + u \\Vert_2^2 \\\\\n\\alpha &\\longleftarrow \\mathop{\\mathrm{argmin}}_\\alpha\\ \\lambda\\Vert D^{(1)} \\alpha \\Vert_1 +\n  \\frac{\\rho}{2}\\Vert D^{(k)}\\theta - \\alpha + u \\Vert_2^2 \\\\\nu &\\longleftarrow u + D^{(k)}\\theta - \\alpha\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/lecture3.html#estimation-algorithm-3",
    "href": "slides/lecture3.html#estimation-algorithm-3",
    "title": "EpiData Workshop 2025",
    "section": "Estimation algorithm",
    "text": "Estimation algorithm\n\\[\n\\mathop{\\mathrm{minimize}}_{\\theta,\\ \\alpha}\\;\n\\eta^{\\mathsf{T}}\\exp(\\theta) -\n\\mathbf{y}^{\\mathsf{T}}\\theta +\n\\lambda\\Vert D^{(1)} \\alpha\\Vert_1\\quad\n\\textrm{subject to}\\quad \\alpha = D^{(k)}\\theta\n\\]\n\n\n\nAlternating direction method of multipliers (ADMM)\n\\[\n\\begin{aligned}\n\\theta &\\longleftarrow  {\\color{Cerulean}\\textrm{Proximal Newton / Fisher Scoring}} \\\\\n\\alpha &\\longleftarrow  {\\color{BurntOrange}\\textrm{Fused Lasso Signal Approximator}} \\\\\nu &\\longleftarrow u + D^{(k)}\\theta - \\alpha\n\\end{aligned}\n\\]\n\nSolve sequentially for \\(\\Vert (D^{\\dagger})^{\\mathsf{T}}(\\eta - y)\\Vert_\\infty = \\lambda_1 &gt; \\cdots &gt; \\lambda_M=\\epsilon \\lambda_1\\)."
  },
  {
    "objectID": "slides/lecture3.html#canadian-covid-19-cases",
    "href": "slides/lecture3.html#canadian-covid-19-cases",
    "title": "EpiData Workshop 2025",
    "section": "Canadian Covid-19 cases",
    "text": "Canadian Covid-19 cases"
  },
  {
    "objectID": "slides/lecture3.html#r_t-for-canadian-covid-19-cases",
    "href": "slides/lecture3.html#r_t-for-canadian-covid-19-cases",
    "title": "EpiData Workshop 2025",
    "section": "\\(R_t\\) for Canadian Covid-19 cases",
    "text": "\\(R_t\\) for Canadian Covid-19 cases"
  },
  {
    "objectID": "slides/lecture3.html#reconvolved-canadian-covid-19-cases",
    "href": "slides/lecture3.html#reconvolved-canadian-covid-19-cases",
    "title": "EpiData Workshop 2025",
    "section": "Reconvolved Canadian Covid-19 cases",
    "text": "Reconvolved Canadian Covid-19 cases"
  },
  {
    "objectID": "slides/lecture3.html#example-simulations-for-different-methods",
    "href": "slides/lecture3.html#example-simulations-for-different-methods",
    "title": "EpiData Workshop 2025",
    "section": "Example simulations for different methods",
    "text": "Example simulations for different methods"
  },
  {
    "objectID": "slides/lecture3.html#rtestim-software",
    "href": "slides/lecture3.html#rtestim-software",
    "title": "EpiData Workshop 2025",
    "section": "{rtestim} software",
    "text": "{rtestim} software\n\n\nGuts are in C++ for speed\nLots of the usual S3 methods\nApproximate “confidence” bands\n\\(\\widehat{R}\\) is a member of a function space\nArbitrary spacing of observations\nBuilt-in cross validation\nTime-varying delay distributions"
  },
  {
    "objectID": "slides/lecture3.html#rtestim-software-1",
    "href": "slides/lecture3.html#rtestim-software-1",
    "title": "EpiData Workshop 2025",
    "section": "{rtestim} software",
    "text": "{rtestim} software\n\n\n\nGuts are in C++ for speed\nLots of the usual S3 methods\nApproximate “confidence” bands\n\\(\\widehat{R}\\) is a member of a function space\nArbitrary spacing of observations\nBuilt-in cross validation\nTime-varying delay distributions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nApproximation + Delta method gives\n\\[\n\\textrm{Var}(\\widehat{R}) = \\left(\\textrm{diag}(\\widehat{y}) +\n\\lambda D^{\\mathsf{T}}D\\right)^{\\dagger} \\left(\\frac{1}{\\eta^2}\\right)\n\\]"
  },
  {
    "objectID": "slides/lecture3.html#rtestim-software-2",
    "href": "slides/lecture3.html#rtestim-software-2",
    "title": "EpiData Workshop 2025",
    "section": "{rtestim} software",
    "text": "{rtestim} software\n\n\n\nGuts are in C++ for speed\nLots of the usual S3 methods\nApproximate “confidence” bands\n\\(\\widehat{R}\\) is a member of a function space\nArbitrary spacing of observations\nBuilt-in cross validation\nTime-varying delay distributions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe solution is an element of the space of discrete splines of order \\(k\\) (Tibshirani, 2020)\n\nLets us interpolate (and extrapolate) to off-observation points\nLets us handle uneven spacing"
  },
  {
    "objectID": "slides/lecture3.html#rtestim-software-3",
    "href": "slides/lecture3.html#rtestim-software-3",
    "title": "EpiData Workshop 2025",
    "section": "{rtestim} software",
    "text": "{rtestim} software\n\n\n\nGuts are in C++ for speed\nLots of the usual S3 methods\nApproximate “confidence” bands\n\\(\\widehat{R}\\) is a member of a function space\nArbitrary spacing of observations\nBuilt-in cross validation\nTime-varying delay distributions"
  },
  {
    "objectID": "slides/lecture3.html#rtestim-software-4",
    "href": "slides/lecture3.html#rtestim-software-4",
    "title": "EpiData Workshop 2025",
    "section": "{rtestim} software",
    "text": "{rtestim} software"
  },
  {
    "objectID": "slides/lecture3.html#wrapup-and-practice",
    "href": "slides/lecture3.html#wrapup-and-practice",
    "title": "EpiData Workshop 2025",
    "section": "Wrapup and practice",
    "text": "Wrapup and practice\n\nBasic compartmental modelling\nDifficulties in estimating compartmental models\nStandard epidemic parameters, \\(R_0\\)\nDiscussion of \\(R_t\\) (model based vs nonparametric estimation)\nSome custom \\(R_t\\) software"
  }
]