{
  "hash": "6cc954436d9afae7808bc2090f64752b",
  "result": {
    "engine": "knitr",
    "markdown": "---\norg: \"CANSSI Prairies &mdash; Epi Forecasting Workshop 2025\"\ntitle: \"Compartmental Models, Renewal Equations, and $R_t$ Estimation\"\nsubtitle: \"Lecture 3\"\nshort-title: \"Epi models\"\nformat: revealjs\n---\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n\n## Outline\n\n1. Compartmental Models\n1. Operationalizing Compartmental Models\n1. What is $R_t$?\n1. Estimating $R_t$\n1. Results and features of `{rtestim}`\n\n# Compartmental models {.inverse}\n\n\n## Mathematical modelling of disease / epidemics is very old \n\n\\DeclareMathOperator*{\\argmin}{argmin}\n\\DeclareMathOperator*{\\minimize}{minimize}\n\n\n* [Daniel Bernoulli (1760)]{.tertiary} - studies inoculation against smallpox\n\n* [John Snow (1855)]{.tertiary} - cholera epidemic in London tied to a water pump\n\n* [Ronald Ross (1902)]{.tertiary} - Nobel Prize in Medicine for work on malaria\n\n* [Kermack and McKendrick (1927-1933)]{.tertiary} - basic epidemic (mathematical) model\n\n![Source: Shiode, et al., \"The mortality rates and the space-time patterns of John Snowâ€™s cholera epidemic map,\" (2015)](https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs12942-015-0011-y/MediaObjects/12942_2015_11_Fig1_HTML.gif?as=webp){height=400px fig-align=\"center\"}\n\n\n## SIR-type (compartmental) models - Stochastic Version {.nostretch}\n\n\n::: flex\n::: w-75\n\nSuppose each of N people in a bucket at time t:\n\n[Susceptible(t)]{.secondary} : not sick, but could get sick\n\n[Infected(t)]{.secondary} : sick, can make others sick\n\n[Removed(t)]{.secondary} : recovered or dead; not sick, can't get sick\n\n ---\n\n::: {.incremental}\n* During period $h$, each $S$ meets $kh$ people.\n* Assume $P( S \\textrm{ meets } I \\textrm{ and becomes } I ) = c$.\n* Then $P( S(t) \\rightarrow I(t+h) ) = 1 - (1 - c I(t)  / N )^{hk} \\approx kchI(t) / N$.\n* Therefore, $I(t+h) | S(t),\\ I(t) \\sim \\textrm{Binom}(S(t),\\ kchI(t) / N)$.\n* Assume $P( I(t) \\rightarrow R(t+h)) = \\gamma h,\\ \\forall t$.\n* Then $R(t+h) | I_t \\sim \\textrm{Binom}(I(t),\\ \\gamma h)$.\n:::\n\n:::\n\n::: w-25\n\n<br><br>\n\n![](gfx/sir.svg){fig-align=\"center\"}\n\n:::\n:::\n\n\n\n\n## SIR-type (compartmental) models - Stochastic Version\n\n::: flex\n::: w-60\n\n\n\\begin{aligned}\nC(t+h) & =  \\mathrm{Binom}\\left(S(t),\\ \\frac{\\beta}{N} h I(t)\\right)\\\\\nD(t+h) & =  \\mathrm{Binom}\\left(I(t),\\ \\gamma h\\right)\\\\\nS(t+h) & =  S(t) - C(t+h)\\\\\nI(t+h) & =  I(t) + C(t+h) - D(t+h)\\\\\nR(t+h) & =  R(t) + D(t+h)\n\\end{aligned}\n\n::: {.fragment}\n ---\n\nIn the deterministic limit, $h\\rightarrow 0$\n\n\\begin{aligned}\n\\frac{dS}{dt} & =  -\\frac{\\beta}{N} S(t)I(t)\\\\\n\\frac{dI}{dt} & =  \\frac{\\beta}{N} I(t)S(t) - \\gamma I(t)\\\\\n\\frac{dR}{dt} & =  \\gamma I(t)\n\\end{aligned}\n:::\n\n:::\n\n::: w-40\n\n<br><br>\n\n![](gfx/sir.svg){fig-align=\"center\"}\n\n:::\n:::\n\n::: {.fragment .box-text .absolute top=30%}\n\n[THE]{.secondary} SIR model is often ambiguous between these.\n\nTypically, people mean the deterministic, continuous time version.\n:::\n\n\n## Data issues \n\n- [Ideally]{.secondary} we'd observe $S(t)$, $I(t)$, $R(t)$ at all times $t$\n\n- Easier to observe new infections, $I(t+h) - I(t)$\n\n- Removals by death are easier to observe than removals by recovery,  \n  so we mostly see $(R(t+h) - R(t)) \\times \\textrm{(death rate)}$\n\n- The interval between measurements, say $\\Delta$, is often $\\gg h$\n\n- Measuring $I(t)$ and $R(t)$ (or their rates of change) is hard \n    + testing/reporting is sporadic and error prone\n    + Need to model test error (false positives, false negatives) _and_ who gets tested\n    + Need to model lag between testing and reporting\n    \n- Parameters (especially, $\\beta$) change during the epidemic\n    + Changing behavior, changing policy, environmental factors, vaccines, variants, ...\n\n\n## Connecting to Data\n\n\n- Likelihood calculations are straightforward if we can measure $I_t$, $R_t$ at all times $0, h, 2h, \\dots, T$\n\n- Or $I_0$, $R_0$ and all the increments $I_{t+h} - I_t$, $R_{t+h} - R_t$\n\n- Still have to optimize numerically\n\n- Likelihood calculations already become difficult if the time between \n  observations $\\Delta \\gg h$\n    + Generally, $\\Delta \\approx$ 1 day\n    + In principle, this just defines another Markov process, with a longer \n    interval $\\Delta$ between steps, but to get the likelihood of a $\\Delta$ \n    step we have to sum over all possible paths of $h$ steps adding up to it\n\n- Other complications if we don't observe all the compartments, and/or have a \n  lot of noise in our observations\n    + We don't and we do.\n\n\n\n\n## Connecting to Data\n\n::: flex\n::: w-65\n\n- More tractable to avoid likelihood (Conditional least squares, simulation-based inference)\n\n- Intrinsic issue: Initially, everything  looks exponential\n    + Hard to discriminate between distinct models\n    + If SIR is true, easier to estimate $\\beta - \\gamma$ than $(\\beta, \\gamma)$ or $\\beta/\\gamma$\n\n- Can sometimes [calibrate]{.secondary} or fix the parameters based on other sources\n    + E.g., $1/\\gamma =$ average time someone is infectious in clinical studies\n:::\n\n::: w-35\n\n<br>\n<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">I have been thinking about how different people interpret data differently. And made this xkcd style graphic to illustrate this. <a href=\"https://t.co/a8LvlmZxT7\">pic.twitter.com/a8LvlmZxT7</a></p>&mdash; Jens von Bergmann (@vb_jens) <a href=\"https://twitter.com/vb_jens/status/1372251931444350976?ref_src=twsrc%5Etfw\">March 17, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n\n:::\n\n\n:::\n\n\n## These models can fit well in-sample\n\n\n* Track observed cases closely (they should)\n\n* Can provide nuanced policy advice on some topics\n\n* Many questions depend on modulating $\\beta$\n    1. What happens if we lock down?\n    2. What happens if we mask?\n    3. What happens if we have school online?\n    4. Vaccine passport?\n    \n* Vaccination modeling is easier, directly removes susceptibles\n\n::: {.fragment}\n\n[What about out-of-sample?]{.secondary}\n\n:::\n\n::: {.fragment .absolute top=20% right=30%}\n\n`<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 512 512\" style=\"height:10em;width:10em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:orange;overflow:visible;position:relative;\"><path d=\"M256 512A256 256 0 1 0 256 0a256 256 0 1 0 0 512zm0-384c13.3 0 24 10.7 24 24V264c0 13.3-10.7 24-24 24s-24-10.7-24-24V152c0-13.3 10.7-24 24-24zM224 352a32 32 0 1 1 64 0 32 32 0 1 1 -64 0z\"/></svg>`{=html}\n\n:::\n\n# Operationalizing Compartmental Models {.inverse}\n\n## What does this \"look like\"?\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsim_SIR <- function(TT, N = 1000, beta = .1, gamma = .01) {\n  \n  S <- double(TT)\n  I <- double(TT)\n  R <- double(TT)\n  S[1] <- N - 1\n  I[1] <- 1\n  \n  for (tt in 2:TT) {\n    contagions <- rbinom(1, size = S[tt - 1], prob = beta * I[tt - 1] / N)\n    removals <- rbinom(1, size = I[tt - 1], prob = gamma)\n    S[tt] <- S[tt - 1] - contagions\n    I[tt] <- I[tt - 1] + contagions - removals\n    R[tt] <- R[tt - 1] + removals\n  }\n  tibble(S = S, I = I, R = R, time = seq(TT))\n}\n```\n:::\n\n\n\n\n## What does this \"look like\"?\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture3_files/figure-revealjs/sim-sir-plot-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## So far, just simulations, how do you fit one?\n\n$$\n\\begin{aligned}\nx_{t+1} &= \\textrm{OdeSolve}(x_t) + \\epsilon_t\\\\\ny_{t+1} &= \\textrm{NegBinom}(\\textrm{mean} = g(x_t),\\ \\kappa)\n\\end{aligned}\n$$\n\n* $x_t$ is all the compartments\n* $y_t$ are some observations (cases and/or hospitalizations and/or deaths)\n* Put priors on all the parameters (they are criminally underidentified)\n\n::: {.fragment}\nTurn Bayesian Crank in Stan or similar until you're done.\n:::\n\n## `{covidseir}` model\n\n::: {layout=\"[40,60]\" layout-valign=\"center\"}\n![](gfx/covidseir-ode.png)\n\n![](gfx/covidseir-dag.png)\n:::\n\n* `R` package: <https://seananderson.github.io/covidseir/index.html>\n* Paper link: <https://doi.org/10.1371/journal.pcbi.1008274>\n\n\n## Fit it to BC data and produce a forecast\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsamp_frac <- c(rep(0.14, 13), rep(0.21, 38), rep(0.37, nrow(early_bc) - 51))\nf_seg <- with(early_bc, case_when(time_value == \"2020-03-01\" ~ 0, time_value >= \"2020-06-01\" ~ 3,\n  time_value >= \"2020-05-01\" ~ 2, time_value > \"2020-03-01\" ~ 1))\nfit <- covidseir::fit_seir(daily_cases = early_bc$cases,\n                           f_seg = f_seg, # change points in transmission\n                           samp_frac_fixed = samp_frac,  # fraction of infections that are tested\n                           iter = 500, # number of posterior samples\n                           fit_type = \"optimizing\") # for speed only\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture3_files/figure-revealjs/covid-seir-plot-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Using this or similar for forecasting\n\nNeeded to make lots of assumptions about future epi parameters\n\n* Future transmission rate\n* Future case ascertainment rate\n* No new variants, or vaccinations, or influx of population\n* People don't lose immunity\n* Etc., etc., etc.\n\n. . .\n\nMore on these as [forecasters]{.secondary} a bit later.\n\nBetter described as [scenario models]{.tertiary}.\n\n# What is $R_t$? {.inverse}\n\n## $R_0$ basic reproduction number\n\nDates at least to [Alfred Lotka (1920s)]{.tertiary} and others (Feller, Blackwell, etc.)\n\n<br>\n\n> The expected number of secondary infections due to a primary infection\n\n\n\n::: flex\n::: w-40\n<br><br>\n\n* $R_0 < 1$ [&xrArr;]{.tertiary} the epidemic will die out\n\n<br>\n\n* $R_0 > 1$ [&xrArr;]{.tertiary} the epidemic will grow until everyone is infected\n:::\n\n::: {.w-60 style=\"text-align: center;\"}\n<canvas id=\"simulation\" width=\"800\" height=\"500\"></canvas>\n<script src=\"_code/infections.js\"></script>\n:::\n:::\n\n::: {.fragment .box-text .absolute top=50 left=150}\n\n![Source: Katelyn Jetelina, \"YLE Newsletter,\" 21 April 2025.](gfx/yle-measles.jpg){height=600}\n\n:::\n\n## $R_0$ is entirely retrospective\n\n* It's a property of the pathogen in a fully susceptible (infinite) population\n\n* Each outbreak is like a new sample\n\n\n* To estimate something like this from data, the \"bonehead\" way is to \n  1. Wait until the epidemic is over (no more infections circulating)\n  2. Contact trace the primary infection responsible for each secondary infection\n  3. Take a sample average of the number caused by each primary\n  4. Possibly repeat over many outbreaks\n  \n\n::: {.fragment .box-text .absolute top=50 left=100}\n\n![Source: Guerra, et al., \"The basic reproduction number (R0) of measles,\" (2019).](gfx/guerra-measles.jpg){height=500}\n\n:::\n\n  \n::: {.fragment .box-text .absolute top=300 left=300}\n\nOf course no one actually does that\n\n<br>\n\nLots of work on how to estimate $R_0$\n\n:::\n\n## Effective reproduction number\n\nSuppose $s$% of the population is susceptible \n\nThen, \"the\" effective reproduction number $R=sR_0$\n\nAllows you to reason about things like \n\n<br>\n\n> The level of vaccine coverage necessary to prevent an outbreak from growing\nuncontrollably.\n\n<br>\n\n. . .\n\nSo, for measles, if $R_0\\approx 15$, the disease will die out if immunity is\n\n\n$$\nsR_0 \\leq 1 \\Longrightarrow 1-s \\leq 1-1/R_0 \\approx 93\\%\n$$\n\n\n---\n\n<iframe data-src=https://epiengage-measles.tacc.utexas.edu height=850 width=1500></iframe>\n\n## $R(t)$ --- instantaneous reproduction number\n\n* The effective reproduction number in the middle of an outbreak\n\n* Some of the population is immune, others are infected, others susceptible\n\n> The expected number of secondary infections at time $t$ caused by an earlier primary\ninfection\n\n. . .\n\n$f(a) \\geq 0,\\ \\forall a$ --- the rate at which an infection of age $a$ produces new infections\n\n$$\n\\begin{aligned}\nR_0 &= \\int_{0}^\\infty f(a)\\mathsf{d}a, \\\\\ng(a) &= \\frac{f(a)} {\\int_{0}^\\infty f(a)\\mathsf{d}a} = f(a) / R_0.\n\\end{aligned}\n$$\n\n. . .\n\nCan allow $g(t, a)$, hold this fixed for now. \n\n## The generation interval distribution $g(a)$\n\n<figure>\n<!-- https://www.cdc.gov/cfa-behind-the-model/php/data-research/rt-estimates/index.html -->\n![Source: US CDC Center for Forecasting Analytics, \"Behind the Model.\"](gfx/infectiousness-over-time-dfe.jpeg)\n</figure>\n\n\n## $R(t)$ and $R_t$ --- renewal equation\n\n$R(t)$ is defined implicitly through the [renewal equation]{.secondary}\n\n$$\nx(t) = R(t)\\int_0^\\infty x(t-a)g(a)\\mathsf{d}a,\n$$\n\nwhere $x(t)$ are infections at time $t$.\n\n. . .\n\n<hr/>\n\nIn discrete time, \n\n$$\nx_{t+1} = R_t\\sum_{a=0}^\\infty x_{t-a}\\widetilde{g}_a = R_t (x * \\widetilde{g}).\n$$\n\n. . .\n\n<hr/>\n\nAnd stochasticly,\n\n$$\n\\mathbb{E}\\big[x_{t+1}\\ |\\ x_1,\\ldots,x_{t}\\big] = R_t\\sum_{a=0}^\\infty x_{t-a}\\widetilde{g}_a = R_t (x * \\widetilde{g}).\n$$\n\n\n::: {.fragment .box-text .absolute top=50}\nMost estimators start here:\n$$\n\\mathbb{E}\\big[x_{t+1}\\ |\\ x_1,\\ldots,x_{t}\\big] = R_t\\sum_{a=0}^\\infty x_{t-a}\\widetilde{g}_a.\n$$\n\n* Assume $\\widetilde{g}$ is known\n* Model $x_t\\ |\\ x_1,\\ldots,x_{t-1}$ as Poisson or Negative Binomial\n* Turn some inferential crank\n\n:::\n\n## $R_t$ for COVID-19 in the US\n\n<iframe data-src=\"https://www.cdc.gov/cfa-modeling-and-forecasting/rt-estimates/state-rt-timeseries/chart-covid.html#covid-United%20States\" height=700 width=1400></iframe>\n\n[Source: US CDC Center for Forecasting Analytics]{.grey style=\"font-size:0.7em;\"}\n\n## $R_t$ in compartmental models\n\nThere is an equivalence between a compartmental model and the renewal equation.\n\n$$\n\\begin{aligned}\nR_0 &= \\beta / \\gamma\\\\\nx_{t+1} &= \\beta S_{t} \\sum_{k = 0}^t \\big[(1-\\gamma)^{k}\\big] x_{t-k}\n= R_0 S_{t} \\sum_{k = 0}^t \\big[\\gamma(1-\\gamma)^{k}\\big] x_{t-k} = R_{t}\\sum_{k = 0}^t g(k)x_{t-k}\n\\end{aligned}\n$$\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture3_files/figure-revealjs/show-sir-Rt-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n# Estimating $R_t$ {.inverse}\n\n## Data issues\n\n$x_t$ is [Infections]{.secondary}, but we don't ever see those\n\n<figure>\n![Source: US CDC Center for Forecasting Analytics, \"Behind the Model.\"](https://www.cdc.gov/cfa-behind-the-model/media/images/2024/10/Fig-6_Sept2024_update.jpg)\n</figure>\n\n::: {.fragment .box-text .absolute top=150 left=150}\n\n* Replace [infections]{.secondary} with [cases]{.tertiary}\n* Replace [generation interval]{.secondary} with [serial interval]{.tertiary}\n* Assume we have the [serial interval]{.tertiary}\n\n:::\n\n## Serial interval distribution\n\n<br>\n\n![](gfx/Incubation_delay.svg)\n\n\n## Standard model for $R_t$\n\n$$\n\\begin{aligned}\n\\eta_t &= \\sum_{a=0}^\\infty y_{t-a}p_a,\\\\ \\\\\ny_t\\ |\\ y_1,\\ldots,y_{t-1} &\\sim \\textrm{Poisson}(R_t\\eta_t).\n\\end{aligned}\n$$\n\n* Using $y$ instead of $x$ to be cases or hospitalizations or deaths, [incidence]{.secondary}\n* Using $p$ for serial interval distribution (discretized)\n* The MLE for $R_t$ is just $y_t / \\eta_t$.\n* This has really high variance, but unbiased.\n* So everybody smooths it.\n\n## The state of the art\n\n::: flex\n::: w-40\n1. `{EpiEstim}` (Cori, et al., 2013) \n:::\n::: w-60\n- Gamma prior on $R_t$, but use a trailing window\n- Super fast computationally\n- Smoothness is ad hoc\n:::\n:::\n\n::: flex\n::: w-40\n2. `{EpiFilter}` (Parag, 2020)\n:::\n::: w-60\n- State space model\n- One step smoothness: $R_{s+1} \\sim \\textrm{Gaussian}(R_s,\\ \\alpha R_s)$\n- Uses a discretized particle filter-type algorithm\n:::\n:::\n\n::: flex\n::: w-40\n3. `{EpiLPS}` (Gressani, et al., 2022)\n:::\n::: w-60\n- Negative Binomial likelihood\n- Smoothness via $\\log(R_t\\eta_t) = \\mathbf{B}_{t,:}\\beta$\n- $\\mathbf{B}$ is cubic B-spline basis, weighted Ridge penalty on $\\beta$\n- More priors, use Metropolis Adjusted Langevin Algorithm\n:::\n:::\n\n::: {.fragment .absolute .box-text top=50}\n4. `{EpiNow2}` (CDC + CFA, Abbott, et al., 2023ish)\n\n* Negative Binomial likelihood\n* Smoothness via a GP prior\n* Accommodates the sequence of delays from infection $\\longrightarrow$ ??\n* Adjusts for real-time issues like partial reporting\n* Big Bayesian MCMC in Stan. Very slow.\n:::\n\n\n## Our model\n\nLet $\\theta_t := \\log(R_t)$. \n\nUse Poisson likelihood.\n\n$$\n\\begin{aligned}\n\\widehat{R} &= \\exp(\\widehat{\\theta}) &\\widehat{\\theta} &= \\argmin_\\theta\\; \\eta^{\\mathsf{T}}\\exp(\\theta) - \n\\mathbf{y}^{\\mathsf{T}}\\theta + \\lambda\\Vert D^{(k+1)}\\theta\\Vert_1\n\\end{aligned}\n$$\n\n. . .\n\n* Convex, has a global optimum\n* $\\lambda$ controls smoothness relative to data fidelity\n* $\\ell_1$ penalty produces adaptive piecewise polynomials of order $k+1$\n* Near minimax optimal for functions with bounded total variation\n\n\n## Local adaptivity --- $\\ell_1$ vs. $\\ell_2$\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture3_files/figure-revealjs/adaptivity-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Polynomial order, $k=0$\n\n::: flex\n::: w-40\n<br><br>\n$$\n\\begin{aligned}\nD^{(1)} &= \\begin{bmatrix} \n1 & -1 &  &  & & \\\\ \n & 1 & -1 &  & & \\\\\n  &   &    & \\ddots && \\\\ \n &   &   &  & 1 & -1 \n\\end{bmatrix} \\\\ \\\\\n&\\in \\mathbb{R}^{(n-1)\\times n}\n\\end{aligned}\n$$\n:::\n\n::: w-60\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture3_files/figure-revealjs/k0-1.svg){fig-align='center' width=800px height=800px}\n:::\n:::\n\n\n:::\n:::\n\n## Polynomial order, $k=1$\n\n::: flex\n::: w-40\n<br><br>\n$$\n\\begin{aligned}\nD^{(2)} &= \\begin{bmatrix} \n1 & -2 & 1 &  & & \\\\ \n & 1 & -2 & 1 & & \\\\\n  &   &    & \\ddots && \\\\ \n &   &   & 1 & -2 & 1 \n\\end{bmatrix} \\\\ \\\\\n&= D^{(1)}D^{(1)}\\\\ \\\\\n&\\in \\mathbb{R}^{(n-k-1)\\times n}\n\\end{aligned}\n$$\n:::\n\n::: w-60\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture3_files/figure-revealjs/k1-1.svg){fig-align='center' width=800px height=800px}\n:::\n:::\n\n\n:::\n:::\n\n## Polynomial order, $k=2$\n\n::: flex\n::: w-40\n<br><br>\n$$\n\\begin{aligned}\nD^{(3)} &= \\begin{bmatrix} \n-1 & 3 & -3 & 1  & & \\\\ \n & -1 & 3 & -3 &1 & \\\\\n  &   &    & \\ddots && \\\\ \n &   &  -1 & 3 & -3 & 1 \n\\end{bmatrix} \\\\ \\\\\n&= D^{(1)}D^{(2)}\\\\ \\\\\n&\\in \\mathbb{R}^{(n-k-1)\\times n}\n\\end{aligned}\n$$\n:::\n\n::: w-60\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture3_files/figure-revealjs/k2-1.svg){fig-align='center' width=800px height=800px}\n:::\n:::\n\n\n:::\n:::\n\n\n## Estimation algorithm\n\n$$\n\\minimize_\\theta\\; \\eta^{\\mathsf{T}}\\exp(\\theta) - \n\\mathbf{y}^{\\mathsf{T}}\\theta + \\lambda\\Vert D^{(k+1)}\\theta\\Vert_1\n$$\n\n## Estimation algorithm\n\n$$\n\\minimize_{\\theta,\\ {\\color{BurntOrange} \\alpha}}\\; \n\\eta^{\\mathsf{T}}\\exp(\\theta) - \n\\mathbf{y}^{\\mathsf{T}}\\theta + \n\\lambda\\Vert D^{(1)}{\\color{BurntOrange} \\alpha}\\Vert_1\\quad\n{\\color{BurntOrange} \\textrm{subject to}\\quad \\alpha = D^{(k)}\\theta}\n$$\n\n\n## Estimation algorithm\n\n$$\n\\minimize_{\\theta,\\ \\alpha}\\; \n\\eta^{\\mathsf{T}}\\exp(\\theta) - \n\\mathbf{y}^{\\mathsf{T}}\\theta + \n\\lambda\\Vert D^{(1)} \\alpha\\Vert_1\\quad\n\\textrm{subject to}\\quad \\alpha = D^{(k)}\\theta\n$$\n\n<br>\n<hr>\n<br>\n\nAlternating direction method of multipliers (ADMM)\n\n$$\n\\begin{aligned}\n\\theta &\\longleftarrow \\argmin_\\theta\\ \\eta^{\\mathsf{T}}\\exp(\\theta) - \n\\mathbf{y}^{\\mathsf{T}}\\theta + \n  \\frac{\\rho}{2}\\Vert D^{(k)}\\theta - \\alpha + u \\Vert_2^2 \\\\\n\\alpha &\\longleftarrow \\argmin_\\alpha\\ \\lambda\\Vert D^{(1)} \\alpha \\Vert_1 +\n  \\frac{\\rho}{2}\\Vert D^{(k)}\\theta - \\alpha + u \\Vert_2^2 \\\\\nu &\\longleftarrow u + D^{(k)}\\theta - \\alpha\n\\end{aligned}\n$$\n\n\n## Estimation algorithm\n\n$$\n\\minimize_{\\theta,\\ \\alpha}\\; \n\\eta^{\\mathsf{T}}\\exp(\\theta) - \n\\mathbf{y}^{\\mathsf{T}}\\theta + \n\\lambda\\Vert D^{(1)} \\alpha\\Vert_1\\quad\n\\textrm{subject to}\\quad \\alpha = D^{(k)}\\theta\n$$\n\n<br>\n<hr>\n<br>\n\nAlternating direction method of multipliers (ADMM)\n\n$$\n\\begin{aligned}\n\\theta &\\longleftarrow  {\\color{Cerulean}\\textrm{Proximal Newton / Fisher Scoring}} \\\\\n\\alpha &\\longleftarrow  {\\color{BurntOrange}\\textrm{Fused Lasso Signal Approximator}} \\\\\nu &\\longleftarrow u + D^{(k)}\\theta - \\alpha\n\\end{aligned}\n$$\n\n. . .\n\nSolve sequentially for $\\Vert (D^{\\dagger})^{\\mathsf{T}}(\\eta - y)\\Vert_\\infty = \\lambda_1 > \\cdots > \\lambda_M=\\epsilon \\lambda_1$. \n\n# Results and features of [{rtestim}]{.monotype} {.inverse}\n\n## Canadian Covid-19 cases\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture3_files/figure-revealjs/cancovid-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## $R_t$ for Canadian Covid-19 cases\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture3_files/figure-revealjs/cancovid-rt-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n## Reconvolved Canadian Covid-19 cases\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture3_files/figure-revealjs/cancovid-reconvolved-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Example simulations for different methods\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture3_files/figure-revealjs/simulated-realizations-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## `{rtestim}` software\n\n![](gfx/rtestim.png){.absolute top=\"-8%\" right=\"-15%\" height=\"105%\" style=\"max-height: unset;\"}\n\n* Guts are in [C++]{.monotype} for speed\n\n* Lots of the usual S3 methods\n\n* Approximate \"confidence\" bands\n\n* $\\widehat{R}$ is a member of a function space\n\n* Arbitrary spacing of observations\n\n* Built-in cross validation\n\n* Time-varying delay distributions\n\n## `{rtestim}` software\n\n::: flex\n::: w-40\n\n* Guts are in [C++]{.monotype} for speed\n\n* Lots of the usual S3 methods\n\n* [Approximate \"confidence\" bands]{.secondary}\n\n* $\\widehat{R}$ is a member of a function space\n\n* Arbitrary spacing of observations\n\n* Built-in cross validation\n\n* Time-varying delay distributions\n\n:::\n\n\n\n::: {.w-60 .fragment}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture3_files/figure-revealjs/confband-1.svg){fig-align='center' width=800px height=500px}\n:::\n:::\n\n\n\n:::\n:::\n\n::: {.fragment}\nApproximation + Delta method gives\n\n$$\n\\textrm{Var}(\\widehat{R}) = \\left(\\textrm{diag}(\\widehat{y}) + \n\\lambda D^{\\mathsf{T}}D\\right)^{\\dagger} \\left(\\frac{1}{\\eta^2}\\right)\n$$\n\n:::\n\n\n## `{rtestim}` software\n\n::: flex\n::: w-40\n\n* Guts are in [C++]{.monotype} for speed\n\n* Lots of the usual S3 methods\n\n* Approximate \"confidence\" bands\n\n* [$\\widehat{R}$ is a member of a function space]{.secondary}\n\n* [Arbitrary spacing of observations]{.secondary}\n\n* [Built-in cross validation]{.secondary}\n\n* Time-varying delay distributions\n\n:::\n\n\n\n::: {.w-60 .fragment}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture3_files/figure-revealjs/cross-validation-1.svg){fig-align='center' width=800px height=500px}\n:::\n:::\n\n\n\n:::\n:::\n\n::: {.fragment}\nThe solution is an element of the space of [_discrete splines of order $k$_]{.tertiary} \n(Tibshirani, 2020)\n\n* Lets us interpolate (and extrapolate) to off-observation points\n* Lets us handle uneven spacing\n:::\n\n## `{rtestim}` software\n\n::: flex\n::: w-40\n\n* Guts are in [C++]{.monotype} for speed\n\n* Lots of the usual S3 methods\n\n* Approximate \"confidence\" bands\n\n* $\\widehat{R}$ is a member of a function space\n\n* Arbitrary spacing of observations\n\n* Built-in cross validation\n\n* [Time-varying delay distributions]{.secondary}\n\n:::\n\n\n\n::: {.w-60}\n\n::: {.r-stack}\n::: {.fragment}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture3_files/figure-revealjs/duotang-1.svg){fig-align='center' width=800px height=600px}\n:::\n:::\n\n\n:::\n::: {.fragment}\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture3_files/figure-revealjs/show-delay-distns-1.svg){fig-align='center' width=800px height=600px}\n:::\n:::\n\n\n:::\n:::\n:::\n:::\n\n## `{rtestim}` software\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture3_files/figure-revealjs/plot-tvar-1.svg){fig-align='center'}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}