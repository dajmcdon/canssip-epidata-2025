{
  "hash": "16770434e9f14781c812006427b87024",
  "result": {
    "engine": "knitr",
    "markdown": "---\norg: \"CANSSI Prairies &mdash; Epi Forecasting Workshop 2025\"\ntitle: \"Introduction to Panel Data in Epidemiology\"\nsubtitle: \"Lecture 1\"\nshort-title: \"Understanding Data\"\nformat: revealjs\n---\n\n\n\n\n\n\n## Outline\n\n1. About Me\n\n1. Workshop Overview and System Setup\n\n1. Panel Data\n\n1. Versioned Data\n\n1. Epidata Repository and API\n\n1. `{epidatr}` and Other Data\n\n1. Versioning in `{epidatr}`\n\n\n# About Me {.inverse}\n\n## Daniel J. McDonald\n\n\n\n## About Delphi\n\n* Founded in 2012 at Carnegie Mellon University, now expanded to UC Berkeley, and University of British Columbia.\n\n* Currently 5 faculty, ~10 PhD students, ~15 staff (mostly software engineers).\n\n* Easy to join us from anywhere (lots of volunteers during Covid-19 pandemic).\n\n* We are:\n    + CDC Center of Excellence for Influenza and Covid-19 Forecasting (2019-24).\n    + CDC Innovation Center for Outbreak Analytics and Disease Modeling (2024-29).\n\n[**Our mission:**]{.primary} To develop the theory and practice of [epidemic detection, tracking and forecasting]{.primary}, and their use in decision making, both public and private.\n\n## What does Delphi do?\n\n* Procure [real-time, aggregated data streams]{.primary} informative of infectious diseases and syndromes, in collaboration with partners in industry and government.\n\n* Extract signals and make them widely available via the [Epidata platform & API]{.primary}.\n\n* Develop and deploy algorithms for [epidemic detection, tracking, forecasting]{.primary}.\n\n* Develop and maintain statistical software packages for these tasks.\n\n* Make it all production-grade, maximally-accessible, and open-source (to serve CDC, state and local public health agencies, epi-forecasting researchers, data journalists, the public)\n\n## What we provide\n\n![](gfx/web_of_parts.svg){fig-align=center}\n\n# Workshop Overview and System Setup {.inverse}\n\n## What we will cover\n\n- Characteristics of panel data in epidemiology\n- Tools for processing and plotting panel data\n- Statistical background on nowcasting and forecasting\n- Tools for building nowcasting and forecasting models \n- Plenty of examples throughout of real case studies\n\n## Goals part I\n\n- Expose you to a statistical way of thinking about now/forecasting\n- Certain basic mindsets (e.g., the importance of empirical validation\n  using techniques like time series cross-validation) are ubiquitous\n- Certain basic modeling considerations (e.g., starting simple and\n  building up complexity, taming variance through regularization,\n  addressing nonstationarity with trailing training windows) are also\n  ubiquitous\n\n## Goals part II\n\n- Expose you to software packages which aid processing, tracking,\n  nowcasting, and forecasting with panel data \n- These tools are still in development and we welcome your feedback\n- We have tried hard to get the framework right; but many individual\n  pieces themselves could still be improved \n- If these aren't working for you, then we want to hear from you!\n- We welcome collaboration, and everything we do is open source\n\n## A disclaimer\n\n- My background is primarily in statistics and computer science\n- This obviously influences my way of thinking and my approach to \n  nowcasting and forecasting\n- I don't have nearly as much experience with traditional epi models,\n  but I do have opinions about the pros/cons. \n- Ask me at any point if\n  you have a question about why I'm doing things a certain way\n  \n## One last slide\n\n- This workshop is supposed to be useful for YOU. Ask questions if\n  you have them, don't be shy\n- We may not (likely won't?) cover everything. Hopefully the materials\n  will be a resource for you beyond this workshop\n  \n\n## System setup\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninstall.packages(\"remotes\")\ninstall.packages(\"tidyverse\")\ninstall.packages(\"tidymodels\")\ninstall.packages(\"glmnet\")\nremotes::install_github(\"cmu-delphi/epidatr\")\nremotes::install_github(\"cmu-delphi/epidatasets\")\nremotes::install_github(\"cmu-delphi/epiprocess@dev\")\nremotes::install_github(\"cmu-delphi/epipredict@dev\")\nremotes::install_github(\"dajmcdon/rtestim\")\n```\n:::\n\n\n\n* Let's take a few moments here.\n* You may also navigate to the GitHub repo and Clone/Fork the entire thing.\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture1_files/figure-revealjs/qr-to-github-1.png){fig-align='center'}\n:::\n:::\n\n\n\n\n# Panel Data {.inverse}\n\n## Panel data\n\n* [Panel data]{.secondary} is cross-sectional measurements of subjects over time.\n\n* With aggregated data, the subjects are geographic units (e.g. provinces, states). \n\n* Time index + one or more locations/keys.\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 549 × 3\n   time_value geo_value percent_cli\n   <date>     <chr>           <dbl>\n 1 2020-06-01 ca               2.75\n 2 2020-06-02 ca               2.57\n 3 2020-06-03 ca               2.48\n 4 2020-06-04 ca               2.41\n 5 2020-06-05 ca               2.57\n 6 2020-06-06 ca               2.63\n 7 2020-06-07 ca               2.73\n 8 2020-06-08 ca               3.04\n 9 2020-06-09 ca               2.97\n10 2020-06-10 ca               2.99\n# ℹ 539 more rows\n```\n\n\n:::\n:::\n\n\n\n[The % of outpatient doctor visits that are COVID-related in CA, between June 2020 to Dec. 2021]{.small .grey}\n\n## Examples of panel data\n\n[JHU CSSE COVID-19 cases per 100k]{.secondary}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture1_files/figure-revealjs/examples-panel-covid2-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n::: {.notes}\n\n* WA switch to weekly reporting in 2022\n* FL reports \"whenever\" (weekly, biweekly, three days in a row, then 4 zeros, etc.)\n* API calculates change from cumulative, so no-report becomes a 0.\n* If state decreases total, then we see a negative.\n\n:::\n\n\n## Examples of panel data\n\n[Confirmed COVID-19 Hospital Admissions per 100k, 7day average]{.secondary}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture1_files/figure-revealjs/examples-hhs-admissions-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n::: {.fragment .box-text .absolute top=20% left=30%}\n\nThe $x$-axis is\n\n[Date of report]{.secondary}\n \nNot \"date of event\"\n\n:::\n\n## More disclaimers...\n\n* Most of this workshop will focus on panel data\n\n* Typical for the tasks my group has focused on\n\n* Typically analyze [aggregate signals]{.secondary}\n\n* [Simultaneously across geographies]{.secondary}\n\n* Contrasts with \"single geo models\"\n\n* Not working with \"line list data\"\n\n\n\n# Versioned Data {.inverse}\n\n## Intro to versioned data\n\n::: {.fragment .fade-in-then-out .box-text .absolute top=20% left=10%}\n::: {.secondary}\n→ Person comes to ER  \n→ Admitted  \n→ Has some tests  \n→ Tests come back  \n→ Entered into the system  \n→ ...\n:::\n:::\n\n* Epidemic aggregates are subject to [reporting delays and revisions]{.secondary}\n\n<br>\n\n* A \"Hospital admission\" may not attributable to a particular condition\nuntil a few days have passed\n\n<br>\n\n* Additionally, various mistakes lead to revisions\n\n<br>\n\n* Track both: when the event occurred and when it was reported\n\n## Intro to versioned data\n\n\n* Epidemic aggregates are subject to [reporting delays and revisions]{.secondary}\n\n<br>\n\n* A \"Hospital admission\" may not attributable to a particular condition\nuntil a few days have passed\n\n<br>\n\n* Additionally, various mistakes lead to revisions\n\n<br>\n\n* Track both: [when the event occurred]{.fragment .hl-green} and \n[when it was reported]{.fragment .hl-green}\n\n\n\n\n## Versioned data\n\n* The event time is indicated by `time_value` (or `reference_date`)\n\n* Second time index indicates the data `version` (or `reporting_date`)\n\n`version` = the time at which we saw a `value` associated to a `time_value`\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n  time_value geo_value percent_cli version   \n  <date>     <chr>           <dbl> <date>    \n1 2020-06-01 ca               2.14 2020-06-06\n2 2020-06-01 ca               2.14 2020-06-08\n3 2020-06-01 ca               2.11 2020-06-09\n4 2020-06-01 ca               2.13 2020-06-10\n5 2020-06-01 ca               2.20 2020-06-11\n6 2020-06-01 ca               2.23 2020-06-12\n```\n\n\n:::\n:::\n\n\n\n\n## Versioned panel data\n\nEstimated percentage of outpatient visits due to CLI across multiple versions.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture1_files/figure-revealjs/versioned-panel-multi-states-ex-2-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Latency and revision in signals\n\n* [Latency]{.secondary} the delay between data collection and availability\n\n::: {.callout-tip icon=false}\n## Example\nA signal based on insurance claims may take several days to appear as claims are processed\n:::\n\n<br>\n\n. . .\n\n* [Revision]{.secondary} data is updated or corrected after initial publication\n\n::: {.callout-tip icon=false}\n## Example\nCOVID-19 case reports are revised as reporting backlogs are cleared\n:::\n\n\n## Latency and revision in signals - Example\n\n* Recall the first example of panel & versioned data we've seen... \n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n* In June 2020, this signal is typically 4 days [latent]{.secondary}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 5\n  time_value geo_value percent_cli version    latency\n  <date>     <chr>           <dbl> <date>     <drtn> \n1 2020-06-01 ca               2.14 2020-06-06 5 days \n2 2020-06-02 ca               1.96 2020-06-06 4 days \n3 2020-06-03 ca               1.77 2020-06-06 3 days \n4 2020-06-04 ca               1.65 2020-06-08 4 days \n5 2020-06-05 ca               1.60 2020-06-09 4 days \n```\n\n\n:::\n:::\n\n\n. . .\n\nand subject to [revision]{.secondary}\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 5\n  time_value geo_value percent_cli version    latency\n  <date>     <chr>           <dbl> <date>     <drtn> \n1 2020-06-01 ca               2.14 2020-06-06  5 days\n2 2020-06-01 ca               2.14 2020-06-08  7 days\n3 2020-06-01 ca               2.11 2020-06-09  8 days\n4 2020-06-01 ca               2.13 2020-06-10  9 days\n5 2020-06-01 ca               2.20 2020-06-11 10 days\n```\n\n\n:::\n:::\n\n\n\n## Revision triangle, Insurance Claims WA January 2022 \n\n* 7-day trailing average to smooth day-of-week effects\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture1_files/figure-revealjs/revision-triangle-1.png){fig-align='center'}\n:::\n:::\n\n\n\n## Revisions\nMany data sources are subject to revisions:\n\n<br>\n\n* Case and death counts are corrected or adjusted by authorities\n\n* Medical claims can take weeks to be submitted and processed\n\n* Surveys are not completed promptly\n\n. . .\n\n<br>\n\n[An accurate revision log is crucial for researchers building nowcasts and forecasts]{.secondary}\n\n<br>\n\n::: {.fragment .callout-important}\n## Obvious but crucial\n\nA forecast that is made today can only use data available \"as of\" today\n:::\n\n## Three types of revisions\n\n\n1. [Sources that don't revise]{.fourth-colour} (provisional and final are the same) \n\nFacebook Survey and Google symptoms\n\n. . .\n\n2. [Predictable revisions]{.secondary} \n\nClaims data and public health reports aligned by test, hospitalization, \nor death date\n\nAlmost always revised upward as additional claims enter the pipeline\n\n. . .\n\n3. [Revisions that are large and erratic to predict]{.tertiary} \n\nCOVID cases and deaths\n\nThese are aligned by report date \n\n\n## Types of revisions - Comparison between 2. and 3.\n\n* Revision behavior for two indicators in the HRR containing Charlotte, NC.\n\n\n* [DV-CLI signal (left)]{.secondary}: regularly revised, but effects fade\n\n* [JHU CSSE cases (right)]{.tertiary} remain \"as first reported\" until a major correction is made on Oct. 19\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture1_files/figure-revealjs/fig1-McDonald-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n## Reporting backlogs - Example\n\nBexar County, Texas, summer of 2020...\n\n* Large backlog of case reports results in a spike\n* Auxilliary signals show continued decline\n* Reports are not be trustworthy without context\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture1_files/figure-revealjs/fig4-Reinhart-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n# Epidata Repository and API {.inverse}\n\n## What is the Epidata repository\n\n[Epidata:]{.secondary} repository of aggregated epi-surveillance time series\n\nSignals can be either public or restricted.\n\n* Currently contains over 5 billion records\n\n* During pandemic, handled millions of API queries per day\n\n* Many signals aren't available elsewhere\n\n\n::: {.callout-important appearance=\"simple\"}\nMake epi-surveillance more nimble, complete, standardized, robust, and real-time\n:::\n\n\n\n\n## Features of Delphi Epidata\n\n* Built-in support for:\n    1. Data revisions (\"backfill\"), including reporting dates and changes\n    1. Geo levels w/ auto-aggregation (e.g. county, state, and nation) and specialized levels (e.g., DMA, sewer sheds)\n    1. Demographic breakdown\n    1. Representation for missingness and censoring\n    1. Population sizes and fine-grained population density\n    \n* Customized smoothing and normalization\n\n* Access control\n\n* Code is Open Source.  \n\n* Signals are as accessible (w/ API, SDK) as allowed by DUAs\n\n\n## Severity pyramid\n\n![](gfx/severity-pyramid.svg){fig-align=center}\n\n\n::: {.fragment .box-text .absolute top=40% left=20%}\n<https://delphi.cmu.edu/epiportal/>\n:::\n\n# [{epidatr}]{.monotype} {.inverse}\n\n\n## Installing `{epidatr}`\n\n(you already did this, but just for posterity...)\n\nInstall the CRAN version\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Install the CRAN version\ninstall.packages(\"epidatr\")\n```\n:::\n\n\n\n<br>\n\nor the development version\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Install the development version from the GitHub dev branch\nremotes::install_github(\"cmu-delphi/epidatr@dev\")\n```\n:::\n\n\n\nThe CRAN listing is [here](https://cran.r-project.org/package=epidatr/index.html).\n\n## Python\n\nIn Python, install [`delphi-epidata` from PyPI](https://pypi.org/project/delphi-epidata/) with \n\n``` sh\npip install delphi-epidata\n```\n\n<br>\n\n`delphi-epidata` is soon to be replaced with `epidatpy`.\n\n``` sh\n# Latest dev version\npip install -e \"git+https://github.com/cmu-delphi/epidatpy.git#egg=epidatpy\"\n\n# PyPI version (not yet available)\npip install epidatpy\n```\n\n\n\n\n## Using `{epidatr}` and `{epidatpy}`\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(epidatr)\nhhs_flu_nc <- pub_covidcast(\n  source = 'hhs', \n  signals = 'confirmed_admissions_influenza_1d', \n  geo_type = 'state', \n  time_type = 'day', \n  geo_values = 'nc',\n  time_values = c(20240401, 20240405:20240414)\n)\nhead(hhs_flu_nc, n = 3)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 15\n  geo_value signal     source geo_type time_type time_value direction issue     \n  <chr>     <chr>      <chr>  <fct>    <fct>     <date>         <dbl> <date>    \n1 nc        confirmed… hhs    state    day       2024-04-01        NA 2024-04-22\n2 nc        confirmed… hhs    state    day       2024-04-05        NA 2024-04-22\n3 nc        confirmed… hhs    state    day       2024-04-06        NA 2024-04-22\n# ℹ 7 more variables: lag <dbl>, missing_value <dbl>, missing_stderr <dbl>,\n#   missing_sample_size <dbl>, value <dbl>, stderr <dbl>, sample_size <dbl>\n```\n\n\n:::\n:::\n\n\n\n<br>\n\nPython equivalent:\n``` python\nres = Epidata.covidcast('hhs', 'confirmed_admissions_influenza_1d', 'day', \n  'state', [20240401, Epidata.range(20240405, 20240414)], 'nc')\n```\n\n\n\n## API keys\n\n* [Anyone may access the Epidata API anonymously without providing any personal data!!]{.fragment .hl-claret}\n\n* Anonymous API access is subject to some restrictions:\n  <small>public datasets only; 60 requests per hour; only two parameters may have multiple selections</small>\n\n* API key grants privileged access; can be obtained by [registering with us](https://api.delphi.cmu.edu/epidata/admin/registration_form) \n\n* Privileges of registration: no rate limit; no limit on multiple selections\n\n* We just want to know which signals people care about to ensure we're providing benefit\n\n<!-- rate limited to 60 requests per hour;  -->\n::: {.callout-tip}\n* The `{epidatr}` client automatically searches for the key in the `DELPHI_EPIDATA_KEY` environment variable. \n* We recommend storing it in your `.Renviron` file, which R reads by default. \n* More on setting your API key [here](https://rdrr.io/cran/epidatr/man/get_api_key.html).\n:::\n\n\n\n\n## Interactive tooling in R \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\navail_endpoints()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 28 × 2\n   Endpoint                          Description                                \n   <chr>                             <chr>                                      \n 1 pub_covid_hosp_facility()         COVID hospitalizations by facility         \n 2 pub_covid_hosp_facility_lookup()  Helper for finding COVID hospitalization f…\n 3 pub_covid_hosp_state_timeseries() COVID hospitalizations by state            \n 4 pub_covidcast()                   Various COVID and flu signals via the COVI…\n 5 pub_covidcast_meta()              Metadata for the COVIDcast endpoint        \n 6 pub_delphi()                      Delphi's ILINet outpatient doctor visits f…\n 7 pub_dengue_nowcast()              Delphi's PAHO dengue nowcasts (North and S…\n 8 pub_ecdc_ili()                    ECDC ILI incidence (Europe)                \n 9 pub_flusurv()                     CDC FluSurv flu hospitalizations           \n10 pub_fluview()                     CDC FluView ILINet outpatient doctor visits\n11 pub_fluview_clinical()            CDC FluView flu tests from clinical labs   \n12 pub_fluview_meta()                Metadata for the FluView endpoint          \n13 pub_gft()                         Google Flu Trends flu search volume        \n14 pub_kcdc_ili()                    KCDC ILI incidence (Korea)                 \n15 pub_meta()                        Metadata for the Delphi Epidata API        \n16 pub_nidss_dengue()                NIDSS dengue cases (Taiwan)                \n17 pub_nidss_flu()                   NIDSS flu doctor visits (Taiwan)           \n18 pub_nowcast()                     Delphi's ILI Nearby nowcasts               \n19 pub_paho_dengue()                 PAHO dengue data (North and South America) \n20 pub_wiki()                        Wikipedia webpage counts by article        \n21 pvt_cdc()                         CDC total and by topic webpage visits      \n22 pvt_dengue_sensors()              PAHO dengue digital surveillance sensors (…\n23 pvt_ght()                         Google Health Trends health topics search …\n24 pvt_meta_norostat()               Metadata for the NoroSTAT endpoint         \n25 pvt_norostat()                    CDC NoroSTAT norovirus outbreaks           \n26 pvt_quidel()                      Quidel COVID-19 and influenza testing data \n27 pvt_sensors()                     Influenza and dengue digital surveillance …\n28 pvt_twitter()                     HealthTweets total and influenza-related t…\n```\n\n\n:::\n:::\n\n\n\n\n## Fetching data - COVIDcast main endpoint \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\njhu_us_cases <- pub_covidcast(\n  source = \"jhu-csse\",                        # this endpoint contains many different sources\n  signals = \"confirmed_7dav_incidence_prop\",  # other signals: deaths, cumulative, etc.\n  geo_type = \"nation\",                        # the geographic resolution (nation, state, hrr, msa, etc.)\n  time_type = \"day\",                          # or week or year\n  geo_values = \"us\",                          # optional\n  time_values = epirange(20210101, 20210401), # optional\n  ...                                         # additional arguments\n)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 8\n  geo_value signal             source geo_type time_value issue        lag value\n  <chr>     <chr>              <chr>  <fct>    <date>     <date>     <dbl> <dbl>\n1 us        confirmed_7dav_in… jhu-c… nation   2021-01-01 2023-03-10   798  61.9\n2 us        confirmed_7dav_in… jhu-c… nation   2021-01-02 2023-03-10   797  64.2\n3 us        confirmed_7dav_in… jhu-c… nation   2021-01-03 2023-03-10   796  67.1\n```\n\n\n:::\n:::\n\n\n\n`value` is the requested signal\n\n[There are some other columns in the usual output that I've hidden]{.small .grey}\n\n\n## Get everything for a `source + signal`\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\njhu_us_cases <- pub_covidcast(\n  source = \"jhu-csse\",                  # this endpoint contains many different sources\n  signals = \"confirmed_incidence_num\",  # raw cases during the entire pandemic reporting until ~ April 2024\n  geo_type = \"county\",                  # the geographic resolution (nation, state, hrr, msa, etc.)\n  time_type = \"day\",                    # lowest resolution\n  geo_values = \"*\",                     # (default) \n  time_values = \"*\",                    # (default) \n  ...                                   # additional arguments\n)\n```\n:::\n\n\n\n<br><br>\n\n* This query takes a few minutes to run, so I don't recommend it. \n\n* But there is support for automatic caching,\n\n* and using `\"*\"` speeds things up relative to specifying many specific ranges.\n\n::: {.fragment .box-text .absolute top=30% left=10%}\nThe result has about 3.75M rows and occupies 400Mb.\n:::\n\n\n# Versioning in [{epidatr}]{.monotype} {.inverse}\n\n## Versioned data in `{epidatr}`\n\n<br>\n\nTwo important, mutually exclusive parameters\n\n<br>\n\n### `issues = c(mdy1, mdy2, ..., )` \n* fetches the data that the source made available on the requested dates\n* Database stores only the diffs, so that's typically what you get\n* Even if the source republishes the entire history every time they make an update\n\n\n### `as_of = mdy`\n* fetches the all available data as it would have looked on `mdy`\n* Think of it as [winding back the clock]{.secondary} to the date `mdy`\n* API only accepts a single date here\n\n## Example `issues` query\n\n* I wanted to display a major reporting error. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nversions <- as.Date(c(\"2021-02-15\", \"2021-02-20\", \"2021-02-25\", \"2021-03-01\", \"2023-01-01\")) \npub_covidcast(\n  \"jhu-csse\", \"deaths_7dav_incidence_num\", \n  geo_type = \"state\", \n  geo_values = \"oh\",\n  time_type = \"day\",\n  time_values = epirange(20210101,20210301),\n  issues = versions\n) |>\n  select(geo_value, time_value, version = issue, deaths = value)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 4\n  geo_value time_value version    deaths\n  <chr>     <date>     <date>      <dbl>\n1 oh        2021-02-14 2021-02-15  670. \n2 oh        2021-02-19 2021-02-20   43.1\n3 oh        2021-02-24 2021-02-25   42.3\n4 oh        2021-02-28 2021-03-01   68.7\n```\n\n\n:::\n:::\n\n\n\n::: {.fragment .box-text .absolute top=20% left=10%}\n* Not what I wanted.\n\n* Got only the diff on each issue.\n\n* I wanted to view the whole history on each of those dates.\n:::\n\n## Correct `as_of` query\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"|1,2,9\"}\nres <- map(versions, # same set as before\n           .f = \\(v) { \n             pub_covidcast(\n               \"jhu-csse\", \"deaths_7dav_incidence_num\", \n               geo_type = \"state\", \n               geo_values = \"oh\",\n               time_type = \"day\",\n               time_values = epirange(20210101,20210301),\n               as_of = v \n             ) |>\n               select(geo_value, time_value, deaths = value) |>\n               mutate(version = v)\n           }) |>\n  list_rbind()\nres |> head(7)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7 × 4\n  geo_value time_value deaths version   \n  <chr>     <date>      <dbl> <date>    \n1 oh        2021-01-01   72.3 2021-02-15\n2 oh        2021-01-02   77.3 2021-02-15\n3 oh        2021-01-03   81   2021-02-15\n4 oh        2021-01-04   81.7 2021-02-15\n5 oh        2021-01-05   75   2021-02-15\n6 oh        2021-01-06   73.3 2021-02-15\n7 oh        2021-01-07   71.4 2021-02-15\n```\n\n\n:::\n:::\n\n\n\n::: {.fragment .box-text .absolute top=20% left=5%}\n* Got the data [as it would have appeared]{.tertiary} for each of the 4 dates.\n* But `as_of` can only accept a scalar, not vector of dates.\n* Had to \"loop\" over them.\n* We'll see a more efficient way to do this later this morning.\n:::\n\n## Now I can show you why I wanted that query\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](lecture1_files/figure-revealjs/oh-death-spike-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n\n\n## Versioning in nowcasting and forecasting\n\n* Revision patterns can be used to inform understanding of current situation\n\n* Often, predicting \"today\" is more about predicting the revisions than the process\n\n* Forecasting often requires adjustments for revision/reporting patterns\n\n* Backtesting requires using data that would have been available at the time, not current data\n\n* Only looking at the most recent data is a huge blunder\n\n\n## Wrapup and worksheet discussion\n\n* [**Delphi Epidata:**]{.primary} platform for real-time epidemic data\n    * provides (aggregated) signals for tracking and forecasting\n    * sources like [**health records**]{.secondary}, [**mobility patterns**]{.tertiary}, and [**more**]{.fourth-colour}.\n\n\n* [**Epidata API:**]{.primary} delivers up-to-date, granular epidemiological data + historical versions.\n\n\n* `{epidatr}`: Client package for R\n\n\n* [**Versioned Data and Latency:**]{.primary}\n    1. `as_of`:  One version; the specific date when the data was last updated \n    1. `issues`: Multiple versions; with different `as_of` dates\n    \nManages the record of revisions for transparency and accuracy in data analysis.\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}